{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-28T07:27:45.892834Z","iopub.execute_input":"2022-08-28T07:27:45.893414Z","iopub.status.idle":"2022-08-28T07:27:57.262499Z","shell.execute_reply.started":"2022-08-28T07:27:45.893326Z","shell.execute_reply":"2022-08-28T07:27:57.261709Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Reading Data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:27:57.265978Z","iopub.execute_input":"2022-08-28T07:27:57.266184Z","iopub.status.idle":"2022-08-28T07:27:57.324527Z","shell.execute_reply.started":"2022-08-28T07:27:57.266158Z","shell.execute_reply":"2022-08-28T07:27:57.323831Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                    Id  Subject Focus  Eyes  Face  Near  \\\n0     0007de18844b0dbbb5e1f607da0606e0              0     1     1     1   \n1     0009c66b9439883ba2750fb825e1d7db              0     1     1     0   \n2     0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1   \n3     0018df346ac9c1d8413cfcc888ca8246              0     1     1     1   \n4     001dc955e10590d3ca4673f034feeef2              0     0     0     1   \n...                                ...            ...   ...   ...   ...   \n9907  ffbfa0383c34dc513c95560d6e1fdb57              0     0     0     1   \n9908  ffcc8532d76436fc79e50eb2e5238e45              0     1     1     1   \n9909  ffdf2e8673a1da6fb80342fa3b119a20              0     1     1     1   \n9910  fff19e2ce11718548fa1c5d039a5192a              0     1     1     1   \n9911  fff8e47c766799c9e12f3cb3d66ad228              0     1     1     1   \n\n      Action  Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n0          0          0      1        0      0          0     0     0   \n1          0          0      0        0      0          0     0     0   \n2          0          0      0        0      1          1     0     0   \n3          0          0      0        0      0          0     0     0   \n4          0          0      1        0      0          0     0     0   \n...      ...        ...    ...      ...    ...        ...   ...   ...   \n9907       0          0      0        0      0          0     0     1   \n9908       0          0      0        0      0          0     0     0   \n9909       0          0      0        0      1          1     0     0   \n9910       0          0      0        0      1          0     0     0   \n9911       0          0      0        0      0          0     0     0   \n\n      Pawpularity  \n0              63  \n1              42  \n2              28  \n3              15  \n4              72  \n...           ...  \n9907           15  \n9908           70  \n9909           20  \n9910           20  \n9911           30  \n\n[9912 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Subject Focus</th>\n      <th>Eyes</th>\n      <th>Face</th>\n      <th>Near</th>\n      <th>Action</th>\n      <th>Accessory</th>\n      <th>Group</th>\n      <th>Collage</th>\n      <th>Human</th>\n      <th>Occlusion</th>\n      <th>Info</th>\n      <th>Blur</th>\n      <th>Pawpularity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>63</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0009c66b9439883ba2750fb825e1d7db</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001dc955e10590d3ca4673f034feeef2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9907</th>\n      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>9908</th>\n      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>9909</th>\n      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>9910</th>\n      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>9911</th>\n      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n<p>9912 rows Ã— 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's get some information about data such as type of attributes and amount of miss values","metadata":{}},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:46:23.183921Z","iopub.execute_input":"2022-08-28T07:46:23.184178Z","iopub.status.idle":"2022-08-28T07:46:23.209640Z","shell.execute_reply.started":"2022-08-28T07:46:23.184149Z","shell.execute_reply":"2022-08-28T07:46:23.208889Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9912 entries, 0 to 9911\nData columns (total 14 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   Id             9912 non-null   object\n 1   Subject Focus  9912 non-null   int64 \n 2   Eyes           9912 non-null   int64 \n 3   Face           9912 non-null   int64 \n 4   Near           9912 non-null   int64 \n 5   Action         9912 non-null   int64 \n 6   Accessory      9912 non-null   int64 \n 7   Group          9912 non-null   int64 \n 8   Collage        9912 non-null   int64 \n 9   Human          9912 non-null   int64 \n 10  Occlusion      9912 non-null   int64 \n 11  Info           9912 non-null   int64 \n 12  Blur           9912 non-null   int64 \n 13  Pawpularity    9912 non-null   int64 \ndtypes: int64(13), object(1)\nmemory usage: 1.1+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:46:26.684650Z","iopub.execute_input":"2022-08-28T07:46:26.684923Z","iopub.status.idle":"2022-08-28T07:46:26.734225Z","shell.execute_reply.started":"2022-08-28T07:46:26.684892Z","shell.execute_reply":"2022-08-28T07:46:26.733407Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                count       mean        std  min   25%   50%   75%    max\nSubject Focus  9912.0   0.027643   0.163957  0.0   0.0   0.0   0.0    1.0\nEyes           9912.0   0.772599   0.419175  0.0   1.0   1.0   1.0    1.0\nFace           9912.0   0.903955   0.294668  0.0   1.0   1.0   1.0    1.0\nNear           9912.0   0.861582   0.345356  0.0   1.0   1.0   1.0    1.0\nAction         9912.0   0.009988   0.099444  0.0   0.0   0.0   0.0    1.0\nAccessory      9912.0   0.067797   0.251409  0.0   0.0   0.0   0.0    1.0\nGroup          9912.0   0.129338   0.335591  0.0   0.0   0.0   0.0    1.0\nCollage        9912.0   0.049637   0.217204  0.0   0.0   0.0   0.0    1.0\nHuman          9912.0   0.166263   0.372335  0.0   0.0   0.0   0.0    1.0\nOcclusion      9912.0   0.172014   0.377411  0.0   0.0   0.0   0.0    1.0\nInfo           9912.0   0.061239   0.239780  0.0   0.0   0.0   0.0    1.0\nBlur           9912.0   0.070420   0.255866  0.0   0.0   0.0   0.0    1.0\nPawpularity    9912.0  38.039044  20.591990  1.0  25.0  33.0  46.0  100.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Subject Focus</th>\n      <td>9912.0</td>\n      <td>0.027643</td>\n      <td>0.163957</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Eyes</th>\n      <td>9912.0</td>\n      <td>0.772599</td>\n      <td>0.419175</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Face</th>\n      <td>9912.0</td>\n      <td>0.903955</td>\n      <td>0.294668</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Near</th>\n      <td>9912.0</td>\n      <td>0.861582</td>\n      <td>0.345356</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Action</th>\n      <td>9912.0</td>\n      <td>0.009988</td>\n      <td>0.099444</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Accessory</th>\n      <td>9912.0</td>\n      <td>0.067797</td>\n      <td>0.251409</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Group</th>\n      <td>9912.0</td>\n      <td>0.129338</td>\n      <td>0.335591</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Collage</th>\n      <td>9912.0</td>\n      <td>0.049637</td>\n      <td>0.217204</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Human</th>\n      <td>9912.0</td>\n      <td>0.166263</td>\n      <td>0.372335</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Occlusion</th>\n      <td>9912.0</td>\n      <td>0.172014</td>\n      <td>0.377411</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Info</th>\n      <td>9912.0</td>\n      <td>0.061239</td>\n      <td>0.239780</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Blur</th>\n      <td>9912.0</td>\n      <td>0.070420</td>\n      <td>0.255866</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Pawpularity</th>\n      <td>9912.0</td>\n      <td>38.039044</td>\n      <td>20.591990</td>\n      <td>1.0</td>\n      <td>25.0</td>\n      <td>33.0</td>\n      <td>46.0</td>\n      <td>100.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"import plotly \nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:46:31.381848Z","iopub.execute_input":"2022-08-28T07:46:31.382113Z","iopub.status.idle":"2022-08-28T07:46:34.549771Z","shell.execute_reply.started":"2022-08-28T07:46:31.382081Z","shell.execute_reply":"2022-08-28T07:46:34.548957Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"col_var = train_df.columns[1:-1].values.tolist()\n\nfor i in col_var:\n    fig, ax = plt.subplots(1,2, figsize=(14,4))\n    sns.boxplot(data=train_df, x=i, y='Pawpularity', ax=ax[0])\n    sns.histplot(data=train_df, x='Pawpularity', hue=i, kde=True, ax=ax[1])\n    plt.suptitle(i, fontsize=20)\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:46:40.545145Z","iopub.execute_input":"2022-08-28T07:46:40.545867Z","iopub.status.idle":"2022-08-28T07:46:48.781789Z","shell.execute_reply.started":"2022-08-28T07:46:40.545831Z","shell.execute_reply":"2022-08-28T07:46:48.780020Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA0MAAAEjCAYAAADwq9qcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABZ/ElEQVR4nO3deXxU1f3/8ddnMtlDVkKAhLDLLoIouO+7ov5qte6KLfVrtdaudrG11bZ2s7VWbalape617nVfcBdEVHZkh4QtO2Rf5vz+mAsGSEiAJHeSeT8fj3nM3HO3TyaTzHzmnPs55pxDREREREQk2gT8DkBERERERMQPSoZERERERCQqKRkSEREREZGopGRIRERERESikpIhERERERGJSkqGREREREQkKikZEhERERGRqKRkSERE9pqZHWBmt5vZPDMrNbMG7362mf3RzA72O0YREZG2mCZdFRGR9jIzA37u3QLAPGAOUAr0Ag4EDgPigGudc3f5FKqIiEibgn4HICIi3crPgZuB9cCFzrn3d93AzPoA3wHSujQyERGRvaRhciIi0i5mNgT4GVAPnNZSIgTgnNvinPsJ8Ptm+z5gZs7MhpjZdWY238xqzGxWs22Gm9lMMys0s3oz2+AtD28hlu3HG9TCumO9dTfv0j7La483s1vNbLWZ1ZnZSjP7hZnF7eNTIyIi3ZR6hkREpL2uJPy+8YhzblFbGzvnGltovgM4Cvgf8CLQBGBmhwCvEx5q9xywGBgJXAKcbWYnOuc+7ogfAngCOAR4EmgAzibc2zXJzKY6jR8XEYkaSoZERKS9jvDu39yPY0wEJjjnVm9v8K5DmgmkApc45x5utu4C4DHg32Y22jkX2o9zbzcKGOOcK/PO8VPgLeBMwsnXvzvgHCIi0g0oGRIRkfbq690X7rrCG652xS7N5c65v+zS9vvmiZDncMK9QB82T4QAnHOPm9m1wJHe7Z19inxnt2xPhLxz1JrZjwknRNNQMiQiEjWUDImISEcYBPxil7a1wF92aZvTwr4TvfvWepzeJJwITaBjkqG3W2h7j/CQvQkdcHwREekmVEBBRETaa5N333/XFc65Wc45c84ZENuOYzS3vercxlb22d6e3p4g22Hzrg3e9U3FhIfqiYhIlFAyJCIi7bW9etwJ+3GMlooTVHj3fVtYB9Bvl+0Atl871NIIh/Q2YsjZtcHMgkBvYGsb+4qISA+iZEhERNrrAaAROM/MRnXgcT/17o9tZf1x3v28Zm3br/kZ0ML2k9o43zEttB0JxDSLRUREooCSIRERaRfn3ErgViAOeMnMDm9l0/S9PPT7wDLgSDM7r/kKb/ko4AvC1/Vst/3ao2/ssv044Po2zneTmWU02ycB+K23+K+9jF1ERLoxFVAQEZG98SvAgJuA983sE8KJSSnhJGgQcKK3bbuKHTjnnJldDrwGPG5mzwJLgRHAOcA24LJdymo/CywHLjSzPGA2kE94zqBngfP3cMolwCIzaz7P0FDCcx+pkpyISBRRMiQiIu3mTUh6s5k9ClxNeAjbRUAy4aRlJXAP8G/n3LxWD7T7cWd7E6/+jHAydRbhggaPEi6FvWyX7WvN7ATgj8BJhCdRXejFUsqek6HzCSdzFxMuBlFIeNLV2zThqohIdDH93xcRkWhgZrOAY7yKdyIiIrpmSEREREREopOSIRERERERiUpKhkREREREJCrpmiEREREREYlK6hkSEREREZGopGRIRERERESikpIhERERERGJSkqGREREREQkKikZEhERERGRqKRkSEREREREopKSIRERERERiUpKhkREREREJCoF/Q5gf/Tu3dsNGjTI7zBERKLaJ598Uuycy/Y7jkik9ykREf/t6X2qWydDgwYNYu7cuX6HISIS1cxsrd8xRCq9T4mI+G9P71MaJiciIiIiIlFJyZCIiIiIiEQlJUMiIiIiIhKVuvU1QyIiIiIi0vkaGhooKCigtrbW71BalZCQQF5eHrGxse3eR8mQtOrYY4/d8XjWrFm+xSGyr4477jiccwQCAd58802/wxEREem2CgoK6NWrF4MGDcLM/A5nN845SkpKKCgoYPDgwe3er9OGyZnZ/Wa2xcwWNmvLNLPXzGy5d5/htZuZ/dXMVpjZfDOb2FlxiUj0cM4BEAqFfI5ERESke6utrSUrKysiEyEAMyMrK2uve64685qhB4BTd2m7EXjDOTcceMNbBjgNGO7dpgP3dGJc0g7Ne4VaWhaJdMcdd9xOy8cff7xPkYiIiPQMkZoIbbcv8XVaMuScewco3aX5bOBB7/GDwDnN2me6sI+AdDPr11mxiUjPt71XaDv1DomIiMiuurqaXI5zbqP3eBOQ4z3OBdY3267Aa9uNmU03s7lmNreoqKjzIhURERERkTZt3ryZiy66iCFDhnDwwQdz2GGH8fTTT/sdVrv4VkDBOefMzLW95W77zQBmAEyaNGmv9xcRERHZ7rJp0ykqq9itPTsjjZn3z/AhIpHuxTnHOeecw+WXX84jjzwCwNq1a3nuued22q6xsZFgMPJqt3V1RJvNrJ9zbqM3DG6L114IDGi2XZ7XJiKyT8xsp6FygYCmVROR3RWVVXDyNbfs1v7q3Tf5EI1I9/Pmm28SFxfH1VdfvaNt4MCBXHfddTzwwAM89dRTVFZW0tTUxNNPP820adNYtWoVSUlJzJgxgwMPPJCbb76ZlJQUvv/97wMwduxYXnjhBQBOPfVUDj74YObNm8eYMWOYOXMmSUlJHRZ/V386eA643Ht8OfBss/bLvKpyU4CKZsPpRET22ltvvbXTskpri4iIdLxFixYxcWLrhaDnzZvHk08+ydtvv80vfvELJkyYwPz58/nNb37DZZdd1ubxly1bxjXXXMOSJUtITU3l7rvv7sjwO7W09qPAh8AIMysws6uA24CTzGw5cKK3DPAisApYAfwTuKaz4hKR6BPp1W9ERER6im9961uMHz+eQw45BICTTjqJzMxMAN577z0uvfRSIFzltaSkhK1bt+7xeAMGDOCII44A4JJLLuG9997r0Hg7bZicc+7CVlad0MK2DvhWZ8UiItFp6tSpPP/880ydOtXvUERERHqkMWPG8N///nfH8l133UVxcTGTJk0CIDk5uc1jBIPBnaq+Np8raNcvNDv6C04NoheRHqmkpISXXnoJ5xwvvfQSJSUlfockIj66bNp0Tjv3gt1uCxct8js0kW7t+OOPp7a2lnvu+XKa0Orq6ha3Peqoo3j44YcBmDVrFr179yY1NZVBgwYxb948IDysbvXq1Tv2WbduHR9++CEAjzzyCEceeWSHxh95JR1ERDrAgw8+SGNjIwANDQ3MnDmTG264weeoRMQvrRVKmDddPcci+8PMeOaZZ7jhhhv4/e9/T3Z2NsnJyfzud7+jpqZmp21vvvlmpk2bxoEHHkhSUhIPPhiefvQrX/kKM2fOZMyYMUyePJkDDjhgxz4jRozgrrvuYtq0aYwePZr/+7//69D4lQyJSI/02muv7agm55zj1VdfVTIkIiLSCfr168djjz3W4rorrrhix+PMzEyeeeaZ3bZJTEzk1Vdf3a19zZo1BINBHnrooY4KdTdKhkSkR8rJyWHNmjU7LYtIz9banEEACxct4uS9ONaC+fM57dwLWlynOYhEeg4lQyLSI23cuHGPyyLS87Q2FA72fjhcQ8i1eizNQSTSNQYNGsTChQs79RwqoCAiPVJsbOwel0VERESUDIlIj1RZWbnHZRERERElQyLSIwWDwT0ui4iIiCgZEpEeaXtZ7daWRURERJQMiUiPlJKSssdlERER2XcD8gdiZh12G5A/sF3nffnllxkxYgTDhg3jtttu2++fQ+NGRKRHqq+v3+OyiIiI7LuC9eu4/dVlHXa87548os1tmpqa+Na3vsVrr71GXl4ehxxyCFOnTmX06NH7fF71DIlIjxQXF7fHZREAM1tjZgvM7DMzm+u1ZZrZa2a23LvP8NrNzP5qZivMbL6ZTfQ3ehGR6DJnzhyGDRvGkCFDiIuL42tf+xrPPvvsfh1TyZCI9EiqJid74Tjn3EHOuUne8o3AG8654cAb3jLAacBw7zYduKfLIxURiWKFhYUMGDBgx3JeXh6FhYX7dUwlQyLSI+maIdkPZwMPeo8fBM5p1j7ThX0EpJtZPx/iExGRDqJkSER6JF0zJO3kgFfN7BMzm+615TjnNnqPNwE53uNcYH2zfQu8NhER6QK5ubmsX//lv+GCggJyc/fv37CSIRHpkXTNkLTTkc65iYSHwH3LzI5uvtI55wgnTO1mZtPNbK6ZzS0qKurAUKUjOecoLKshOO403l1exKfryqiqUwl+kUh2yCGHsHz5clavXk19fT2PPfYYU6dO3a9jqpqciPRIumZI2sM5V+jdbzGzp4FDgc1m1s85t9EbBrfF27wQGNBs9zyvbddjzgBmAEyaNGmvEinpGkXb6nhl0SZKquoJjjyO+QUVNIYc764oZlxuGkcN6+13iCIRL29AfrsqwO3N8doSDAb529/+ximnnEJTUxPTpk1jzJgx+3VeJUMi0iMFg8GdJloNBvXvTnZmZslAwDm3zXt8MvAr4DngcuA27357qaLngGvN7DFgMlDRbDiddBNLN23l9cVbSIgNcPLoHJ69ZRrfuftJyqrq+aygnPkFFRSW1UBiqt+hikS09evW+nLe008/ndNPP73DjqdPByLSIzVPhFpaFiF8LdDTZgbh98NHnHMvm9nHwBNmdhWwFjjf2/5F4HRgBVANXNn1Icv+WLGlklcXbyY3LZHTx/UjMS6GZxvD1xNmJMdx3Ig+DO6dzIsLNhJ/zDeprm8kKU4flUR6Mv2Fi0iPlJKSstPQOFWTk10551YB41toLwFOaKHdAd/qgtCkE1h6f15euImcXgmcNb4/ccGWL5selJXM1PH9eXJOPc9/vpHzDs4jJmBdHK2IdBUVUBCRHqmhoWGPyyISPRqaQsQddgkJsQGm7iER2i4vI4n62Y+waWstH64s6aIoRcQPSoZEpEfq16/fHpdFJHq8v6KYQGoOJ4/pS2JcTLv2CRXMZ1xuGp+sK2NdaXUnRygiflEyJCI90oYNG/a4LCLRoWhbXbha3PL3yM9M2qt9jx7em/TEWN5cuoXGplAnRSgiflIyJCI9kobJiYhzjre/KCI+NkDDgpf3ev9gTIBjR2RTUdPAJ+vKOiFCEfGbkiER6ZHC17q3viwiPd+q4ioKy2s4bEgWNNTs0zEGZiUzvE8KH68pY1utvlQR2W5Qfh5m1mG3Qfl5bZ5z2rRp9OnTh7Fjx3bYz6FqciLSI5nZTgmQVz5ZRKKEc47Zq0pJS4xlbP80XtyPYx05rDeriqqYvbqUE0fldFiMIt3Z2vWFuDd/02HHs+N/0uY2V1xxBddeey2XXXZZh51XPUMiIiLS46wurqKoso5DB2US2M/S2KmJsYzLTWPxxq2UVdV3UIQisreOPvpoMjMzO/SYSoZEpEfSMDmR6OWcY86aUlITgozo26tDjnnI4AyCAeOj1Sq1LdKTKBkSERGRHmVDRS2bt9Zx8MCMDpswNSkuyIF56SzfXEl9bMckWCLiPyVDIiIi0qN8vr6c+GCAUf1SO/S4EwakEwgYJZkdd/G2iPhLyZCIiIj0GNtqG1hRVMnY/mnExnTsx5zk+CBj+qdSnjaEjRX7Vp1ORCKLL9XkzOwG4OuAAxYAVwL9gMeALOAT4FLnnK5SFOlm7rzzTlasWOF3GMTHx1NXV7fT8vXXX+9jRGHDhg3juuuu8zsMkR5rfkEFODgwL61Tjn9wfgbz15cx88O1/OjUkZ1yDpHuYOCA3HZVgNub47XlwgsvZNasWRQXF5OXl8cvf/lLrrrqqv06b5cnQ2aWC3wbGO2cqzGzJ4CvAacDf3bOPWZmfweuAu7p6vhEpGfIz89n+fLlO5YHDhzoYzQi0hUcxuKNWxnUO5nUxNhOOUdqYiy9Ktfz6Jx4rj9hOAmxMZ1yHpFIt2ZdQZef89FHH+3wY/o1z1AQSDSzBiAJ2AgcD1zkrX8QuBklQyLdTiT1epxyyinU1dUxaNAgZsyY4Xc4ItLJKpNzqa5vYkz/jr1WaFcZZUtZ12sgz35WyAWH5HfquUSkc3X5NUPOuULgj8A6wklQBeFhceXOuUZvswKgxb4yM5tuZnPNbG5RUVFXhCwi3VR+fj6BQICf/exnfociIl2gPG04SXExDMpK7tTzJNVsZmTfXvzr/TUq2y/SzXV5MmRmGcDZwGCgP5AMnNre/Z1zM5xzk5xzk7KzszspShHpCZKSkhg3bhzDhg3zOxQR6WRbttZSmZLLqH6pHVZOuzUGXHnEIJZu2sZHq0o79VwikSTSk/99ic+PanInAqudc0XOuQbgKeAIIN3Mtg/bywMKfYhNREREuqHnPt8AFmB0B5fTbs3ZB+WSkRTLAx+s7pLzifgtISGBkpKSiE2InHOUlJSQkJCwV/v5cc3QOmCKmSUBNcAJwFzgLeA8whXlLgee9SE2ERER6Yae/WwDCbUlZCYP75LzJcTGcOGh+fz97ZWsL61mQGZSl5xXxC95eXkUFBQQyZepJCQkkJeXt1f7dHky5JybbWZPAvOARuBTYAbwP+AxM7vVa7uvq2MTERGR7mdlUSULCivos3UVMKXLznvJlIH8451VPDR7LT8+bVSXnVfED7GxsQwePNjvMDqcL9XknHO/AH6xS/Mq4FAfwokYkTI/S2v8nqNF87OIiAjAZdOmU1RWsWO5KGs8ZB3IxrmvwIUX7WHPjtU/PZGTRuXwn7kFfPekA4gPqsy2SHfjV2ltiXCBQIBQKLTTsoiISCQoKqvg5GtuAcLXCcz8cC0DEoJ8sa2sy2O5eEo+Ly/axMsLN3H2QW1PGikikUXJUASJtF6PY489dsfjN998079AREREWlFSVU95TQMT8zP4wofzHzG0N4Oyknj4o3VKhkS6IX3dL63a3hvUp08fnyMRERFp2cotlQAMye7cuYVaEwgYF03OZ86aUpZt2uZLDCKy75QMSavGjRvH+PHjeeKJJ/wORUREpEUriirpn5ZAcrx/g13OO3gAccEAj8xe61sMIrJvNExOREREuqXy6nqKK+s5anhvX+PITI7jjHH9eOj9FXz04G8JuMad1mdnpDHz/hk+RScie6JkSERERLqllUVVAAzLTvE5Erh4cj5Pf1pI3tTvMDY3bad1r959k09RiUhbNExOREREuqUVWyrp0yue1MRYv0Ph4IEZxNeVsaCwou2NRSRiKBkSERGRbqeytpFNW2sZGgG9QgBmRnr5F2zZVsemrbV+hyMi7aRkSERERLqdlUXhKnLD+kRGMgSQtnUVsTHGggL1Dol0F0qGREQkqplZjJl9amYveMuDzWy2ma0ws8fNLM5rj/eWV3jrB/kaeJRbUVRJRlIsmclxfoeyQ0yogRE5vfhi8zbqGpr8DkdE2kHJkIiIRLvrgSXNln8H/Nk5NwwoA67y2q8Cyrz2P3vbiQ+aAnEUltdEzBC55sblpdEYcizRnEMi3YKSIRERiVpmlgecAdzrLRtwPPCkt8mDwDne47O9Zbz1J3jbSxerTO6Pc/5NtLonfXolkJMaz4KCCpxzfocjIm1QMiQiItHsL8APgZC3nAWUO7djopgCINd7nAusB/DWV3jb78TMppvZXDObW1RU1ImhR6/K5FwSY2PISU3wO5QWHZibTml1PYXlNX6HIiJtUDIkIiJRyczOBLY45z7pyOM652Y45yY55yZlZ2d35KEFaAo5qpJzGZiVRCBCO+aG56QQHwyozLZIN6BJV0VEJFodAUw1s9OBBCAVuANIN7Og1/uTBxR62xcCA4ACMwsCaUBJ14cd3T4vKKcpmMCgrMgbIrddbEyAUf1SmV9QTnV9Y9s7iIhvlAyJiEhUcs79GPgxgJkdC3zfOXexmf0HOA94DLgceNbb5Tlv+UNv/ZtOF4V0qsumTaeobOfelaKs8biscQzMSvIpqvYZl5vGZ+vLWbRhq9+hiMgeKBkSERHZ2Y+Ax8zsVuBT4D6v/T7g32a2AigFvuZTfFGjqKyCk6+5Zae2R+esI7RqKQmxI3yKqn0yk+PIS09kYWEF/f0ORkRapWRIRESinnNuFjDLe7wKOLSFbWqBr3ZpYLKTqrpGtmyrI7RxMXCy3+G0aVxeGi8t3ERastIhkUilAgoiIiLSLawpqQKgaeOSNraMDEOzU0iKi6EsLbJ7sUSimXqGREREpFtYU1xNSnyQmvKNfofSLjEBY0z/VObU5XLiV68ktrF6t22yM9KYef8MH6ITEVAyJCIiIt1AU8ixrrSaA3JS6E6zN43tn8ac1SVknjCdw4buNi0Vr959kw9Rich2GiYnIiIiEW9jRQ31TSEG9Y7cktotSU2MJbRxKYs2VNAUUvFBkUijZEhEREQi3tqSagIGAzIiu6R2SxpXfEBVfROriiv9DkVEdqFkSERERCLeutJq+qYlEBfsfh9dQpuW0ishyILCirY3FpEu1f3+o4iIiEhUqalvYsu2OvIzu1+vEADOMbZ/GutLayirrvc7GhFpRsmQiIiIRLT1ZeEqbAMzu9f1Qs2N6Z9KwGCheodEIoqSIREREYlo60qriQ8G6JMa73co+yw5PsjQ7BQWbdhKfWPI73BExNOuZMjMnjKzM8xMyZOIiIh0Gecca0uqGZCRRMDM73D2y4T8dOoaQyzaoN4hkUjR3uTmbuAiYLmZ3WZmmkpZREREOl15dQOVdY3d93qhZvqlJdI/PYFP15erzLZIhGhXMuSce905dzEwEVgDvG5mH5jZlWYW25kBioiISPRaWxq+Xig/q/snQwAHD8xgW20jy7ds8zsUEWEvrhkysyzgCuDrwKfAHYSTo9c6JTIRERGJeutKq0lLjCUtsWd89zo4K5nMpDg+WVuGc+odEvFbe68Zehp4F0gCznLOTXXOPe6cuw5I2duTmlm6mT1pZkvNbImZHWZmmWb2mpkt9+4z9va4IiIi0nM4jIKy6h4xRG47M2PiwHSKK+tZ5/V6iYh/2tsz9E/n3Gjn3G+dcxsBzCwewDk3aR/OewfwsnNuJDAeWALcCLzhnBsOvOEti4iISJSqScymocn1qGQIYETfXiTHx/DJujK/QxGJeu1Nhm5toe3DfTmhmaUBRwP3ATjn6p1z5cDZwIPeZg8C5+zL8UVERKRnqErqhwEDMhL9DqVDBQMBJgzIYH1pDTUJWX6HIxLVgntaaWZ9gVwg0cwmANtrWqYSHjK3LwYDRcC/zGw88AlwPZCzvdcJ2ATktBLTdGA6QH5+/j6GICIiIpGuMrk/OakJxMfG+B1KhxuXm8bctaUUZY33OxSRqLbHZAg4hXDRhDzg9mbt24Cf7Mc5JwLXOedmm9kd7DIkzjnnzKzFqwqdczOAGQCTJk3SlYciIiI9UEV1A7UJWT2mityu4oIBJuZn8EFDiM/Wl3PQgHS/QxKJSnscJuece9A5dxxwhXPuuGa3qc65p/bxnAVAgXNutrf8JOHkaLOZ9QPw7rfs4/FFRESkm/tgZTFYoMddL9Tc+Lx0YhprueP1L/wORSRqtTVM7hLn3EPAIDP77q7rnXO3t7DbHjnnNpnZejMb4ZxbBpwALPZulwO3effP7u2xRUREpGd4d0UxgaZ6+qYm+B1Kp4kLBsgsW8xbyxLUOyTik7YKKCR79ylArxZu++o64GEzmw8cBPyGcBJ0kpktB070lkVERCQKvbe8mKTqzcQErO2Nu7GMsqVkJMWqd0jEJ3vsGXLO/cPMYoCtzrk/d9RJnXOfAS2V5D6ho84hIiIi3dPakirWlVaTU73B71A6XYxr5BtHD+H3Ly/j03VlTMjXNIsiXanN0trOuSbgwi6IRUREZJ+Y2RHtaZPu4d3lxQAkV/X8ZAjgssMGkZUcx+9fXoZzqg0l0pXaO8/Q+2b2NzM7yswmbr91amQiIiLtd2c726QbeHd5EbnpicQ1bPM7lC6REh/k2uOH8eGqEt7xEkER6Rptldbe7iDv/lfN2hxwfIdGIyIishfM7DDgcCB7l0I/qUDPm5wmCjQ2hfhgZQlnjOvH57Pb3r6nuGhyPve/v5rfvbSUo4b15oqvf5OisordtsvOSGPm/TN8iFCkZ2pXMuSV1xYREYk0cYSL/ATZubDPVuA8XyKS/fJ5QQXbahs5cnhvPvc7mC4UH4zheyeN4DuPf8bz8zdQVFbBydfcstt2r959kw/RifRc7e0ZwszOAMYAO2pcOud+1foeIiIincs59zbwtpk94Jxb63c8sv/eW16MGRwxtDd3+R1MF5s6vj//eGcVf3x1GcntvpJBRPZHu/7SzOzvwAWES2Ib8FVgYCfGJSIisjfizWyGmb1qZm9uv/kdlOy9d5cXMS43jYzkOL9D6XKBgPGjU0ewvrSGsvQD/A5HJCq092uHw51zlwFlzrlfAocB+isVEZFI8R/gU+BnwA+a3VplZglmNsfMPjezRWb2S699sJnNNrMVZva4mcV57fHe8gpv/aDO/ZGiz7baBj5dX85Rw3v7HYpvjjkgm8OHZlHcezy1DU1+hyPS47U3Garx7qvNrD/QAPTrnJBERET2WqNz7h7n3Bzn3Cfbb23sUwcc75wbT7hQ0KlmNgX4HfBn59wwoAy4ytv+KsJfCg4D/uxtJx3ow5UlNIUcRw7L9jsU35gZN505mqZALLNXl/odjkiP195rhl4ws3TgD8A8wpXk7u2soERERPbS82Z2DfA04SQHAOdcq58mXXhCl0pvMda7ba+UepHX/iBwM3APcLb3GOBJ4G9mZk4Tw3SY91YUkxQXw8SB6X6H4qtR/VJJr1jB/IIDOHCXIYML5s/ntHMvaHE/VZoT2XvtrSa3vZzJf83sBSDBObd7vUcRERF/XO7dNx8a54Ahe9rJzGKAT4BhwF3ASqDcOdfobVIA5HqPc4H1AM65RjOrALKA4l2OOR2YDpCfn7+PP050end5MZMHZxIfVFX07OLPqM4aybsripk6vv+O9oaQa7HKHKjSnMi+2GMyZGb/bw/rcM491fEhiYiI7B3n3OB93K8JOMgb/fA0MLIDYpkBzACYNGmSeo3aaX1pNauLq7h0SnTVZ2qtp2fpokUcfer/8f6KEtaWVDEwK9mH6ER6vrZ6hs7awzoHKBkSERHfmdllLbU752a2Z3/nXLmZvUW4QFC6mQW93qE8oNDbrBAYABSYWRBIA0r2O3gBwkPkAI4+ILqKJ7TW0zNv+lQOGpDOwsKtvLu8mAEZSQQC5kOEIj3bHpMh59yVXRWIiIjIfjik2eME4ATC17i2mgyZWTbQ4CVCicBJhIsivEV4wtbHCA+/e9bb5Tlv+UNv/Zu6XqjjvLu8iL6pCQzNTvE7lIgRDAQ4clhv/rdgIws3VHBgXrrfIYn0OO26ZsjMft5SuyZdFRGRSOCcu675sjfs7bE2dusHPOhdNxQAnnDOvWBmi4HHzOxWwuW67/O2vw/4t5mtAEqBr3XgjxDVmkKO91eUcPLoHMzU+9Hc0OxkctMT+WhVKSNyevkdjkiP095qclXNHicAZwJLOj4cERGRDlEF7PE6IufcfGBCC+2rgENbaK8lPOm4dKDLpk1nXU2QioFn8P7zj3DaI7/ZsW7hokWc7GNskcDMOPqA3jw6Zz1z1qjUtkhHa281uT81XzazPwKvdEpEIiIie8nMnid8LStADDAKeMK/iKS9isoq6HfaDaxZVcIZF1xOUtyXH03mTZ/qY2SRo0+vBMb0T+Wz9eVYSnRdUyXS2drbM7SrJMIXlYqIiESCPzZ73Aisdc4V+BWM7J11pdX06RW/UyIkOztsSBZfbN5G7Pg91bYSkb3V3muGFrDzN27ZgK4XEokAd955JytWrPA7jIi0/Xm5/vrrfY4kMg0bNozrrruu7Q27Aefc22aWw5eFFJb7GY+0X5MF2VhRw4T8DL9DiWjJ8UEOGZTJB01jVWpbpAO19yuYM5s9bgQ2N5uQTkR8tGLFCpYv+pT8lCa/Q4k4cQ0BAOrWzvU5ksizrrJnTWppZucDfwBmAQbcaWY/cM496Wtg0qbqpL6EHAzMTPI7lIg3YUA6732+jHe+iOOiyUnEqNS2yH5r7zVDa81sInAk4R6i9whX2BGRCJCf0sRPJm71OwzpRn4zL9XvEDraT4FDnHNbYEfZ7NcBJUMRriq5H8GA0S89we9QIl4wJkDDp89SetRVfF5QzkT1ponst0B7NvJKaz8IZAG9gQfM7GedGZiIiMheCGxPhDwltPM9TvxVldSf3IxEggH9utojtGExA7OSmL2qlKo6DdIR2V/tHSZ3MTDeKyuKmd0GfAbc2klxdRldb9E6XW+xZz3peguRHuBlM3sFeNRbvgB40cd4pB0Ky2uoj08jX0Pk9soxw7N5aPZaPlhZwkmjc/wOR6Rba28ytIHw/EK13nI8UNgpEXWxFStW8NnCJTQlZfodSsQJ1IdrZnyyarPPkUSemGrN9SASCcxsGJDjnPuBmf0/wsO5AT4EHvYvMmmP95YXAbpeaG9lJMdx0IB05q0rZ1xuGn3TNMRQZF+1NxmqABaZ2WuErxk6CZhjZn8FcM59u5Pi6xJNSZnUjDzd7zCkG0lcqi+cRSLEX4AfAzjnngKeAjCzcd461SGOYO98UUywsZrM5Di/Q+l2Dh2cydJN23j7iyLOn5SHmYopiOyL9iZDT3u37WZ1fCgiIiJ7Lcc5t2DXRufcAjMb5EM80k6NTSHeWV5EcmUhZuP9DqfbiQ/GcOSw3ry6eDNLNm5jdP8eVxRFpEu0NxkqAD5wztV0ZjAiIiJ7KX0P6xK7KgjZe/PWlbOttpHcqh4x6t4XI/v2Yn5BBe+vLGZoH807JN3fZdOmU1RWsVt7dkYaM++f0SnnbG8ydBlwj5mVAu8C7wDvOefKOiUqERGR9plrZt9wzv2zeaOZfR34xKeYpB3eWraFYMBIrt7odyjdlplx7IhsHvt4PXNW61pW6f6Kyio4+Zpbdmt/9e6bOu2c7Z1n6HIAM+sPnAfcBfRv7/4iIiKd5DvA02Z2MV8mP5OAOOBcv4KStr21dAuTBmVQsaTB71C6tZzUBMb0T+Wz9eUMitNQOZG91d55hi4xs38QnrzuROBvwFGdGZiIiEhbnHObnXOHA78E1ni3XzrnDnPObfIzNmndxooalm7axnEj+vgdSo9w+NAsgjEBNvc5FOec3+GIdCvt7dn5C7AS+DvwlnNuTWcFJCIisrecc28Bb/kdh7TPrGXhktrHjezDM/6G0iMkxQWZMjiTd5aHeG3xZk4e09fvkES6jfYOk+ttZmOAo4Ffm9lwYJlz7tJOjU5ERER6hOYXRq/vfyzBhCy+ffXXWbRoESf7HFtPcGBeOrMXLueW/y3m6AOySYiN8TskkW6hvcPkUoF8YCAwCEgDQvtzYjOLMbNPzewFb3mwmc02sxVm9riZadIBERGRHmL7hdEnXP0r6tIHMnJQP0655hbqGxr9Dq1HiAkYOVs+Zn1pDXfPWul3OCLdRruSIeA9whPXzQcucM6N2F5UYT9cDyxptvw74M/OuWFAGXDVfh5fREREIsyG8hoamhyDs1QKuqMlV2/i7IP68/dZK1lZVOl3OCLdQruSIefcgc65a5xzjzjnCvb3pGaWB5wB3OstG3A84QINAA8C5+zveURERCSyrCmpIsaMvIwkv0PpkX52xmgSYgP87OmFKqYg0g7tHSaXbWZ/MLMXzezN7bf9OO9fgB/y5VC7LKDcObe9r7wAyG0llulmNtfM5hYVFe1HCCIiItLVVhdXkZuRSFywvYNTZG9k94rnR6eN5MNVJTz9qSa0FWlLe/8TPQwsBQbzZfnSj/flhGZ2JrDFObdPk+E552Y45yY55yZlZ2fvyyFERETEB2XV9ZRVNzC4t4bIdaYLD8lnQn46v/7fEsqr6/0ORySitTcZynLO3Qc0OOfeds5NIzysbV8cAUw1szXAY95x7gDSzWx7dbs8QF9niIiI9CCriqoAGKJkqFMFAsavzxlHeU0Dv3t5qd/hiES09iZD26eH3mhmZ5jZBCBzX07onPuxcy7POTcI+BrwpnPuYsLzQ5znbXY58Oy+HF9EREQi08qiSrJ7xZOaGOt3KD3e6P6pTDtiEI/OWc8na0v9DkckYrU3GbrVzNKA7wHfJ1z44IYOjuVHwHfNbAXha4ju6+Dji4iIiE8aYxLYWFHLUPUKdZnvnHgA/dMS+MlTC6lv3K8ZUUR6rD1OumpmCcDVwDDCBQ3uc84d11End87NAmZ5j1cBh3bUsUVERCRybEsZAMCQ7BSfI+m5Fsyfz2nnXrBTWyA5j2V5x3P3rBV858QDfIpMJHLtMRkiXOK6AXgXOA0YTXh+IBEREZF225YygNSEIL1TNKd6Z2kIOU6+5pbd2v/19Cv87U3j5NF9Gd0/1YfIRCJXW8PkRjvnLnHO/YPw9TxHdUFMIiIi0oNU1jVSndSPodkphKcWlK6Us/lj0pPi+P5/PqehScPlRJprKxnaXjiBZnMAiYiIiLTbO18U4QIxDNUQOV8EQ3X8+tyxLN64lXtmrfQ7HJGI0tYwufFmttV7bECit2yAc86pr1XEZ4WFhVRti+E38/TnKO23dlsMyYWawUC6xquLNhHTWEu/tAS/Q4lap4zpy9Tx/bnzzeWcNDqHUf30niECbfQMOedinHOp3q2Xcy7Y7LH+ikREpNsyswFm9paZLTazRWZ2vdeeaWavmdly7z7Dazcz+6uZrTCz+WY20d+foHtoaArxxtItpFQVEAhoiJyfbp46hrTEWH7wpIbLiWzXVs+QiES43Nxc6ho38pOJW9veWMTzm3mpxOfm+h2G3xqB7znn5plZL+ATM3sNuAJ4wzl3m5ndCNxIePqH04Dh3m0ycI93L3vw3opittU2krdtnd+hdJiWqrYBLFy0iJN9iKctzeONT8lnYe6xHD79N4xy65h5/wyfoxPxl5IhERGJSs65jcBG7/E2M1tCeBqJs4Fjvc0eJDwFxI+89pnOOQd8ZGbpZtbPO4604vnPN5CaECS5eoPfoXSY1qq2zZs+1Ydo2rZrvC8u2MhKm8Cbr85qMakDyM5IU6IkUSHqk6HCwkJiqitIXPqi36FINxJTXUJhoWqKiPQUZjYImADMBnKaJTibgBzvcS6wvtluBV7bTsmQmU0HpgPk5+d3XtDdQG1DE68u2szp4/qy4HMNy4oUx4/sw8aKWhonX8xxUw8jNmb3qyZevfsmHyIT6XptVZMTERHp0cwsBfgv8B3n3E7jTb1eILc3x3POzXDOTXLOTcrOzu7ASLufWcu2UFnXyFnj+/sdijSTEBvDyaNzsF69eeeLIr/DEfFV1PcM5ebmsqkuSM3I0/0ORbqRxKUvkpub0/aGIhLRzCyWcCL0sHPuKa958/bhb2bWD9jitRcCA5rtnue1SSue+3wDvVPiOGxIlt+hyC4GZCbRuHQWC+14BmYlM6yPyp5LdFLPkIiIRCULz/55H7DEOXd7s1XPAZd7jy8Hnm3WfplXVW4KUKHrhVpXWdfIG0u2cMa4fgRbGIYl/mtc+DJ9esXzxpLNVNZp6LdEJ/13EhGRaHUEcClwvJl95t1OB24DTjKz5cCJ3jLAi8AqYAXwT+AaH2LuNl5bvIm6xpCGyEWyUBOnjulLY8jx6qJNhEeFikSXqB8mJyIi0ck59x7hScRbckIL2zvgW50aVA/y3GcbyE1PZGJ+ht+hyB5kJMdxzAHZvLF0C/PWlXPwQP2+JLqoZ0hEREQ6VFlVPe8uL+bMA/tpotVuYEz/VIZlp/DBymI2VtT4HY5Il1IyJCIiIh3qfws20hhyGiLXTZgZJ47qQ6+EWF5csIma+ia/QxLpMkqGREREpEM9MXc9I/v2Ykz/VL9DkXaKj43h9LF9qWlo4pVFm/aunrxIN6ZkSERERDrMog0VzC+o4GuHDCBcsE+6iz6pCRwzPJu1pdWUZI7zOxyRLqFkSERERDrMEx+vJy4Y4JwJuX6HIvtgbG4qI/r2oqj3Qby1bEvbO4h0c0qGREREpEPUNjTx9KeFnDa2L+lJcX6HI/vAzDhhZB/i68r49qOfsqqo0u+QRDqVkiERERHpEC8v3MTW2kYuOGSA36HIfoiNCZBX+BaxMQG+MXMuW2sb/A5JpNNoniERERHpEI/OWcfArCSmDM7yOxTZT8vmfciQ2BRWDjiJw79/P3mFb2E4sjPSmHn/DL/DE+kwSoZEeoB1lTH8Zp6qNu1qc3W48zsnKeRzJJFnXWUMw/0OQnqUVUWVzF5dyg9OGaG5hXqAhpDj3Cuv5fP15cz6IkDiiddx9AHZvHr3TX6HJtKhlAyJdHPDhg3zO4SIVb9iBQDxA/Uc7Wo4eu1Ix3p87npiAsZ5B+f5HYp0oAPz0iivbuDT9eWkJOhjo/Q8elUDMdWlJC590e8wIk6gdisAoQT1OOwqproUyPE7DACuu+46v0OIWNdffz0Ad9xxh8+RiPRs1fWNPDZnPSeNyiEnNcHvcKQDmRlHHdCbbXUNvLu8mNyUgX6HJNKhoj4Z0jejrVuxYhsAw4ZExof+yJKj146IiOe/nxRQUdPA148a7Hco0gkCZpw6pi9PfVrIhtCRfLSqhClDdF2Y9AxRnwzpW/XW6Vt1ERFpSyjkuO+91YwfkM7BAzP8Dkc6STAmwFnj+/PAa/O46oGPmXnVoRw8MNPvsET2W9QnQyIiIrLv3li6hTUl1fztlBGYGZdNm05RWcVu2y1ctIiTfYhPOk5ibAz561+jacoVXH7/x/z7qkOZkK8EWLo3JUMiIiKyz+59dxW56YmcOqYvAEVlFZx8zS27bTdv+tSuDk06QWxTDQ99YwoXzPiQy+6fw8Nfn8yBeel+hyWyzzTpqoiIiOyTBQUVzF5dypVHDCIYo48U0aJvWgKPfmMK6UmxXPTP2XywstjvkET2mf5ziYiIyD65971VpMQHOf+QAX6HIl2sf3oiT3zzMPqnJ3DF/R/zv/kb/Q5JZJ9omJyIiIjstVVFlTz/+QauOnIwqQmxfocjPuiXlsh/vnk4Vz34Md96+BN+9ec5ZJYv22277Iw0Zt4/w4cIRdrW5cmQmQ0AZhKepMUBM5xzd5hZJvA4MAhYA5zvnCvr6vhERESkbXe8sZz4YAzfPGao36FIF1owfz6nnXvBTm0hi8GlHMTm/pPpM/Fkjjkgm5iA7Vj/6t03dXWYIu3mR89QI/A959w8M+sFfGJmrwFXAG84524zsxuBG4Ef+RCfiIiI7MFXvvE9Psk8jqzSRVx66b92WqeqcT1bQ8i1WCDjs2+ezZE/uI9P1pZRXFnHGeP6kRyvAUgS+br8Veqc2whs9B5vM7MlQC5wNnCst9mDwCyUDImIiEScL+KGEBeM4SvnTiUx9tyd1qlqXJRyjiOH9SY7JZ7Xl2zmsY/Xc+rYvuSmJ/odmcge+VpAwcwGAROA2UCOlygBbCI8jK6lfaab2Vwzm1tUVNQ1gYqIiAgAizZUsK3XIA4akE5ibIzf4UiEGdG3F+dPGkBMwPjvJwV8tKoEh7W9o4hPfEuGzCwF+C/wHefc1ubrnHOO8PVEu3HOzXDOTXLOTcrOzu6CSEVERGS7P7/2BYGmOibmp/sdikSo7F7xXHRoPiP79mL26lLWDjiF9aXVfocl0iJfkiEziyWcCD3snHvKa95sZv289f2ALX7EJiIiIi2bs7qU15dsIat0MfHqFZI9iAsGOHlMX04Zk0NdfDon//kd7n9vNU2hFr/rFvFNlydDZmbAfcAS59ztzVY9B1zuPb4ceLarYxMREZGWNTaF+PmzC+mflkBm2RK/w5FuYmTfVIaseZ7JQzL51QuLOe/vH7B88za/wxLZwY+eoSOAS4Hjzewz73Y6cBtwkpktB070lkVERCQCPDx7HUs3beNnZ44m4Br9Dke6kdjGKv51xSH85YKDWFNcxRl/fY87Xl9OfWPI79BEfKkm9x60eiXdCV0Zi4iIiLStpLKOP726jCOGZXHa2L7c6XdA0u2YGedMyOWo4b355fOL+fPrX/DMZ4X87IxRHD+yD+GBQyJdz9dqciIiIhL5/vDKMqrrm7j5rDH60Cr7JSslnr9eOIEHpx1KwOCqB+dy+b8+ZsWWSr9Dkyil2bBERCQqmdn9wJnAFufcWK8tE3gcGASsAc53zpV517veAZwOVANXOOfm+RF3V7ps2nTW1cSyJv80MssW8+2rHwQ0sarsnQXz53PauRfs1r5m2TJyppzDe03jOXHZZjLLlpJVsoB+aQnMvH+GD5FKNFIyJCIi0eoB4G/AzGZtNwJvOOduM7MbveUfAacBw73bZOAe775H21y+ja0HTSOlKcT5555FfPAcQBOryt5pCDlOvuaW3drnTZ/KtRdeRHV9Ix+uLGGhjaYyeyzlmz6hqq6R5PjdP6ZeNm06RWUVu7VnZ6QpgZJ9omRIRESiknPuHW/y7+bOBo71Hj8IzCKcDJ0NzPTmwfvIzNLNrF+zycK7XFd8KCzOOojS6nrOOag/8UGV0pbOkRQX5IRROYwfkM6HK0tY1TSBY/7wFt86bhgXTc7f6bVXVFbRYmL16t03dWXI0oMoGRIREflSTrMEZxOQ4z3OBdY3267Aa9stGTKz6cB0gPz8/E4LtLM/FH64soSSzDGM6Z/KwKzkDjmmyJ70TonnrPH9efb+O+h33KX88vnF3Pvuaq47fhhfOTiP2Bhd6i4dT68qERGRFni9QHs9Q6RzboZzbpJzblJ2dnYnRNb5Sqvq+c7jnxLXsI2jh3fPn0G6r8TaYh75xmQeumoyvXvFc+NTCzj+T7P4z9z1uFYLEovsGyVDIiIiX9psZv0AvPstXnshMKDZdnleW4/TFHJc/9inlFU1kLvhbeKC+qggXc/MOHJ4b5655nDuv2ISaYmx/ODJ+awafDZLN20l5Pb6ewqRFuk/nIiIyJeeAy73Hl8OPNus/TILmwJU+Hm9UGf63ctLeXd5Mb88ewwJdWV+hyNRzsw4fmQOz197JP+49GAs1Mgrizbz0Edr+WLzNpySItlPumZIRESikpk9SrhYQm8zKwB+AdwGPGFmVwFrgfO9zV8kXFZ7BeHS2ld2ecBd4NE565jxziounTKQCw/N36nMnkhXaa0UN0D1osWc9fMH+Gh1KS8t3MSc5DimDMna+/GsIh4lQyIiEpWccxe2suqEFrZ1wLc6NyJ/vbxwIz99egHHjsjm52eN9jsciWKtleKGcDnu4Tm9GNonheWbK/lodQn/W7CR+IFn8trizZw4qo8mBpa9omFyIiIiUe6lBRu57tFPOWhAOndfPFFVuyTiBcwY0bcXl04eyMmjcwgFgnxj5lzOvut93lq2RcPnpN3UMyQiIhLFHpuzjp8+s5CDBqTzrysPISmuZ340qKqs5OknHmqxXbqvQMAY1S+VF391KwOOOJsl9Qdy5b8qSKwponfxZwyKr+bfmoxV9qBn/scTERGRPaprbOK3Ly7lgQ/WcPQB2dxz8USS43vuxwLnHOceOmi39k+eVg9CT9DQ1MT5l1xBU8ixeONW5qwOsj4xm5LqTcxZXcqhgzP9DlEiVM/9ryciIiItWrxhK9994jOWbtrGtCMG85PTRxLU0DjpAWICxrjcNEb168Wiwq28u7ia8//xIUcN7833Th7BQQPS/Q5RIoySIRERkSixsaKGO99cwWNz1pGZHMe9l03ixNE5fofVY7Q2FK+8vLzF9u37SMcLBgKMH5DOxhf+wnnfuZV73l7JOXe9z4mjcvjuSQcwun+q3yFKhFAyJCIi0oOFQo6PVpXwxNz1vDA/PDXS5YcP4voThpOeFOdzdB2rtWQEoLGpsX0HcY5gqI6kpq289+Q94SaMRgJUhuJpJKbVBKa1oXiznwy12A4aptfZAq6Jbxw9hAsn5/PA+6v5xzurOP2v73LsiGy+cdQQDh+apepzUU7JkIiISIS6bNp0isoqWly3cNEiTm5lv4qaBt75ooi3lm3h7WVFlFTV0ys+yCVTBvL1owaTl5HUeUF3gdaSnobGhlaTjtlPfpl0xIeq6N2wkd4NG7n96BrGvfFVsgOVZMdUkhKoI2iO66YB3L/7OSyW4isaiZt3PjWx6WyN78/WhH5UxPfj6NxGkpvKqQqkgT5gR5SU+CDXHj+cS6cM4sEP1zDzwzVcfO9sRvdL5ZIpAzlzfD9SE2L9DlOAhqYQX2zexqaKWrbWNpIYG0NJ1vhOO5+SIRERkQhVVFaxx/lWmquqa+SLzdtYM+AUJt7yGk0hR3pSLMcekM0Jo3I4aXQOCbExLR6rtaRrTwmXn1rvgWm5lyW5qYILRzRxYtnj5NWtJKOpaMe6CQdAQ68GtsXksDbmAGotiYZAPP959hXOPPcrhPuFHAHXRLyrJT5Uw4KF73JE/hCSG0rIq5hLr6ItGI5TzgU2/ZKaQDJFsf0pis2lKLY/IzJC4JwSpAiQlhTLt08YzvSjh/DsZ4Xc/94afvL0An71wiJOG9uPsw/qz2FDs4gPtvy3Ip2nrrGJ4sxx3PvuauqbQiQEA6QmxlJeXU9tr4Gddl4lQyIiIt1UKOT4Yss2Fm/YSkFZDQ6Ij4nj/44ZynEjszloQAYxgbY/gLeWdO2acHUnaY3FDK/5nKE1C+jfsJbpp0JtzecUxg9hYfJkimL7Uxzbj+t+/Ftu+/33d9v/7/NfZ9AlU1o89s/e+phbp9+2YzkQaqBX3Wae+vmFfPfy08luKCS7YQPjK98nSAOnXgbVm35OYdxgCuOHUBg3lKLYXJypaIVfEmJjuOCQfM6fNID5BRU8MXc9z32+gac/LSQlPsgxB2Rz/Mg+TBmaRW56IrDnntrsjDRmqoT3Plu2aRvXPjKPouwJDM1MZGJ+Bv3SEnYMYXzl7vuBizvl3EqGREREuhnnHDEDD+bBD9ewtbaRtMRYDhmUyYi+vZj74Ey+f8olfofoi5RYx5iqjxhTPYfc+tUAbI7N4/1ep3HDP17nou/f2kICsv+9NaFALBWJebxVEOSElKO+PLJrIrNxCx88cjvfPmskufWrGF67AIAaS2JtwggWj2ggqb6E6ris/Y5D9p6ZMX5AOuMHpHPTmaP5YGUxry3ezGuLt/C/BeFr7PIyEpk8OIvlTdmcdMW3SU+M3e06o1fvvsmP8HuElxZs5Hv/+ZykuCADCt7gzBOu3m2bzuxTVTIkIiLSjZRW1fPa4s3ETbmIhNgYjjkgm8G9k6P6IvCMhs1MqHqXb3y9npTyxykJ9uHd1DNZljiRbcEMAD4vepMLu7gnxlkMJbH9+NeiGEZcHv5WO7mpnLy6VQysW8qg2qX886Q6+PhUltX34b3aIbxbM5RVjVmqMueDhNgYjh+Zw/Ejc/j1OY4lm7Yye1Upc1aX8tayLZT2O5yZH64lMTaGvmkJ9E1LoF9qAjmpCX6H3m09MnsdP31mARMGpHPPJQdzxeX/7PIYlAyJiIh0A8455hdU8O6KYmJjjPrZj/K1H98UvUmQc+TVr+CQbW8yqG4pjQR5aHmA+GOvY1PswIi9PqcqJp1lSRNZljQRXIhH/3gjt199EkNqFzMtbjZXpX5EWUxv/jWllr7bFrApZQxoOF2naG3Y2/Yhb2P6pzGmfxrTjhyMc44TvvZNBp/2DTZU1LCpopbVxVVA+KUW6nM8E775JxJri0isKSK2oRJDw+f25B9vr+S3Ly3luBHZ3H3xwSTG+XOdlpIhERGRCNfYFOKNpVtYumkbg7KSOHFUDnc+NHevEqF9rUwXcZzjmNxGvlr8N/LqV1EV6MX7vU5jQfLhXH/Hrdx28iC/I2w/C/B5UYCPe53Ex71OIqlpK0NrFzKsZj7XHVRM7PxpFDUl817NUN6uHcrndbnqMepArV0r96erz+a0cy/YrX35okWc9fXvMzY3DYDahiY2VtSyqaKWDzd+QWXuKMqaRgLh6nX5mUms+OQFSirryEqJ79wfphtxzvGHV5Zx96yVnHlgP24//yDigv4l/EqGREREIlhdYxMvzN9IQVkNUwZncujgzD0mQQvmz2/xg9zCRYv47l1PtbhPtyiU4Bz5FXOYsv5ebji3lm2NJbyZ9v9YmDyFJusZJZGrY1JZkHw4C5IP57abfsQDP/4qw2oWcGZwCeemzKfWkvjvCfX0KpnF2vQpNMZoeFZnaAi5dhUUSYiNYXDvZAb3Tubt3/2D7/zjWUoq69lYUcP6shpWFlVS1/9oDr71deJrS0ip2khy9QYSa7aQk94rKnuMQiHHz59byEMfrePCQ/O59Zyx7Sry0pmUDImIiESoxpgEnppXSHFlHaeMyWFk39Q292nvB7luY3sStO6f5G77nG1xfbjh7TgGX/jTHpMEtaS8zliaNImlSZMIhuoZWLeUYTULOH3QXDKW/oCGQDxr0g9jZdZxrMo8krpg268N6VwBM7J7xZPdK54D89IJOccffnwtx33zFtaVJrKxIosSN5bYGKOwYh3//mgtxx6QzYDM7j3vV3vVNTbxg//M57nPN/DNY4Zw46kjI2KYr5IhERGRCLS+tJq1+acSqqrnzAP7M7h3st8hdS3nOKZ/HRcsuIr+2xawLa4Pbwz5IYtyzmbG7adw60U9NxHaVWMgjpWJB7Iy8UBu/tMS7r/rdwwtmcWw0rcZXjqLJouhIPVgikdWkV6zlvKE/Ii9ZiqaBMxwpes51OvRrW8MUVBezdriaj7fmsxNzywEIK6unJSqDSRXFZJUs7lH9hpV1DTwzX/P5aNVpdx42kiuPmao3yHtoGRIREQkAr25dAuNMfF8ZUIu/b15TqKCcwws/zA8HO6kUrbWxfLGkBtZlHMWTYE4v6PzXWPIWJc+mXXpk3lryA/oW7mYYSVvMbT0bX49eSvMO4+K+P6syTiMNemHsT5tkt8hiycuGGBI7xSG9E5h9u1fZ/qfn2RNSRVrS5IoLMugNHM0wYBRuHUd//5wDceO6NMjeo0Ky2u48l9zWF1cxR1fO4izD8r1O6SdKBkSERGJQJcdNpB/334z/U/+id+hdA3nGFL2Loeuv59+lYvYGt+Xb8+KZ9Hw82hYXQM8sWPTxqZG/+L0WWNTI08/8dAurRnAOZS+eS93/OJaBpV/yKgtLzJ+039psiATTgkQWDeDwtQJbOw1LqquNWrtGjrwv3BIZnIcmclxTMzPoKEpxPqycK/Rktp0bnp2EbCI3PREJg7MYNLADA4emMHIvr0IxnSf6oLvLS/mO49/Sl1DiAenHcrhQ3v7HdJulAyJiIhEIDMjtqnG7zA6neEYXvwGhxbcR5+q5VTE9+f1oT9mUZ+zuO9PJ3PrxcN222f2k86HSCOF49xDB7W45sYnm/jlu7XABGIZx9i4jUxOWMuowDwOXHcvMeZodAGW1ucwv74/R2aVE99QQV1sWpf+BF2ptWvoILKuo4uN+bLXqP7NO7lrxn2880URc9eUMWd1Cc9/vgGApLgYRvbtxYi+qYzq14uRfVP58603UV5avNsx91TWu62y4vurqq6R21/7gvvfX82w7BTuvngiw3N67fdxO4OSIRHpUHfeeScrVqzwOwyAHXFcf/31PkfypWHDhnHdddf5HYaI72JCdYwoepW3zy5mxLIbKU0cyMvDb2ZZ71MIBSL740nLvTOR0GO1a6I0jM0cxZU/XMjtt/2C/vVryK1bSV79Si6o/4yLzmyCOSdS2JjGkvocljbksLQ+hy8a+qiEt48Wzp/PtdOv2rGcAfQKJrOqrIH4oeNZWp7BZ6szCMV45bqzTye+X4C0xNidbstfe4jVxVX0S0sgIXbnOXxaKyv+6t037VfsjU0hnvq0kL+89gUbKmq5eHI+Pz1jFElx7fubXrJoAVUt/G2tW7Rgv+Lak8j+byMish8SE6PoOguRbiK5rogDNz3JgZufJqmhjMWhIP874Ncs730CzvyZdHHvtdw7E8k9VvWBRNYkjGJNwigAgqF6nv/bz7jpylPoW7+OQxvWcWLTFwCEMJZ+zbBlP6M4+QCKkodRnDScqrjIG+LUE7XWm3Xb9Klc96NwsuKco6quieLKOp588B8ceMYlVNQ0ULStjpVFlYQcMOBkjvvjLAAykmLpl5ZIv7QE+qYlUJw5liUbt5ISHyQlIUiv+OB+Db9bVVTJ/+Zv5LGP11NYXsOBeWncceEEDhmUuVfHaWqob/Fv6/bX6/c5trZEVDJkZqcCdwAxwL3Oudt8DqlLRdI36hB536rrG/XuQb8jEdmNCzEhtZyxr13McYkrCBDig9ohPFl5HPc88iKTa7YAj+62m/89LT1XYyCOtwsCnNbrhB1tSU3byKlfR9+GdZSteYMjtn7GqOJXdqyvCaYx8YRKtrzyDVY1ZLG2MZN1jRlsDSWqJ6mLmRkpCeFEpnHZLI773nd3rAs5R2VdI288+g+u/94P2bS1lg3lNWyqqGVDRS3z1pVRlj2RVxdv3umYCbEB3MAzueqBj+mblkC/tAR6p8STFB8kOS6G+GAMdY1N1DWGqKprZEN5LSuKKvlsfRnrS8NDeg8fmsUvzhrNSaNzIqJsdntETDJkZjHAXcBJQAHwsZk955xb7G9k0UvfqouIyP5Iq1nPqKKXGL3lf9xwbg11to7Pk47i85QjqQj2ZiDAI/9r9RqYSO5p6YmqY3qxOnEMqxPH8LMXPuDWR18gvnErvatW0Lt6BdlVy0kseI5zei0m1n35TX1NIJnP/l8NvZb/irLEQZQmDqQscSBbE/rRFIj38SeKTgEzUhNiWTX7Ne69dfNu6/sCxUuWceXvHqKytpHKuka21TVSWdvI6rK1XyZM1Q1tnivYUEl601Z+dcFJHD+yD3kZ3a/6XcQkQ8ChwArn3CoAM3sMOBuImmRI36iLiEh7VVVWtnjdiq/f0LsQYzIamLJuBsNK3iK7egUOY13aIdzwfAkTLv8ljSqP3a3UBVMpTJtIYdpEAH520+vc+ptfktZUQmbjFjIaisho3EJDaDaDy95n7Jbnd9q/KjaLo0/fSsqyn7A1vl/4lhC+T40NgXOaE6mTtFU8IiMpjoyknf8eX33zLV7629UA1DY0UVpVT3V9I1+//kdMOvebxMQYwYARGxMgOS6GYEyAV+++icsO+0an/zydJZKSoVxgfbPlAmDyrhuZ2XRgOkB+fn7XRCYiIhJhnGv5upVPnu7C3hQXIrNmDf22LSC//GMGVHzMDVNLcevvpTD1IGYNvoHlWcdTGd+Xx399HOOUCHUbeywSYQEqgtlUBLNZ7VXpvvHJT5l83qWkWB0DgmXkBcvpF9xK35itJNeWM6RyKcNK3iLGfTn08fKLoPHDI6mOy6QqNovq2Eyq47IIHbSN8RufoCaYTm0wlbpgKrXBVGpjUzHUW9hVEmJjdsxxllhbQm5GyyOGWitfvnzpEoaPHLVbe0dVrOsokZQMtYtzbgYwA2DSpEn6ixAREelszpFcX0xGzVoya9ZyyyEVnLrw/8ipXEJ8UxUQ7gFYlz6Ze57+gDE3PE51XJbPQcv+2dsiEbtvv8273fjDHzP5vP+H4cgKVNHXS5IqF77BQRPGkRlTTWZgG5kxm+kfqOaGA6sJrPpDi2e5+jKofPdItoUS2BqKpzKUwNZQArdM2ELCy9fsaN8aSmRrKJ682AqS6kuoDaZFfJXCSNBaYrOnOZla64GaN31qi+1/uvrsVud+Kq+s3qt4O0IkvSoKgQHNlvO8NhEREdkP5ppICoZIaCgnGKolGKontqmG2FANsU3VnDmwhtGbnyc2VENcYxVJDaUkN5Rw6CkljJp3Hil1RcSFvvyQcthwY1tjFUuzT2VTyhg29RpLaeIgMOPxlVO5UYmQ7KTlxOrX/57FbRdewq5Xtfz8Jz/jjw88SULj1p1u8Y1b+fDxv3HqcYeQEKohIVRNWqiaoa6MccOa6J30CQFCOx/sIuDjUwGoi0mmNpjm9TKlMfjoMgat/N2O5dpgOjXBNCb0rietpoDa2DTqYlKiahjfnhKbzj4HwDvvHtdh52mvSEqGPgaGm9lgwknQ1wi/hEVERKLSl3NuOFKsjt4xVWTHVJIVU8V142s5fOuLxIeqSQjV7Lg/7aIq+s2dSjBUt+MW4xr5zsXAnJNaPM//OxZY8asdy3UxyVTHZlFqUJw0nLXpUyhLzKcscSCliQO56bpv8KMZM1s8VmvXMqkynLRXfWMTDz/zcovrZn8YQ8K5X9mt/cY/3chtv/stca6OhFAVCaFqEkJVPPfIA1z+f98OJ1QNFV5iFb4fl9lA/+LXiG/ctlMSde4ZwLxzAWiyGC+BSuPQk7bQ9PrX2BpKoCKUQEUo0XucyLiUcjKq11ATm05dsFc3KhMvEZMMOecazexa4BXCpbXvd84t8jksERGRnXTZNBBLnufxE7Ywov/DJIcqiHW7VHY6CkLbXqfOEqkLJFEbSKQukMiiEmNNQhr1LkidC1LvYqhzQVbM/4STzjiLRov1bnHUWzwNFs/v/3IPw0+8iGoXS00ojnrv48HsJ2cw+bwx3gnrgeXAcsrKK1pMeAAaGhu63Rw8Emla7kmCNl5HZtRbAvWBBLYS7p18cnksB/U7v8XNb7rteCaecwXmfdmQFqghNVDLpg+f4dCjjyE1UEtqoJZ0r50mx9he1SSEikgIVRGk6cuDfQX49Kte9EZDIJGGmATO/X8VJH96IQ0xiV5bIg2BBHofVs6YVbfTGIijKRBHUyCWJgvfXzSsmpFbXgy3W6y3Po5J2fX0qVwa3sfbtikQR0psiJhQPU0W2716sZwjJlRHbKh2xxc3Y7OayKlfhyP8c4TvjWFpnfdlSsQkQwDOuReBF/2OQ0REpCVdOg2Ec4QcbIrLpzImlcqYNKoCaVR5j3948x/46S2/Bdt5osQbX7yR237/zd0O96d/fUb2BUe3eKpFJcalB4/frX32k6FWEpuW28PrlPRI5GitEAS0nrj/69FnOeaa02kASrwbwI0zbuS23/8wvOAcsa6exFAVCaEqHr/3bq7+wU9JbKggobGCuKYqYptq+GLpSxw0MI/YpmpiQzUkNZQRG6rhlAF1pG9+lhhXv1NRCYDjjwCW/2K3uL56OvD5pbu1X30R8OER4Z+3WZJ0/nkVJH9yLk0W+2XS5a0fdVwpQ5b+mKZA7E77BCZs5dB1/9zR7iwGI8T0UVVMLHwYcJhzGA4jhLkmbpywjaNX/5mYUL2X1ITvDzyhlAMWfHNHorM96bnia8X0+vBIgqG63X6WKy8Eiv68W/txJ+77hLBtiahkSEREJMJ13TQQo6dy/ivpfPcnu3/4AdhWb7slQiKyq33sZWqLGQ0WT0Mgnq1k8soaKH+r2FuZ5N1g9gvG5ISWvmiYweTzwuWoDUcsTcRZE7HWyKKX/s1Pf/w9Ylzjlzca+fe9M/j6tMt2LG9f98rzzzF0/CHEWhPx1kSsNRFLE+Vrt5Jryd5yPXFWQ5w1EmtN9E9qIKt6BcFQPTGugZhQPTGhBg4cW03s+t0rvR17KLDmLy0+FVPGQl3Bf6h3MdS7IPWEe6PTYhswHHXBXlQFsmkMxNMYiGf2568z/sSv7FhuDMTTEEigMRDPv//6Wy64+GLvyF/2D/3n9f/y733/be2RkiEREZH2a9c0ECISbVqrvrf3vasvPwHlwezd2l9ZG8NxieN2a//Lp//jtgt3Hwp44303ctvvr27xHOEKf2e3ENcMppz3jR3JWYyFCDnj42cf5OCzryDkpSchDOeMEMb7T/6T236/+2jhG+/+MZPP2703et6bMdzy9W+3GNezK//AIYljd2ufVfhCi9t3BHOu+3Znm1kRsNbvOHq43kBxm1uJRC69hjvfQOfc7u/cPZCZnQec6pz7urd8KTDZOXdts212zIcHjACW7eVp9JrVcwB6DrbT86DnAPb/OWj1fapb9wxFy5uvn8xsrnNukt9xiOwrvYalg7U5DUTz+fD2hV6zeg5Az8F2eh70HEDnPgcabCwiItJ+O6aBMLM4wtNAPOdzTCIiso+6dc+QiIhIV9I0ECIiPYuSIWnLPg/1EIkQeg1Lh+qCaSD0mtVzAHoOttPzoOcAOvE56NYFFERERERERPaVrhkSEREREZGopGRIWmRmp5rZMjNbYWY3+h2PyN4ys/vNbIuZLfQ7FpH2isb/vWY2wMzeMrPFZrbIzK732jPN7DUzW+7dZ/gda2czsxgz+9TMXvCWB5vZbO/18LhXtKPHMrN0M3vSzJaa2RIzOyzaXgdmdoP3d7DQzB41s4RoeB209J7d2u/ewv7qPR/zzWzi/pxbyZDsxsxigLuA04DRwIVmNtrfqET22gPAqX4HIdJeUfy/txH4nnNuNDAF+Jb3c98IvOGcGw684S33dNcDS5ot/w74s3NuGFAGXOVLVF3nDuBl59xIYDzh5yJqXgdmlgt8G5jknBtLuEjL14iO18ED7P6e3drv/jRguHebDtyzPydWMiQtORRY4Zxb5ZyrBx4Ddp+mWCSCOefeAUr9jkNkL0Tl/17n3Ebn3Dzv8TbCH4BzCf/sD3qbPQic40uAXcTM8oAzgHu9ZQOOB570NunRz4GZpQFHA/cBOOfqnXPlRNnrgHBxs0QzCwJJwEai4HXQynt2a7/7s4GZLuwjIN3M+u3ruZUMSUtygfXNlgu8NhER6TxR/7/XzAYBE4DZQI5zbqO3ahOQ41dcXeQvwA+BkLecBZQ75xq95Z7+ehgMFAH/8oYK3mtmyUTR68A5Vwj8EVhHOAmqAD4hul4HzbX2u+/Q/5VKhkRERMR3ZpYC/Bf4jnNua/N1Llz6tseWvzWzM4EtzrlP/I7FR0FgInCPc24CUMUuQ+Ki4HWQQbjXYzDQH0hGw72Bzv3dKxmSlhQCA5ot53ltIiLSeaL2f6+ZxRJOhB52zj3lNW/ePvTFu9/iV3xd4AhgqpmtITw88njC18+ke8OloOe/HgqAAufcbG/5ScLJUTS9Dk4EVjvnipxzDcBThF8b0fQ6aK61332H/q9UMiQt+RgY7lUviSN88d5zPsckItLTReX/Xu/amPuAJc6525uteg643Ht8OfBsV8fWVZxzP3bO5TnnBhH+vb/pnLsYeAs4z9uspz8Hm4D1ZjbCazoBWEwUvQ4ID4+bYmZJ3t/F9ucgal4Hu2jtd/8ccJlXVW4KUNFsON1e06Sr0iIzO53w+OUY4H7n3K/9jUhk75jZo8CxQG9gM/AL59x9vgYl0oZo/N9rZkcC7wIL+PJ6mZ8Qvm7oCSAfWAuc75zr8UVRzOxY4PvOuTPNbAjhnqJM4FPgEudcnY/hdSozO4hwAYk4YBVwJeEv7qPmdWBmvwQuIFxl8VPg64Svh+nRr4OW3rOBZ2jhd+8lin8jPISwGrjSOTd3n8+tZEhERERERKKRhsmJiIiIiEhUUjIkIiIiIiJRScmQiIiIiIhEJSVDIiIiIiISlZQMiYiIiIhIVFIyJNJBzCzHzB4xs1Vm9omZfWhm5/odl4iI9Cxm1mRmn5nZQjP7j5kldfH5HzCz89recqd9rjazy7zHV5hZ/86JTmTvKBkS6QBezftngHecc0OccwcTnjgvb5ftgi3sLiIisjdqnHMHOefGAvXA1X4HtCdmFnTO/d05N9NrugJQMiQRQcmQSMc4Hqh3zv19e4Nzbq1z7k7vG7DnzOxN4A0zyzSzZ8xsvpl9ZGYHApjZzWb2/e37e9/4DfJuS83sYTNbYmZPdvW3gCIiErHeBYaZ2VlmNtvMPjWz180sB8DMFphZuoWVNOudmWlmJ3nvUc+a2SwzW25mv/DWDzKzhdtPYmbfN7Obdz25mf3czD723rNmeF8O4h3vL2Y2F7h++3uc16M0CXjY6906w8yeaXa8k8zs6c57ukR2pmRIpGOMAebtYf1E4Dzn3DHAL4FPnXMHEp5lfeYe9ttuBHC3c24UsBW4Zj/jFRGRbs4bbXAasAB4D5jinJsAPAb80NvsfeAIwu9Tq4CjvPbDgA+8x4cCXwEOBL5qZpP2Ioy/OecO8XqpEoEzm62Lc85Ncs79aXuDc+5JYC5wsXPuIOBFYKSZZXubXAncvxfnF9kvSoZEOoGZ3WVmn5vZx17Ta865Uu/xkcC/AZxzbwJZZpbaxiHXO+fe9x4/5B1DRESiU6KZfUY4qVgH3Ed4WPYrZrYA+AHh5AfCPUdHe7d7gHFmlguUOeeqvG1ec86VOOdqgKfYu/eY47weqQWER0mMabbu8bZ2ds45wu+Jl5hZOuEk7aW9OL/IftH1CyIdYxHhb9UAcM59y8x6E36jAqhqca+dNbLzFxQJzR67XbbddVlERKJHjdersoOZ3Qnc7px7zsyOBW72Vr0DfAvIB34KnAucRzhJ2q6l95g9vSdtP2cCcDcwyTm33htG13y79rz3AfwLeB6oBf7jnGts534i+009QyId400gwcz+r1lba9f1vAtcDOC9YRU757YCawgPp8PMJgKDm+2Tb2aHeY8vIjwcQkREZLs0oNB7fPn2RufceqA3MNw5t4rw+8f3CSdJ253kXc+aCJxDeGjdZqCPmWWZWTw7D3/bbnviU2xmKYSTrPbYBvRqFuMGYAPwM8KJkUiXUTIk0gG8bv5zgGPMbLWZzQEeBH7UwuY3Aweb2XzgNr580/ovkGlmi4BrgS+a7bMM+JaZLQEyCA91EBER2e5m4D9m9glQvMu62Xz5nvIukMvOX6rNIfweNB/4r3NurnOuAfiVt+41YOmuJ3TOlQP/BBYCrwAf77pNKx4A/u4VUEj02h4mPCR8STuPIdIhLPwZTkQilZkNAl7wLk4VERHpMGZ2BeFhbtf6HMffCBcXus/POCT66JohEREREfGN15tVBXzP71gk+qhnSEREREREopKuGRIRERERkaikZEhERERERKKSkiEREREREYlKSoZERERERCQqKRkSEREREZGopGRIRERERESi0v8H4UB9XJqypT8AAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA0MAAAEjCAYAAADwq9qcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABe0ElEQVR4nO3dd3zV5fn/8dd1TvaGECADCFvZKjir4sINaq2jzjqw1Vq7ta1+O2yt/traWq1WHFVa66h171FxK0tlCoSdsLJDdnJy//44JxgggQSSfE5y3s/H4zzO+ezrnJzk5Dr3fV+3OecQERERERGJND6vAxAREREREfGCkiEREREREYlISoZERERERCQiKRkSEREREZGIpGRIREREREQikpIhERERERGJSEqGRESk25nZ5WbmzOzybrzmHDPTfBIiIrKDkiERkQhiZpPN7B9mtsbMasyswswWm9kfzCzb6/hERES6k5IhEZEIYEF3APOAi4Evgb8CDwHVwI+BlWZ2rndRdrlLgQO9DkJERMJHlNcBiIhIt7gF+CmwDjjDObe05UYz+zrwL+AJMzvJOfdO94fYtZxzG7yOQUREwotahkREejkzyyWYDDUA03dNhACcc/8FfgD4gfvMzLfLOc43s7fNrMTMas1snZk9bmaTW7leu/dt5VhnZnPa2PZIaHvuLuunh6632czqzGyTmb1rZtfusl+rY4bMzGdm3zazeWZWaWZVocff2fV1aBmjmfUzs1ktrrvUzL61t+coIiLhQy1DIiK937cI/r1/yjm3eA/7PQj8HzAaOBZ4x8wM+AdwGVAEPAMUAjnAccAKYD4Eu+K1d9/OYmYzgfuBLcCLoev2ByYQfN73tuM0/wS+CWwk+Bo44OzQsV8DLmrlmDTgQ6AeeBqIBb4BPGxmTc65R/f5SYmISLdRMiQi0vt9LXT/1p52cs41mtk7BBODo4B3gKsJJjfzgJOcc+XN+5uZn2Di0awj+3aWawgmJBOdc9tabjCzfns72MwuJPh8PwOOcc5VhtbfDLwLfNPMXnbO/XuXQycSHG91jXMuEDrmL8Ai4EZAyZCISA+gbnIiIr1fZuh+Yzv2bd4nK3R/fej+mpbJDYBzLuCc29xiVUf27UyNBLsA7sQ5V9SOY68I3d/UnAiFjq0imNQAXNXKcdXAD5sTodAxywi2Fh1oZkntjF1ERDykZEhERFplZonAOGCrc+6zztq3kz0GJADLzOzPZnaWmWV04PiDgSZgTivb3gUCwEGtbFvlnKtoZX1zMtmnAzGIiIhHlAyJiPR+W0L3g9qxb/M+mwiOiwEoaMdxHdm30zjn7iTYNW898D3gWWCrmb3TnoINQCpQ4pyrb+XcjQTHIKW2clxZG+drDN3723FtERHxmJIhEZHe74PQ/Yl72ik0rmdqaPFDvvqHvz2TsXZk3z1xtD2eNa3VA5yb7Zw7HEgHTic4lucY4PV2tBKVA33NLHrXDWYWBfQDWmsBEhGRXkDJkIhI7/cIwe5eZ5vZ2D3sdwXBsUIrgHdD42aWAAPMrLWuYjt0ZN+9KKWVFqxQojZpLzGUOedecc5dTfA59yWYFO3JZwQ/C1vb7xiCLTwL9xq1iIj0SEqGRER6OefcGuA2IBp4wczG7LqPmZ0F3EUwafqOc64ptOmvofv7zSx1l2N8ZpbZYlVH9m3LXGCwmU3bZf3NwJBW4j4uVNJ7V82V66r3cr2HQ/e/N7OEFudNAG4PLT6016hFRKRHUmltEZHI8CsgEfgh8IWZvQ4sJZggHQkcBtQAFzrn3mlx3IPA0cAlwCoze57g3EFZwPEEk4lf7cO+bfkjcDLwvJk9CZSE4htKsMjB1F32fxaoNLNPgHWAhWKYAixg7+XE/21mM4DzgKVm9hzBrnpnha75pHPusb3ELCIiPZSSIRGRCBBq6flRKMG4jmAXsBMItgStA/4E/MU5l7/LcQ64NJQ8zSSYNMQCm4H3gRf2Zd89xPl2qJXq/4ALgCrgTeB84NetHHITweTpYOA0oJZgMYUbgfucc7uV3G7FhQQrx11BcN4igOUEX5P72nG8iIj0UBb87BIREREREYksGjMkIiIiIiIRScmQiIiIiIhEJCVDIiIiIiISkZQMiYiIiIhIRFIyJCIiIiIiEUnJkIiIiIiIRCQlQyIiIiIiEpGUDImIiIiISERSMiQiIiIiIhFJyZCIiIiIiEQkJUMiIiIiIhKRlAyJiIiIiEhEivI6gP3Rr18/l5ub63UYIiIRbcGCBUXOuQyv4whH+pwSEfHenj6nenQylJuby/z5870OQ0QkopnZeq9jCFf6nBIR8d6ePqfUTU5ERERERCKSkiEREREREYlISoZERERERCQi9egxQyIiIiIi0n4NDQ3k5+dTW1vrdSidLi4ujpycHKKjo9t9jJIhadPUqVN3PJ4zZ45ncYjsK72HRUREdpafn09ycjK5ubmYmdfhdBrnHMXFxeTn5zN06NB2H9dl3eTM7GEz22ZmS1qs62tmb5rZqtB9n9B6M7O/mlmemS0ys4O7Ki4RERERkUhVW1tLenp6r0qEAMyM9PT0Drd4deWYoUeAU3ZZdxPwtnNuJPB2aBngVGBk6DYTuK8L45J2aPmNemvLIuFO72EREZHW9bZEqNm+PK8uS4acc+8BJbusngE8Gnr8KHBWi/WzXdAnQJqZZXZVbCIiIiIiIt1dTW6Ac25z6PEWYEDocTawscV++aF1uzGzmWY238zmFxYWdl2kIiIiIiIRID8/nxkzZjBy5EiGDx/ODTfcQH19fYfOMWfOHM4444x9uv5VV13FsmXL9unY/eVZAQXnnDMztw/HzQJmAUyePLnDx4uIiIg0u/SKmRSWlu+2PqNPKrMfnuVBRCLdyznHOeecw3e+8x2ef/55AoEAM2fO5Be/+AV/+MMfuiWGBx98sFuu05ruToa2mlmmc25zqBvcttD6AmBQi/1yQutERERE9ltbSc+SpUv54d+e2W39G/fe0h1hiXjuf//7H3FxcXzrW98CwO/38+c//5mhQ4fyq1/9il/+8pe89tpr+Hw+rr76aq6//nrmzZvHDTfcQFVVFbGxsbz99ts7nfNXv/oVSUlJ/PjHPwZg3LhxvPTSS2RkZHDeeeeRn59PIBDglltu4fzzz2fq1Kn88Y9/ZPLkyTz++OPcdtttOOc4/fTTueOOOwBISkrihhtu4KWXXiI+Pp7nn3+eAQMGsL+6Oxl6AbgMuD10/3yL9d81syeAw4DyFt3pREQ6bPr06bzwwgs7lmfMmOFhNCLitcLScqZde+tu6xfOnO5BNCLhY+nSpRxyyCE7rUtJSWHw4ME8+OCDrFu3js8//5yoqChKSkqor6/n/PPP58knn2TKlClUVFQQHx/frmu99tprZGVl8fLLLwNQXr7zFxSbNm3ixhtvZMGCBfTp04dp06bx3HPPcdZZZ1FVVcXhhx/O7373O37605/ywAMPcPPNN+/38+/K0tqPAx8Do80s38yuJJgEnWRmq4ATQ8sArwBrgDzgAeDaropLRCLDW2+9tdPym2++6VEkIiIiPdOcOXO45ppriIoKtp/07duXFStWkJmZyZQpU4Bg4tS8fW/Gjx/Pm2++yY033sj7779PamrqTtvnzZvH1KlTycjIICoqiosuuoj33nsPgJiYmB1jkg455BDWrVvXKc+xK6vJXeicy3TORTvncpxzDznnip1zJzjnRjrnTnTOlYT2dc6565xzw51z451z87sqLhGJDCeeeOJOyyeddJJHkYiIiISvMWPGsGDBgp3WVVRUsGHDhn0+Z1RUFE1NTTuWm+f+GTVqFAsXLmT8+PHcfPPN/OY3v2n3OaOjo3eUzvb7/TQ2Nu5zfC11dzU5EZFuccwxx+xxWUREROCEE06gurqa2bNnAxAIBPjRj37E5Zdfzsknn8z999+/I/EoKSlh9OjRbN68mXnz5gGwffv23RKT3NxcFi5cCMDChQtZu3YtEOwGl5CQwMUXX8xPfvKTHfs0O/TQQ3n33XcpKioiEAjw+OOPc+yxx3bp8/esmpyISFe65557dlq+++67eeSRR7wJRkS6RVtFEiBYKGFaN8cj0hOYGc8++yzXXnstt956K01NTZx22mncdttt+P1+Vq5cyYQJE4iOjubqq6/mu9/9Lk8++STXX389NTU1xMfH79Y1/etf/zqzZ89m7NixHHbYYYwaNQqAxYsX85Of/ASfz0d0dDT33XffTsdlZmZy++23c9xxx+0ooNDVY36VDIlIr7RrX+LO6lssvYuZrQO2AwGg0Tk32cz6Ak8CucA64DznXKkF+2fcBZwGVAOXO+cWtnZe8UZbRRJAhRJE9mTQoEG8+OKLrW678847ufPOO3daN2XKFD755JOd1k2dOpWpU6cCEB8fzxtvvLHbuXJzczn55JN3Wz9nzpwdjy+88EIuvPDC3faprKzc8fjcc8/l3HPPbfP5dIS6yYlIr7TrYM72Du6UiHScc26Sc25yaPkm4G3n3Ejg7dAywKnAyNBtJnDfbmcSEZEeRcmQiPRKu/Zf7qyBlhIRZgCPhh4/CpzVYv3sUNGfT4C00Jx5IiLSQ+mrUhHplZKSknZqUk9KSvIwGgljDnjDzBxwv3NuFjCgxVx3W4DmWf2ygY0tjs0PrdtpXjwzm0mw5YjBgwd3YejSlRYvWsSpZ5/f6raMPqnMfnhWN0ckIl1ByZCI9EoNDQ17XBYJ+ZpzrsDM+gNvmtmXLTc651woUWq3UEI1C2Dy5MkdOlbCR0OTa3P80Rv33tLN0YhIV1E3ORHplTIzM/e4LALgnCsI3W8DngUOBbY2d38L3W8L7V4ADGpxeE5onYiI9FBKhkSkV9q6desel0XMLNHMkpsfA9OAJcALwGWh3S4Dng89fgG41IIOB8pbdKcTEZEeSMmQiPRKJ5100o6Zqs2MadM0w4jsZgDwgZl9AcwFXnbOvQbcDpxkZquAE0PLAK8Aa4A84AHg2u4PWUSk+wwaPAQz67TboMFD9nrN1157jdGjRzNixAhuv/32ve6/vzRmSER6pcsuu4xXX32VhoYGoqOjufTSS70OScKMc24NMLGV9cXACa2sd8B13RCaiEhYyN+4gTvfWNFp5/vhtNF73B4IBLjuuut48803ycnJYcqUKUyfPp0xY8Z0Wgy7UsuQiPRK6enpnHrqqZgZp556Kunp6V6HJCIiInswd+5cRowYwbBhw4iJieGCCy7g+eef3/uB+0HJkIj0WtOnTychIYEzzzzT61BERERkLwoKChg06Ks6NTk5ORQUdG2dGiVDItJrvfDCC1RXV/Piiy96HYqIiIiEISVDItIrFRcX89prr+Gc49VXX6W4uNjrkEQkzNQ2BPANHM2mshpq6gNehyMS8bKzs9m48au5rfPz88nOzu7SayoZEpFe6dFHH90x0WpDQwOzZ8/2OCIRCRdl1fU893kB97+3hthjZ/KfBfk8+MEa3li6hfIaTdAs4pUpU6awatUq1q5dS319PU888QTTp0/v0muqmpyI9EpvvvkmweJf4JzjjTfe4Ac/+IHHUYmI11Zu3c6by7biM+PQ3L68/4/fct4Pfsv6omqWbCpnTVEVp4wd6HWYImEhZ9DgvVaA6+j59iQqKop77rmHk08+mUAgwBVXXMHYsWM77fqtXrNLzy4i4pEBAwawbt26nZZFJLKt2rad15ZuITMljlPHZZIUF8W721aTm55Ibnoikwan8dKiTTz/xSb8g3arui4ScTZuWN/t1zzttNM47bTTuu166iYnIr1Syz7HrS2LSGSxPjm8tmQLA1PimDEpm6S43b8PTo2P5rzJg8hMjSP6sG+ysaTag0hFpDspGRKRXikQCOxxWUQiR31jEzFHXExCTBTTJ2YRE9X2vz/Rfh/TJ2bhKgt5ZfFmKmsbuzFSEeluSoZERESkV/sgrwhLSufksQOIi/bvdf+4aD/1HzxCY5Pj9WVbaAqNPxSR3kfJkIiIiPRahdvrWFxQTmDVB+T0SWj3ca6yiKmjM8gvreGLjWVdF6CIeErJkIj0SlFRUXtcFpHezznHeysLiYv20bDkjQ4fPyYzhSHpCXyypoTKOnWXE+mNlAyJiIhIr7SuuJr8shoOH5oODTUdPt7MmDoqg4BzvL+ysAsiFBGvKRkSkV6psbFxj8si0rs555i7toSUuCjGZafu83nSEmKYPKQPK7dVsqms4wmVSE+WOzgHM+u0W+7gnL1e84orrqB///6MGzeuG56h5hkSERGRXqigrIYtFbUcNzoDv8/261yHDOnD4oJyPlxdxLkH7/2fOZHeYv3GAtz/buu089nxP9/rPpdffjnf/e53ufTSSzvtunuiliERERHpdeatKyUhxs+YzJT9Ple038ehQ/uyqayWtcVVnRCdiLTlmGOOoW/fvt12PSVDIiIi0qsUV9axoaSaSYPSiPJ3zr8647JSSY2P5tM1JajQtkjvoWRIREREepXFBeX4zRibtf+tQs38PmPykD5s215HVUJmp51XRLylZEhERER6jfrGJpZv3s7IAUkkxHTu0OgDMpNJjPFT3Ld7BnaLSNdTMiQiIiK9xoqt26kPNDF+PyrItSXK5+OgwX2oTszkc03EKtIreFJNzsx+AFwFOGAx8C0gE3gCSAcWAJc45+q9iE9Eer6oqKidymlr0lWRyLBsUwXpiTFkpsZ1yfnHZ6fy0YoC7puTx/2XTO6Sa4iEiyGDsttVAa4j59ubCy+8kDlz5lBUVEROTg6//vWvufLKKzsthl11+38HZpYNfA8Y45yrMbOngAuA04A/O+eeMLO/A1cC93V3fCLSO2ieIZHIUxedzJaKWr42oh9m+1dOuy0xUT76lK7g9aWx5G3bzoj+yV1yHZFwsG5Dfrdf8/HHH+/W63nVTS4KiDezKCAB2AwcDzwd2v4ocJY3oYlIb7DrP0Jd9Y+RiISP8pThGDB6YNcmKH3LlhMX7ePv767p0uuISNfr9mTIOVcA/BHYQDAJKifYLa7MOdf81W0+0Go7mpnNNLP5Zja/sLCwO0IWkR7IObfHZRHpXZqaHBWpwxjcN4Gk2K7t+BIVqOP8yYN4/vMCCrfXdem1RKRrdXsyZGZ9gBnAUCALSAROae/xzrlZzrnJzrnJGRkZXRSliPR0ahkSiSzz15fSEJ3EAZnd023t0iNzaQg4npi7oVuuJ9KZeusXhPvyvLzoJncisNY5V+icawCeAY4C0kLd5gBygAIPYhORXkItQyKR5eVFm7CmRob1S+qW6w3PSOLokf3416fraQg0dcs1RTpDXFwcxcXFve5z0TlHcXExcXEdK57iRXmlDcDhZpYA1AAnAPOBd4BzCVaUuwx43oPYREREpIcJNDleWbKFpKoCYqIO7LbrXn5kLlc+Op83lm7l9AmaiFV6hpycHPLz8+mNw03i4uLIycnp0DHdngw55z41s6eBhUAj8BkwC3gZeMLMfhta91B3xyYiIiLh79IrZlJYWr5juSp+AIWDT6Zp2Qdw1ondFsfU0f0Z1DeeRz9ep2RIeozo6GiGDh3qdRhhw5OJN5xzvwR+ucvqNcChHoQTNu6++27y8vK8DqNNN9xwg6fXHzFiBNdff72nMcjehfP72Ov3MOh9LNIZCkvLmXbtrTuW31mxjU2bKti+cUm3xuH3GZccPoTbXvmS5Zsr+P0vfrxTktYso08qsx+e1a2xiUj7aBZCaVV0dDQNDQ07LYv0JFlZWWzatGnHcnb23id6E5GexznH6m2V5KYnsjjQ/XO1nzd5EHe+uZLZH6/bLUlr9sa9t3R7XCLSPkqGwki4fVs8derUHY/ffPNN7wKRHiWc3sfN72Ez47HHHvM2GAlbZuYnOHa1wDl3hpkNJTh+NZ3g1A+XOOfqzSwWmA0cAhQD5zvn1nkUtoRsraijqj7A8P6JLPbg+mkJMZw1KZtnPytgsC/GgwhEZH94Nemq9ADNrUG5ubneBiKyj7KysgD44Q9/6HEkEuZuAJa3WL4D+LNzbgRQClwZWn8lUBpa/+fQfuKx1YWV+Axy0xM9i+GSI4ZQ29BEecowz2IQkX2jZEjaNGbMGCZOnMgjjzzidSgi+yQjI4OJEydy5plneh2KhCkzywFOBx4MLRtwPPB0aJdHgbNCj2eElgltP8E0gZXnVhdWkp0WT1y037MYxmalctDgNErTRvW6csUivZ2SIRERiWR/AX4KNE8Ukw6UOecaQ8v5QPOAs2xgI0Boe3lof/FIaVU9pdUNDM/onrmF9uSiw4ZQH5tGQVmN16GISAcoGRIRkYhkZmcA25xzCzr5vDPNbL6Zze+N83iEkzVFVQAMzfCui1yzMyZk4gvUsSh/92pyIhK+lAyJiEikOgqYbmbrCBZMOB64C0gzs+YCQzlAQehxATAIILQ9lWAhhZ0452Y55yY75yZnZGR07TOIcOuKq0hPiiElzvuKp3HRftLKV7O6sJKqusa9HyAiYUHJkIiIRCTn3M+ccznOuVzgAuB/zrmLgHeAc0O7XQY8H3r8QmiZ0Pb/OQ0Q8Ux9YxObymo8LZywq7SylTQ5WLq5wutQRKSdlAyJiIjs7Ebgh2aWR3BM0EOh9Q8B6aH1PwRu8ig+ATaWVtPkIDc9wetQdohtqCCnTzxLCsppUp4s0iNoniEREYl4zrk5wJzQ4zXAoa3sUwt8o1sDkzatK6oixu8jMzXe61B2MiE7lVeWbGF9cTVD+4VPq5WItE4tQyIiItKjOGBdcTWD+sbj94VXdfNhGUkkxPhZXKBCCiI9gZIhERER6VHqYtKorGsMq/FCzfw+Y1xWKmuLqqioafA6HBHZCyVDIiIi0qNUJQanfhoSRuOFWhqbnYIBSzapdUgk3CkZEhERkR6lMjGL9KQYksOgpHZrUuKiye2XyNJNFQSaVEhBJJwpGRIREZEeo7KukeqE/mHZRa6l8dmpVNcHWFNY6XUoIrIHSoZERESkx/gwrwjMH1YltVszJD2BlLgoFqmQgkhYUzIkIiIiPcacFYX4AvVhV1J7Vz4zxmWnkl9aQ11MitfhiEgbNM+QiIiIhKVLr5hJYenOLSt5Q88mULQBv2+sR1G135jMFD5ZU0xZ6iivQxGRNigZEhERkbBUWFrOtGtv3bFcXtPA8o/W0bBlpYdRtV9ibBQjMpLIaxxOTX2A+Bi/1yGJyC6UDImIiEiPsLGkGoCmras8jqT9xueksnJbJcdffQtpFat3257RJ5XZD8/yIDIRASVDIiIi0kNsLK0mMcZPTcVWr0Npt+y0eJrKt9A0+nimTbl8t+1v3HtL9wclIjuogIKIiIiEPeccG0tqyOkb3lXkdmVmNK7+mK0VdWyrqPU6HBHZhZIhERERCXvFVfXUNAQY1Ce8q8i1JrBuPlE+Y7HKbIuEHSVDIiIiEvaaxwsN6mEtQwA01DJqQDIrtm6nrjHgdTQi0oKSIREREQl7G0trSI2PJiUu2utQ9sn4nFQaAo4vN2/3OhQRaUHJkIiIiIS1piZHQWkNg/r2vC5yzQamxNE/OZbFBeU457wOR0RClAyJiIhIWNu6vZb6QBOD+/TALnItjM9Opbiqnk3lKqQgEi7alQyZ2TNmdrqZKXkSERGRbrWxpAaAnB6eDI0emEyM36dCCiJhpL3Jzb3AN4FVZna7mY3uwphEREREdthYUk1GUizxMX6vQ9kv0X4fB2Ymk7e1kur6Rq/DERHamQw5595yzl0EHAysA94ys4/M7Ftm1jNHMoqIiEjYawg0sbm8tkePF2ppfHYqAedYtqnC61BEhA6MGTKzdOBy4CrgM+AugsnRm10SmYiIiES8TWU1BJxjUA/vItcsPSmWnD7xfJFfTqBJhRREvNbeMUPPAu8DCcCZzrnpzrknnXPXA0kdvaiZpZnZ02b2pZktN7MjzKyvmb1pZqtC9306el4RERHpXTaW1uAzyErrHS1DAAcNSqOyrpG8bZVehyIS8drbMvSAc26Mc+73zrnNAGYWC+Ccm7wP170LeM05dwAwEVgO3AS87ZwbCbwdWhYREZEItrGkmoEpccRE9Z4aTkP7JZIWH81nG0tR25CIt9r7l+W3raz7eF8uaGapwDHAQwDOuXrnXBkwA3g0tNujwFn7cn4RERHpHQK+GLZtr2NQ397RRa6ZmTFpcBpbK+qoic/wOhyRiBa1p41mNhDIBuLN7CDAQptSCHaZ2xdDgULgH2Y2EVgA3AAMaG51ArYAA9qIaSYwE2Dw4MH7GIKIiIiEu6qE4L8CvWW8UEtjMlP4eHUxJX3GeB2KSETbYzIEnEywaEIOcGeL9duBn+/HNQ8GrnfOfWpmd7FLlzjnnDOzVluOnXOzgFkAkydPVuuyiIhIL1WdkEmUzxiYGud1KJ0u2u9jfHYq8xsGsbGkute1fon0FHvsJuece9Q5dxxwuXPuuBa36c65Z/bxmvlAvnPu09Dy0wSTo61mlgkQut+2j+cXERGRXqAqYSDZfeLx+2zvO/dAE3PSAPjHh+s8jUMkku0xGTKzi0MPc83sh7ve9uWCzrktwMYWE7eeACwDXgAuC627DHh+X84vIiIiPd+W8lrqY9N6ZRe5ZklxUaRUrOWJeRsoq673OhyRiLS3AgqJofskILmV2766HnjMzBYBk4DbgNuBk8xsFXBiaFlEREQi0EeriwB6zWSrbUkvWUp1fYDZH6/3OhSRiLTHMUPOufvNzA9UOOf+3FkXdc59DrRWkvuEzrqGiIiI9Fwf5hXjb6wlIynW61C6VFx9Gccf0J9/fLiWq44eSkLM3oZzi0hn2mtpbedcALiwG2IRERHZJ2Z2VHvWSc/gnOOj1UUk1GzBrHeOF2rpO1OHU1rdwFPzNnodikjEae88Qx+a2T1mdrSZHdx869LIRERE2u/udq7bwczizGyumX1hZkvN7Neh9UPN7FMzyzOzJ80sJrQ+NrScF9qe2/lPQwDWFlWxubyWxKotXofSLabk9mXykD488P5aGgJNXocjElHa2xY7KXT/mxbrHHB8p0YjIiLSAWZ2BHAkkLFLYZ8UwL+Xw+uA451zlWYWDXxgZq8CPwT+7Jx7wsz+DlwJ3Be6L3XOjTCzC4A7gPM7+SkJ8OHqYgASqzfvZc/e4ztTh3Plo/N58YtNnHNwjtfhiESMdrUM7VJWu/mmREhERLwWQ7DITxQ7F/ipAM7d04EuqDK0GB26NX/R93Ro/aPAWaHHM0LLhLafYJHQh8sDH+UVkZUaR3TDdq9D6TbHje7P6AHJ3DdnNU1NmkZRpLu0e5SemZ0OjAV2zHzmnPtN20eIiIh0Lefcu8C7ZvaIc67D5bhCRYIWACOAvwGrgTLnXGNol3wgO/Q4G9gYum6jmZUD6UDRLuecCcwEGDx4cIefU6RranJ8vKaYEw8cwNK5XkfTfXw+49rjhnPDE5/z2tItPPHnX1JYWr7bfhl9Upn98CwPIhTpndqVDIW6CSQAxwEPEvy2LYL+RImISJiLNbNZQC4tPtv21oshVCRokpmlAc8CB+xvIM65WcAsgMmTJ+sr/g5atrmCsuoGjhqRzlKvg+lmZ0zI4q63V3HXW6uw0nJOvvbW3fZ5495bPIhMpPdqbwGFI51zlxLsK/1r4AhgVNeFJSIi0iH/AT4DbgZ+0uLWLs65MuAdgp9vaWbWnFDlAAWhxwXAIIDQ9lSguBNilxY+zAs2tB05vJ/HkXQ/v8+44YSRrNi6ne1JalUU6Q7tTYZqQvfVZpYFNACZXROSiIhIhzU65+5zzs11zi1ovu3pADPLCLUIYWbxwEnAcoJJUfN4o8uA50OPXwgtE9r+P+ecWn462YerixnRP4kBKXF737kXOmNCFsMyEinqNxG9vUS6XnuToZdCHxh/ABYC64DHuygmERGRjnrRzK41s0wz69t828sxmcA7ZrYImAe86Zx7CbgR+KGZ5REcE/RQaP+HgPTQ+h8CN3XNU4lcdY0B5q4t5msjIq9VqFlz61BdbB/ytlXu/QAR2S/tGjPknGvutPpfM3sJiHPO7T6qT0RExBvNLTYtu8Y5YFhbBzjnFgEHtbJ+DXBoK+trgW/sX5iyJwvXl1Hb0BTRyRAEW4d+8ui7fLo2hhH9kyJi4lkRr+wxGTKzc/awDefcM50fkoiISMc454Z6HYPsvw/zivD7jMOG7a1Rr3fz+4x+xYvYFHs0edsqGTkg2euQRHqtvbUMnbmHbQ5QMiQiIp4zs0tbW++cm93dsci+ez+viEmD0kiOi/Y6lG6zeNEiTj1797l7Ny5dRr+Lj+fTtSVqHRLpQntMhpxz3+quQERERPbDlBaP44ATCI5xVTLUQ5RXN7A4v4zvHj/S61C6VUOTY1orJbQXzpzOoUP78vrSrWodEulC7Z1n6P9aW69JV0VEJBw4565vuRwq+vOEN9HIvvh4TTFNDo4eGdnjhVoaNSCZuWtL+GRtCcP7J+FT65BIp2tvNbmqFrcAcCrBie1ERETCURWgcUQ9yId5RSTG+Jk0KM3rUMKGz4zDh6VTUlXPl1u2ex2OSK/U3mpyf2q5bGZ/BF7vkohEREQ6yMxeJDiWFcAPHAg85V1E0lEf5BVx2LB0ov3t/Z42Mozsn8SC5Fg+WVPMqAFJXocj0uu0KxlqRQLBWblFRETCwR9bPG4E1jvn8r0KRjomv7SatUVVXHz4EK9DCTtmxpHD03nu800szi9vs+ACQEafVGY/PKubIxTp2do7ZmgxO3/jlgFovJCIiIQF59y7ZjaArwoprPIyHumYj/KKAY0Xasvgvgnk9Iln3rpSGnwxrRZcAHjj3lu6OTKRnq+9LUNntHjcCGx1zjV2QTwiIiIdZmbnAX8A5gAG3G1mP3HOPe1pYNIuH+QVkZEcy8j+6gbWGjPjqOH9eHL+RqJGH+t1OCK9SnvHDK03s4OBrxFsIfoA+KwrAxMREemAXwBTnHPbAMwsA3gLUDIU5i65YiYf9Z1GYtUmTjvngZ22LVm6lGkexRVuBqbGMSIjiVWjj6W6vpGEmH0d6SAiLXWktPY3+GqS1UfM7D/Oud92WWQiIiLt52tOhEKKaX/FVPFQfrWPQP94DjviSMZknrLTtoUzp3sUVXg6Yng6q7ZWMG9dKceOyvA6HJFeob1fK1wETHTO1QKY2e3A50CPT4buvvtu8vLyvA4jLDW/LjfccIPHkYSnESNGcP311+99xy6m93Db9B7es3B5D3eS18zsdeDx0PL5wCsexiPtVJWQCcDgPgkeRxL++ibGEFg7l8X+IzhoUBop8dFehyTS47U3GdpEcEbv2tByLFDQJRF1s7y8PD5fspxAQl+vQwk7vvpgzYwFa7Z6HEn48VeXeB3CDnl5eaxa+hmDkwJehxJ2YhqCDQN16+d7HEn42VDp9zqETmFmI4ABzrmfmNk5BLtzA3wMPOZdZNJeVYmZ9E2IISlO3b7ao2HpG8SOPIKP1xRz8tiBXocj0uO19y9PObDUzN4kOGboJGCumf0VwDn3vS6Kr1sEEvpSc8BpXochPUj8l+H1hfPgpAA/P7jC6zCkB7ltYYrXIXSWvwA/A3DOPUOoO7eZjQ9tO9OrwGTv6hoDVMcPYETfeK9D6Tlqypk0KI0F60uZNCiNASlxXkck0qO1Nxl6NnRrNqfzQxEREemwAc65xbuudM4tNrNcD+KRDli4vgzni2JwX3WR64gpuX1YtqmCd1cW8o1DcjAzr0MS6bHamwzlAx8552q6MhgREZEOStvDNjU3hLkP8grBNZHdRz+qjoiN8nPE8HT+9+U28rZVMnJAstchifRY7U2GLgXuM7MS4H3gPeAD51xpl0UmIiKyd/PN7Grn3E41mc3sKmCBRzFJO723soj4miJio0Z7HUqPMzYrhUX5ZXyQV8TQfolE+VU8UXq+S6+YSWFp+W7rM/qkMvvhWV1yzfbOM3QZgJllAecCfwOy2nu8iIhIF/k+8KyZXcRXyc9kIAY426ugZO+2ba9lcUE5GVX5XofSI/nMOHpkBs9+VsDnG8uYnKtCUNLzFZaWM+3aW3db/8a9t3TZNds7z9DFwNHAeKAIuIdgC5GIiIhnnHNbgSPN7DhgXGj1y865/3kYlrTDeyuLAEiq2uRxJD3X4L4JDO2XyLx1pRyY2WuKooh0q/a27PwFWA38HXjHObeuqwISERHpKOfcO8A7Xsch7ffOim30T44lti58piroiY4e2Y9/fbKeT9YUex2KSI/Urg6mzrl+wBUE5xr6nZnNNbN/dmlkIiIi0is1Bpp4f2Uhx47KQHXQ9k+fhBgm5KSxdFMFtbFpXocj0uO0KxkysxRgMDAEyAVSgab9ubCZ+c3sMzN7KbQ81Mw+NbM8M3vSzGL25/wiIiISnj7bWEZFbSPHHdDf61B6hcOG9iU2ysfW/ofinPM6HJEepb2lRz4gOHHdIuB859zo5qIK++EGYHmL5TuAPzvnRgClwJX7eX4REREJQ3NWbMPvM44a0c/rUHqFuGg/R43oR3XCQJ79rMDrcER6lPZWk5vQmRc1sxzgdOB3wA8tOFvY8cA3Q7s8CvwKuK8zrysiIiLeaFkyd82QM4htqueCb17MkqVLmeZxbL3B2KwUPvpsKb97eTknHDCA1IRor0MS6RHa200uw8z+YGavmNn/mm/7cd2/AD/lq6526UCZc64xtJwPZLcRy0wzm29m8wsLC/cjBBEREekuzSVzj7zyl9TF9eWg8WOZdu2t1Dc07v1g2SszY+DWTyitrucPb3zpdTgiPUZ7u8k9BnwJDAV+DawD5u3LBc3sDGCbc26fJsNzzs1yzk12zk3OyMjYl1OIiIiIR9YXVwEwJD3R40h6n7i6Ui47MpfHPt3A5xvLvA5HpEdobzKU7px7CGhwzr3rnLuCYLe2fXEUMN3M1gFPhM5zF5BmZs3d9nIAdXoVERHpZdYVVZMUG0W/JNVJ6go/PGkUGUmx/OLZxTQE9qvWlUhEaG8y1BC632xmp5vZQcA+TXXsnPuZcy7HOZcLXAD8zzl3EcH5Ic4N7XYZ8Py+nF9ERETCU6DJsaGkmiHpCQSHC0tnS46L5jczxrJ0UwX3v7va63BEwl57k6Hfmlkq8CPgx8CDwA86OZYbCRZTyCM4huihTj6/iIiIeGhjaTX1gSaGZyR5HUqvdsq4TE6fkMldb69ixZbtXocjEtb2WE3OzOKAbwMjCBY0eMg5d1xnXdw5NweYE3q8Bji0s84tIiIi4WV1YSXRfmNQn3ivQ+n1fjN9LB+vLuYnT3/BM985kih/e7//Fokseyut/SjBLnLvA6cCYwjODyQiItKjmdkgYDYwAHDALOfcXWbWF3iS4CTj64DznHOloWkg7gJOA6qBy51zC72IvSdywJrCKnLTE/WPeRdZvGgRp559/o7l+OQhLMo6lpNu+CPv3PNTDyMTCV97S4bGOOfGA5jZQ8Dcrg9JRESkWzQCP3LOLTSzZGCBmb0JXA687Zy73cxuAm4i2JX7VGBk6HYYwbnwDvMk8h6oJq4f1fUBhmWoilxXaWhyTLv21h3LzjleXryZNU0HsHxzBQdmpngYnUh42ttXM82FE2gxB5CIiEiP55zb3Nyy45zbDiwn2CV8BsGeEYTuzwo9ngHMdkGfEKyCmtm9UfdclUmD8RkMVUntbmNmHH9Af3xNdVz/+GfU1Ae8Dkkk7OwtGZpoZhWh23ZgQvNjM6vojgBFRES6mpnlAgcBnwIDnHObQ5u2EOxGB8FEaWOLw1qdIFyTg+/OOcf25MHk9EkgNtrvdTgRJSEmiqzNH5K3rZJbX17mdTgiYWeP3eScc/qLJSIivZqZJQH/Bb7vnKtoWfLZOefMzHXkfM65WcAsgMmTJ3fo2N4qb1sl9TEpDO8lXeR2HZvTbMnSpUzzIJ69SarezDXHDOP+99ZwzMh+nDJODZoizfY2ZkhEwlxBQQFV2/3ctlB9waX91m/3k1igua3NLJpgIvSYc+6Z0OqtZpbpnNsc6ga3LbS+ABjU4nBNEN5Ory/dAsCwfr2jpPauY3OaLZw53YNo2udH00bz8ZpibvzvYsbnpJGdpop+IqBkSEREIlSoOtxDwHLn3J0tNr1AcPLv29l5EvAXgO+a2RMECyeUt+hOJ3vwxrKtxNUUkhQ30utQIlZMlI+7LjiIM+/+gGv/tYAnrzmCmdd8h8LS8lb3z+iTyuyHZ3VzlCLdL+KToYKCAvzV5cR/+YrXoUgP4q8upqAgPGqKZGdnU9e4mZ8frGF80n63LUwhNnu34S6R5ijgEmCxmX0eWvdzgknQU2Z2JbAeOC+07RWCZbXzCJbW/la3RttDFZTVsCi/nIzKjXvfWbrU0H6J/Om8iVzzzwX86oWlFJaWt9rCBfDGvbd0c3Qi3oj4ZEhERCKTc+4DwNrYfEIr+zvgui4Nqhd66YtNAKRsX+dtIALAyWMH8t3jRnDPO3kMTFVLnUjEJ0PZ2dlsqYui5oDTvA5FepD4L18hO3vA3ncUEYlwz3++iYmD0qhfUel1KBLyg5NGsaignPebDmVzeQ2ZqRo/JJFLU0CLiIhIl1i1dTvLNlcwY2KW16FIC36f8dcLJhHVWM1LizZTUdOw94NEeqmIbxkSERGRrvHCF5vwGZwxIZP/eB1MBGurFHjthkLs1J/wwheb+MbkHGKjNKOKRB4lQyIiItLpnHM8//kmjhzej/4pcV6HE9H2VAr8G+Mzee7zAl5ZvIXpE7Pw+9oaRifSO6mbnIiIiHS6L/LL2VBSzfRJ6iIXzgb1TeD4A/qzoaSad1ZsI1gnRCRyqGVIREREOt3znxcQE+XjlHEDvQ5F9mJsVirlNQ3MW1dKWkI0k4f09TokkW6jZEhEREQ6VaDJ8eIXmzl+dH9S4qK9Dkfa4Yhh6ZTXNPBhXrF+ZhJRlAyJiIhIp/podRFFlXXqIteDmBknHTiAyrpGXl+6heyETK9DEukWGjMkIiIinerJeRtJjY/m+AP6ex2KdECU38f0CVn0TYwhP3sqn28s8zokkS6nZEhEREQ6TXFlHa8v3cI5B2cTF61SzT1NbLSfsyZlE9VYy7f+MZe8bdu9DkmkS6mbnIiIiHSa/y7MpyHg+Oahg70ORfZRYmwUNW/dQ9O073PKHa+Su+FVohurAcjok8rsh2d5HKFI51EyJCIiIp3COcfjczcyJbcPIwckex2O7IeG7UVceuRonl6QT/H4C/nGIYOIj/Hzxr23eB2aSKdSNzkRERHpFB+vKWZtURUXqlWoV8hIjmX6xCwqaht59rMCahsCXock0umUDImIiEineHxusHDCaeNViay3yO4TzxkTMimpque5zwsI+FR2W3oXdZMD/NUlxH/5itdhhB1fbQUATXEpHkcSfvzVJcAAr8PYYUOln9sW6ue0q63Vwe97BiQ0eRxJ+NlQ6Wek10FIr1JcWcdrSzZz8eFDVDihl8lNT+S08QN5efFmKrKPp7q+kYQY/QspvUPEv5NHjBjhdQhhKy8vWEFmxLDw+ac/fAwIm/dOuMQRjurz8gCIHaLXaFcj0XtHOtfTC1Q4oTcblpHEKWMH8sriJq56dD4PXz5FSa/0ChGfDF1//fVehxC2brjhBgDuuusujyORPdF7uG16D4t0j8ZAE7M/Xs+hQ/uqcEIvNnJAMllvfsjHvqO55p8LuP+SQ5QQSY+nMUMiIiKyX15fupWCshqu+tpQr0ORLpZasZbfnz2ed1cWcvXs+dTUq6iC9GwR3zIkIiIi++fBD9aQm57ACQeqW3Vvt3jRIh79/U/ITBnO++4IDvnxI+Tk/4+BaYmaf0h6JCVDIiIiss/mryvhsw1l/GbGWPw+49IrZlJYWr7bfkuWLmWaB/FJ52pocky79lYAVmzZzuvLfFRMvgIW/MPjyET2jZIhERER2Wd/eyePvokxnHtIDgCFpeU7/lluaeHM6d0dmnSx0QOT8fuMV5dspnTQNEqq6umbGON1WCIdomRIRERE9smSgnLeWVHIT04erVLLEWpE/yTOnJDFcwsbOOLmpxiU/zbRjdU77ZPRJ1Vd6CRsdftfLjMbBMwmOEmLA2Y55+4ys77Ak0AusA44zzlX2t3xiYiISPvcOyeP5NgoLj58iNehiIdy+yVS/96DxJ54HVvGXMCMSVn0S4rdsf2Ne2/xMDqRPfOimlwj8CPn3BjgcOA6MxsD3AS87ZwbCbwdWhYREZEwtGxTBa8s3sLlR+WSGh/tdTjisaZteZx7SA7OOf6zIJ+NJdV7P0gkDHR7MuSc2+ycWxh6vB1YDmQDM4BHQ7s9CpzV3bGJiIhI+9z55gpS4qK46uhhXociYSIjOZbzpgwiKSaK5z/fxLJNFV6HJLJXns4zZGa5wEHAp8AA59zm0KYtBLvRtXbMTDObb2bzCwsLuydQERER2WHhhlLeWr6Na44drlYh2UlKXDTfmJxDVlocby7fyrsrC3GY12GJtMmz0Y5mlgT8F/i+c67C7KtfFOecMzPX2nHOuVnALIDJkye3uo+IiIh0Deccl//lRfy+BF64+5e89NfGnbarhLbERfs5a1I27+cV8fnGMhJyTqS0qp4+qjQnYciTZMjMogkmQo85554Jrd5qZpnOuc1mlgls8yI2ERERadtrS7ZQEZPO8Qf0Z/zJv9xtu0poC4DPZxw7KoOMpFjeWhrgtL++z1/On8Rhw9K9Dk1kJ93eTc6CTUAPAcudc3e22PQCcFno8WXA890dm4iIiLStrjHA71/9kti6UsZmpXgdjvQAY7JSGLLhVeKi/Vz4wCf8+c2VNAaavA5LZAcvxgwdBVwCHG9mn4dupwG3AyeZ2SrgxNCyiIiIhIm/z1nDhpJqBmybj880DkTaJ76uhBev/xpnTcrmrrdXcd79H5O3bbvXYYkA3lST+8A5Z865Cc65SaHbK865YufcCc65kc65E51zJd0dm4iIRA4ze9jMtpnZkhbr+prZm2a2KnTfJ7TezOyvZpZnZovM7GDvIvfGuqIq/jYnjzMmZJJYvXnvB4i0kBQbxZ3nT+Iv509idWEVp931Aff8bxUNaiUSj3laTU5ERMRDjwCn7LKurTnvTgVGhm4zgfu6Kcaw4Jzj5ueWEOP3ccsZY7wOR3qwsw7K5q0fHstJYwbwxzdWcubdH/BRXpHXYUkE86yanIiIiJecc++FpnhoaQYwNfT4UWAOcGNo/WznnAM+MbO05qI/3RTubi69YiaFpeW7rc/ok8rsh2d16rUen7uRD/KKuPWscQxIievUc0vkyUiO5W8XHcyMpVv49YvL+OaDn3Ligf35+WkHMiwjaY/Hduf7XiKDkiEREZGvtDXnXTawscV++aF1niVDhaXlTLv21t3Wv3HvLZ16nY0l1fzu5WUcNSKdiw4d3KnnDmdVlZU8+9S/2twm+2/a2IEcMyqDf3y4jr+9k8e0P7/HOQdnc91xIxiSntjqMd31vpfIoWRIRESkFXua825PzGwmwa50DB7cs5OHi6+4hgXJh1MXk8aW15/i9Jf/DETGXELOOc4+NLfVbQue1TSHHbF40SJOPfv83dav+nI5Iw84EIBMfxxF6eP5z9wGnpq3gXMOGcS3jx3OqAHJ3R2uRBglQyIiIl9pa867AmBQi/1yQut205smB1/uH0pNfH9OHTeQUdNu2rG+J84l1FZLT1lZWavrGwONu62TfdPQ5FptzVk4c/pu66vqGnnmhZd4ZXEUzyws4Gsj+vGto3I5bnR/fD5VMJTOp2RIRETkK81z3t3OznPevQB818yeAA4Dyr0cL9QdXluymeL08YzLSukV38631dLz6dNNbazv0Xlsj5UYG8WAwgU89ufv8/jcDcz+eB1XPjqf3PQELjsyl4Av2usQpZdRMiQiIhHJzB4nWCyhn5nlA78kmAQ9ZWZXAuuB80K7vwKcBuQB1cC3uj3gbrRsUwU/ePIL4msKOXbUcK/Dabc9jfNpq6XHcCQFykhuLCXOVRPbVENMUx1Xjw8wrupjmvBR50ugxpdIjS+J7f7UTo1L449a1zcxhuuOG8HMY4bx6pIt/OPDtfz6xWX4hn2dOSu2MXFQGn0SYrwOU3oBJUMiIhKRnHMXtrHphFb2dcB1XRtReNhYUs3l/5hLanw0ScvnEOU/0uuQ2m1P43w+fdphron0xs1k1a0lq34t/Rq2cM219SRs+fVu+59wPFD2VKvn+sa3jMDiqymJG8K2pNFsSzqQwoQR+xSXxh/tWbTfx/SJWUyfmMXnG8u49LbZLC6I4Yv8coakJzAxJ43c9ASvw5QeTMmQiIiIALCtopZLHvqUusYmnrrmCL4/LzxLFbfV0tJa6090Uy25dV/yyMkNnL35ZuJcDQCVvhS2RWfz78VbGXf82VT4+1LrS6DW4qn3xXHbrb/j5lt+hs81EdtUTXxTJQlNVSQHSlm97HVOyDRGlMxh/LZgT8om/Jw03QisupWC1IPITzmIitgsMI1z6SyTBqWRveVDjjr9RJYUlLO4oJwXvthEanw0cWkHUFMfID7G73WY0sMoGRIRERHyS6u56MFPKdpex+wrD2P0wPAdJ9T2+J9gK4u5JgbXrWRs9acMr1lMFAEKB8Pq+PFsiB3JppihVPj7ghk3vX8Tt5951G7n2lJtVPrTQkt9d9p28//e5bdXzwLnSK7fSv/KL+lf+SXb8//F10reZdy2FwDYHtOf/JSDWDWmgaTGUiqj+nTmy9BrtVV9DkKVDGOjOGxYOpNz+5K3rZIv8svYPOBQxv38OfqWLqdP2Qr8TfWA5h+SvVMyJCIiEuG+2FjGzH/Op6Y+wL+uOoyDBvfMf9r7xjkO3f4m46s+IiVQRo0lsDjxSFbFT+Sy/5vFbXe01TNyH5mxPXYg22MHsjp9Krf87CkOOesycqOKmRhbwMSYTUyqeZ97j6+Drb+hOKo/62MPYH3cAeTHDKfRpzEvrWmr+hzsXMnQ7zNGD0xm9MBk/t/Pv8fo825kXdRBlA08mPHZqRw8uA8fPrR7F0iRlpQMiYiIRCjnHE/O28gvX1hKv6RYnvr2oRwwMMXrsDostbGIgyrfZeYV9SRWvML62FG8lzqDNXHjCFjwX50m1/Xd1ZxznHXoUGAoMJlFwCLnePSOG7nrutMYUreCCVUfc3DVezTipyB2OAUT6kmp3URFXFaXx9ebNRWtY8akbAq31zF/fQmfbSjji/xyUvofSn5pNTl9NK5IWqdkSEREJALll1bzqxeW8dbyrRw5PJ27LzyI9KRYr8PqkJTGEg7d/gZjq+fhMP650ofvuB9THJ3pdWhfMWN5iY+FyVNZmDwVv6snu24tQ+pWMLR2GX88ph4WzGB1Qzof1Aznw9qhrGgYoCpz+ygjOZZTx2VyxLB6FqwvZUlgJFP/MIdzDs7mO1NHMLRfotchSphRMiQiIhJBtm2v5aEP1vLIh+swg5tPP5Arjhraoya07BfnOL7sP4yr+gSHjy8Sj2Je8glcf9fvuX1aGCVCrQhYDBviRrMhbjTvp07ngd/dyL03nMrwmqVcEj2fy1LmUulL4d/H1JBWvoBNKZNw9lVRAJXpbp+0hBhOOHAAte8/zNcu+TGPz93A0wvyOWNCFtcdNyKsx8RJ91IyJCIi0svVNgT4dG0Jzy7M55UlW2gINDF9YhY3nnIAWWnxXofXbuYambDlGT6/uIqUqk9YkngEc5NPbFHooOdZXW58ljSVz5KmEheoIrduOSNqFnPxAYtIWPJtigKJzKkZyf9qRrK0PpOGxgaV6e6A6MZqfjV9LNcdN4IHP1jDPz9ezwtfbOLksQO4duoIJg5K8zpE8ZiSIRERkV7GOcfqwkreXVnEeysL+XRtMbUNTaTERXH+5EFc8bWhPa67UHb5Zxy35g9kVK/inUI/Gw75MSXRA70Oq1PV+hP5MmEyXyZM5tY7b+Sfv7iAUTWfcZZ/CecmfU6FP42HvtZAesMmiqM1xqgjMpJj+dmpB/LtY4bzj4/W8Y8P1/L60q1MGpTGZUcO4bTxmcRG7bks96VXzKSwtLz186tqXY+lZEhERCRM7emfryVLlzKtxXJjoIn80hq29D+Ur93xDgVlwfl0hmUkcsGUwRw7KoMjhqcTF92z5mFJrCvk6HV3cWDR61TEDODF0XdwwT2/4beH965EaFdVDcbKhINYmXAQMU21DKtdwuiaz7hu0jJitv2BrdE5LE04lC8TDqbO17MSWy/1SYzhhyeN4uqjh/LfBfnM/ng9P3jyC259aTlnTsjkrIOymTQoDWtlfqjC0vI2q9y9ce8tXR16RHHOUVUfoLqukYSYKLqyzVPJkIiISJja0z9fzSWGC7fX8UV+GSu3bqch4LDU4UzOSuHa44ZzzMgMBvXdexWttpKuXROu7uRrauCqkSVcPHcGfmvike2H8ljlZOrWbqIxEPAoKm/U++J2tBj94a4beeynpzO2ei7Hlz/DMeXPsyZuHEsTD8Vv6ibXXslx0Vx+1FAuPSKXD1cX8fjcDTw+byOPfrye3PQETh47kOMO6M8hQ/oQ7fd5HW7EqI9O4t0VhazYup2ahq9+z6OGfb3LrqlkSEREpAeylAG88MUm1hZVEeUzRg5IYtSAZL586v/xwP97vEPnaivpajmnS3caXPoJx639I32PrGN13DjeTZ1BeU4/Tgttb55cNRIV1xqfJx3D50nHkFFfwJjquRxQs4BRtV8w5VJjw8YHWTLgLKpi+nkdao/g8xlHj8zg6JEZVNQ28NriLby4aBMPf7iW+99bQ0pcFMeMyuD4A/rT6I/zOtxeq7q+kTvfWMnqoTPwF5QztF8iOX3jSYyJorq+kWXvze2yaysZEhER6UEaA018vKaY2JN/xKayGo4Yls7EnFRiQ93fVromjyPcdym1mzhm7Z8ZWTKH0rhBnPNiHEd/+0qvwwpbhTHZvBtzNu+nnsmw2mXEb5jNiRvu57CND7K673F8MfDr5Kce0mYFOlWf21lKXDTnTRnEeVMGUVnXyAerCnl7+TbeWVHIS4s2w4jz+Nen6xncJ4HBfRPI7hOvVqNOsHRTOdc//hlri6pILV/DN86YRmLszinKlrIvu+z6SoZERER6iOLKOl5dsoXiqnoCa+dx2eXfJD6mZ40B2lVVZSUvP/UI30yez0XJ82lyxv3bj+SpgoP4YM1DHO11gD1Ak0WRFz+Bm1+I556HH2X8lmcYt+1FRhW/RXF8LgXj6xg2eQB1vp0rB0Z69bm2uoc2F0M4ZVwmp4zLpKnJsXRTBVf88q/E9TmKRQXlfLaxDJ9BZmo8g/smUBOXTqDJ4e9BJerDwRtLt3DDE5+TEh/FY1cexq0/mU1i7Gl7P7ATKRkSERHpAVYXVvL60i1E+XzMmJjFE0/+h/iZl+y23+JFizj17PN3W7/qy+WMPODAVs/t2dgg5zgtt4EHBj9OaqCEFfEH8V7KmVQP6sMZwAcR3B1uX5XFD+b9od/no8HfZnTxW0zY/F/+eEw9DVt+xZfxB7Eo8Si2xQzyOsyw0Fb30F2LIfh8xvicVPqVLGHawefTEGhiU1kNG0tq2FBSzcdrimHI6Yy88VkSq7eQWLWZxOrNRDdsp7+qzLXKOcdDH6zld68sZ0JOGg9eOpmMZG8mfVYyJCIiEuYW5ZfxzopC+ifHcuaELJLi2v74bmhybY7/2Vsxhu7Up3odU9f+iR+cXkuRpfGffteSHzuy2+PorQL+OJb1P4Nl/c/gP9cfw/1XTOSAmoWMr/6ULdGDWZR4JPFRSjZb09YXCs1fGkT7fQxJT2RIerCKX3V9I3+74zdM+vp1bChJZEvyEABS4qLYsmUZLy/azNdG9CM1Ibo7n0bYagw08csXlvLYpxs4ddxA7jxvkqct3EqGREREwtiC9aV8kFfE0H6JnDZuIFE9dIxC87iVJKvj0uS5fD3pc+pcFD96P4rBF/6YJuvZ3f3CQWOgsdWxQQu2Ot7qcz7vpU7nwOr5TKz6kGllT7Dqcli75k8sHngOJQlDuz/gMLWnLxRakxATRWDj55w0ZgDOOcpqGthQXM2GkmrWJedy3b8X4jOYNCiNY0ZlcMyoDCbmpEVkl7rttQ1c9+/PeG9lId8+djg/PXk0vhavw/Kli6lq5T28YeniLotJyZCIiEgYcs5RmD6R5XlFjOqfxLSxA3v0P08+mvi/sZs4suIV4puqWZpwKB+mnM49n/+O27+pRKhzOM4+NHe3tc3V9+p98XyRdDRfJH6N7Po18NHf+Xr80xy8+Qk2phzCooHnkJd+HE0+tWDsKzOjT0IMfRJimDgojT995zqGH3ocVQlZLKvOYuH6Uv7y1iqimuo5eeIQjg0lRwNTe3+lurVFVVw9ez7riqq4/ZzxXHDo4N32CTTUt/oevvOt+i6LS8mQiIhIGHrw/bUU9ZvImMwUTjiwP75WJoHsKQaVzeWj82sYV/Yf8mOG827qDI1b8ZIZBbHDuenVKP6VfAmnJyxleuMSTq/4BcWBBN6qHs2IuHJwDnrw+y4cNAQCnPWt7+1YrmkIsLGkmo8+/ID565N5efFmAEYNSOLI4f04dGhfpuT29Wz8TFeZs2Ib33v8M/w+Y/YVh3LkiPAp/a5kSEREJAzNmJTFrEf/zYnHfwProf+QZlYs4sgNf2dw+TzWxRgv9r2cvLgJPf4f7La6ozUGGj2IZn84jps8hmrG8IT7Orl1Kxhf9RHn+hdx/vkBij87jy8zTmFFxsmUx+V4Hew+aWv8D3hTOCQ+2s+oAcm8+MbfGTdhAgkxaVQlZlFQlcWjm0t55KNgq9ywfolMye3LlKF9mZLbh8F9E3rk34FAk+Pv767mT2+sYNSAZB64dHK7JoLuTkqGREREwlD/lDj6lSzG7DyvQ+mw/pXLOWLD/Qwr/ZDq6D68m/t9zr7xAW757USvQ+ske+6O1iOZj3VxB7Iu7kBim6pY/u9buXFGH47a8HeO2vB3tiWOZG2fo5mcUY+5AK6HjPFqa/wPeDepMATjOnmXuAJNjsLtdbzzyrMMO/A0Xlu6hSfnbwQgLSEaKy3AV7mF+Npi4mqLiG6sAb4qBR5u1hRWcuN/FzFvXSmnT8jkD+dOICEm/FKP8ItIREREeqTMikU8clwJp35xKTVRqXww5Do+zzyPBn8CdYEHvQ5P2qnOl8jDS6MZdvMskms3M6r4LYaWfMCU/Ed5+bQA1XNPYV2fIylIOYiClEmUxg/xOuRewe8zBqbGsendJ0gvXUYm0DcmjZr4DGrj+lFCIr5+E3ChnDsxxk+/pFiW5M3jyXkbGDkgmZH9k0iO83bMV1FlHfe/u5pHPlpHXLSfP31jIuccnB22LVtKhkRERGSfmWtkWMn7TC74F1nbF1E6wPh40EwWZl1IfVSS1+HJftoel8mC7EtYkH0JsY0VfPH/vs73zz2c3LKPGVP4CgDVUWkccFwNSfmPUpg4isLEkVTHhM+YkJ6mrdas22dO58f3PUdhZR1bK+rYVlFLUVU9pWmjufG/X1Vby0qNY3j/JHL6JJDTJz50S2BQn3j6JcXi89leJ5ztKOccn20s4+kF+TyzMJ+6xibOPTiHn5wymv7J4V0cQsmQiIiIdFhS3VbGbX2BcVufI7l+G+WxWbwz9Mdc8dt/8r17r/Y6POkCdVEpPLcungNG3QrO0admPVnbvyCr4gtGFb/C8PX37Ni3KrovRYkjKUoYzubRVQwu+5SyuEFsjx3QY7rYhaMov4/M1HgyU+N3rPvTt89i9CFHUBeTRl1sGpXlqczbksonsck0+HYuxBAT5aN/cixFyUeSNSaXhBg/CTFRoXs/i1/9J59vLCM5LoqUuGgSYvxE+Y2rZn6HwtJymnzRNFkUTf4YGqISqYtNxaUMhIwRFG6vIy7ax5kTsrjm2OGM6N8zvgwJq2TIzE4B7gL8wIPOuds9Dqlb3X333eTl5Xkdxg7Nsdxwww0eRxI0YsQIrr/+eq/DkL0Ip/dxuL2HQe9j6dliGisZUTKHx08sYer86fhoYl3a4cwZ9iNW9z0GZ1FUNz7mdZjSCdoqElFVWRl8YEZpQi6lCbksHTCDW345h6nnXMiwqGJGRBcyPLqIEVVrGRu1gP93eCMs/S4A9c7PpsZUChpT+dn4QgIv/5TNjSlsDqSytTGZeqK+uoa0S0NTE2dcfeNu69+49xb+++RjFJTWkF9aQ35pNfmlNWzbXscb+aspr21gc3ktNQ2Brw4adBJn/e3D3S/Sfwb0b/36UQ3VnDosnamjMpg2doDn3fQ6KmySITPzA38DTgLygXlm9oJzbpm3kUWu+Pj4ve8kEsb0HhbZf4n1ReSWfsiwkvfJLf2YKFfPumTjX9sn83LVWDYXpMLSTcATAJSVlfWSSmuRrq0iEQ2t/nwbGhs4YfKBAASAlaEbrom//uZn/L+briatsZA+jYWkNRYxurGIgyc0Eh/1TosrGpW+FBadXUWflb+kIi6L8tgsyuOyKY/Loiomo0ueaW+1eNEivn7+Ra1uq1i6lKv+9gwATU2OmoYANQ0BPvjPLH75fzdTUdPI9toGqusDNDY5/vHYkwyfcjwxfh/RUT5i/D6S46JIjY/m7zd8nbw1E8gDWo4MDNfCDrsKm2QIOBTIc86tATCzJ4AZQMQkQ/q2WHoDvY9FukdVZeWev7nfR7GN28mu+Iyc8gUcf0YhE+edCkBFzAAWDzyLFf1O5sprvsdvf/9NDm/l+E+fbup9ldakhQ5W0jMfm6qM/NgR5MeO2GnTz356I3f//mekNhaTEijZcd/kFpBTvoDkwlcxvjpvwKKYfrbDv/S7O5Kk5oSpb2yT5kXaRXsr6fl8RmJsFImxUSTUbOP4Awbstv9Lf13E4cO+0aHrvHHvLfsYefcKp2QoG9jYYjkfOGzXncxsJjATYPDg3WeuFRERiQTOtf5P6YJn25l0OEdCQzEZVau4flwlp335M/pXraRP7QYAGi2GT2ods8qP4KPaoaxp7AdrDVhEYyCw53OLtIPDqPSnUelPo4DhO9bf9PRiDjv3AqJpZIB/O5lRFWT6K8iMKidmy+eMi1vHYP8i0vw1O4755gVQ/8nUHa1IFbFZlMdlMS2nlvSqPMrjsmn0q7fA3rQ1L9O+zMnU1rnCrcUonJKhdnHOzQJmAUyePFlfM4mIiLTC31RHct1Wkuu2kFy3hR9N3M5Jq35DSt2WHeujXD0A5xwC5ZXL2JY0mmX9T6cgZSJbksfxs4tO4be/P4+JQMsZgtTKI12r9UR/G3DTw0u4/f/dBEB0Uy2pgRJSGov58Pl/ceF5Z5JSu4m02nyGlH1KdFMtx50AfH4hECzqUBGbRUVcJttj+lM6ppJRhW9QFdOPypgMqmIyaPSHd+WzrtZWK8++zMnU1rn+9O0ZbU6EW1ZZ3eHr7K9wSoYKgEEtlnNC60RERCLS8qWLqWqlKxw4kqMa6F+/kZRAKcmBUpIbS0kJlHL0N6o5cO7JJDaU7HTESROhuuwTKmIHsi1xFKv7HsP22IEUJQznFzf/iu/c83z3PCmRTtLgi6PIl0VRdBZ3LfTxybCBwEDgYMCR5quh4sPH+MnPf0FqXQGptZtIqd1E/8ovGVb/HpOn1MHKX+x0zlp/EqeeWU3l2+dQ0pRAWVM85YF4ypviOaF/KdnlC6mJTqMmKo3a6FRVxtsHe+q+9977x3VzNOGVDM0DRprZUIJJ0AXAN70NSURExCONdQyJr+b7E2pIaSwmNVBMamNJ6L6Y2G/XQeGdO3ZvsBgq/GmsrzPW9D2GitiBbN9xG8CPr7qEcdN3/VhtAL5k/bYKFT2QHq711qSb/+tjZUYrHbyc44/fOp7jp59FP38V/XxV9PNXku6vwle8mMMH+BjZVEh8UxUxri54zKnAkmtaXNGojUqhLiqZ488opO/ib1MXlUS9P3HH/XVjK5mw+b87luv9iTT44xiR0khy3RYafHE0+uJo9MWA+fbpmXfV+MFu4RyxjRUkNRSRWF/EN0c3cFDlHKJcI37XiM8FwIyqsV3XYhQ2yZBzrtHMvgu8TrC09sPOuaUehyUiIrKTbpsGYu4s3j27FIqDfesbiaY8qi/l/r4UJAzl369+zNFnXUaFvw/b/X2o9SWAGTf/5RZ+e+EvdjtdXYBW/1kEFT2QCGRGWR0cfPAhO1ZVh243PXQTt0/9/o71ftdAXFMVs/70e7528umk+WpI89WS6qshzVdDkq+Oxu2OdJpIrd1ETKCK2EAlMY1VHDY5AGt2/xNx0dnA/DN3WlfbFEWti+Lcc+pIWPiNYJLkj9uRMA0+upRReb+lwRdPgz9088VzyQH1nDGuhEaLod4XS4PF0Ggx/P6tAHENZTT44gj4Yru3uIRrIiMuQEblChIbikisLyaxPpjwjJpawkGLrggtF+/orgvw9ZOA8q9aqZsIJohZB3RdqGGTDAE4514BXvE6DhERkdZ06zQQI6dxwy13cOTZl1MelU6VL3mnb47/+tk8si4cv9thbc0Po1YeiURt/T40b2uPgEVT5U9jcZFx0cRjAHBAWegGcNMDP+Ow6GN2OdKx+Ln7uePWnxHTVEuMqyW2qZYo18B/HnuUSy88lyhXT7SrJ8o1hO7rWbzyUw7NHUF0Uy1RTbXEBKpIrC/i4H4N9C/5gKimWqIDNfhoAgiOiyr9525xX3oZMPckIJhUNPjjafTF0eCP54TTt2L/m06Ni6bWRVPtoqltiuZnE4o4bMMsGn1xNJkPMJwZVx1QxaRNT+LM8LlGogO1oThqST+8nMO/vIn4hlLiG8uIbygjvqGcH5wfgC8u3immWn8y8akBGn1xbEqZFByvFd2Pqph+VMWk89sbf8i3f/oLGi2aAP4df/PuvO02Nv6xXT+uDgurZEhERCTMdd80EBmjeWZNHLmxwzp4YAdLH4v0aq3/PkBn/0609XsHVf5UqvypO63/z0o/hyTuVjQZgJveWMBhKWNbOdcsDju3OblwxBAgztfAilcf5eabvk90KLGKdnVEN9Xz/FP/ZsyUo4i3BuKtgThfA3HWSLzVU1sOE7OT6NdUT7SrDh7j6mFcAwkbH9jt2lMPA9bunI00J1iDBtfiq15NbXQapXGD2ZQ8kZroNP7z738TP/YEipsSKQ4Eb/VEsfC5h7n13/e2+txXl/uo8yW0uq2rKBkSERFpv3ZNAyEisu/aSqxa78765lNQEj1wt/WPLnuS2y8/a0f3v5ZueuAmbj/m2t2OuemnP+OIc68mxgIYDh8OAxa/8i9+PutZzDXR5IumwRdHk0WBGbd883gOPmvG7vF+Ztx+4Un0BUbu9Dxan7gXvGnBNud67jdFZlYIrPc6jl6uH1DkdRAi+0Hv4a43xDkXEVPDm9m5wCnOuatCy5cAhznnvttinx3z4QGjgRUdvIzes3oNQK9BM70Oeg1g/1+DNj+nenTLUKR8+HrJzOY75yZ7HYfIvtJ7WDrZXqeBaDkf3r7Qe1avAeg1aKbXQa8BdO1rsG81/ERERCLTjmkgzCyG4DQQL3gck4iI7KMe3TIkIiLSnTQNhIhI76JkSPZmn7t6iIQJvYelU3XDNBB6z+o1AL0GzfQ66DWALnwNenQBBRERERERkX2lMUMiIiIiIhKRlAxJq8zsFDNbYWZ5ZnaT1/GIdJSZPWxm28xsidexiLRXJP7tNbNBZvaOmS0zs6VmdkNofV8ze9PMVoXu+3gda1czM7+ZfWZmL4WWh5rZp6H3w5Ohoh29lpmlmdnTZvalmS03syMi7X1gZj8I/R4sMbPHzSwuEt4HrX1mt/Wzt6C/hl6PRWZ28P5cW8mQ7MbM/MDfgFOBMcCFZjbG26hEOuwR4BSvgxBprwj+29sI/Mg5NwY4HLgu9LxvAt52zo0E3g4t93Y3AMtbLN8B/Nk5NwIoBa70JKrucxfwmnPuAGAiwdciYt4HZpYNfA+Y7JwbR7BIywVExvvgEXb/zG7rZ38qwXlcRxKc0+2+/bmwkiFpzaFAnnNujXOuHngC2H1qYZEw5px7DyjxOg6RDojIv73Ouc3OuYWhx9sJ/gOcTfC5Pxra7VHgLE8C7CZmlgOcDjwYWjbgeODp0C69+jUws1TgGOAhAOdcvXOujAh7HxAsbhZvZlFAArCZCHgftPGZ3dbPfgYw2wV9AqSZWea+XlvJkLQmG9jYYjk/tE5ERLpOxP/tNbNc4CDgU2CAc25zaNMWYIBXcXWTvwA/BZpCy+lAmXOuMbTc298PQ4FC4B+hroIPmlkiEfQ+cM4VAH8ENhBMgsqBBUTW+6Cltn72nfq3UsmQiIiIeM7MkoD/At93zlW03OaCpW97bflbMzsD2OacW+B1LB6KAg4G7nPOHQRUsUuXuAh4H/Qh2OoxFMgCElF3b6Brf/ZKhqQ1BcCgFss5oXUiItJ1IvZvr5lFE0yEHnPOPRNavbW560vofptX8XWDo4DpZraOYPfI4wmOn0kLdZeC3v9+yAfynXOfhpafJpgcRdL74ERgrXOu0DnXADxD8L0RSe+Dltr62Xfq30olQ9KaecDIUPWSGIKD917wOCYRkd4uIv/2hsbGPAQsd87d2WLTC8BloceXAc93d2zdxTn3M+dcjnMul+DP/X/OuYuAd4BzQ7v19tdgC7DRzEaHVp0ALCOC3gcEu8cdbmYJod+L5tcgYt4Hu2jrZ/8CcGmoqtzhQHmL7nQdpklXpVVmdhrB/st+4GHn3O+8jUikY8zscWAq0A/YCvzSOfeQp0GJ7EUk/u01s68B7wOL+Wq8zM8Jjht6ChgMrAfOc871+qIoZjYV+LFz7gwzG0awpagv8BlwsXOuzsPwupSZTSJYQCIGWAN8i+AX9xHzPjCzXwPnE6yy+BlwFcHxML36fdDaZzbwHK387EOJ4j0EuxBWA99yzs3f52srGRIRERERkUikbnIiIiIiIhKRlAyJiIiIiEhEUjIkIiIiIiIRScmQiIiIiIhEJCVDIiIiIiISkZQMibSDmeWY2fNmtsrMVpvZXaF5QDpyjqlm9tI+Xv9BMxuzL8eKiEjvYmYBM/vczJaY2X/MLKGbr/+ImZ279z13OubbZnZp6PHlZpbVNdGJdIySIZG9CNWzfwZ4zjk3EhgFJAHdNv+Hc+4q59yy7rqeiIiEtRrn3CTn3DigHvi21wHtiZlFOef+7pybHVp1OaBkSMKCkiGRvTseqHXO/QPAORcAfgBcYWaJZvbH0Ldzi8zsegAzm2JmH5nZF2Y218ySW57QzH5lZj9usbzEzHJD53s5dNwSMzs/tH2OmU0OPb7QzBaHtt/R4hyVZva70LGfmNmALn9lRETEa+8DI8zsTDP71Mw+M7O3mj8DQp8XaRZU3KJ1ZraZnRRqpXk+9Dmzysx+Gdqea2ZLmi9iZj82s1/tenEz+z8zmxf6TJoV+gKx+XPrL2Y2H7ih+XMv1KI0GXgs1Lp1upk91+J8J5nZs133consTMmQyN6NBRa0XOGcqwA2EJwZOheY5JybQPCPewzwJHCDc24icCJQ085rnQJscs5NDH3j91rLjaFuBXcQTNAmAVPM7KzQ5kTgk9A13wOu7tjTFBGRnsTMooBTgcXAB8DhzrmDgCeAn4Z2+xA4iuBn2Rrg6ND6I4CPQo8PBb4OTAC+0fzlWzvd45ybEvrMigfOaLEtxjk32Tn3p+YVzrmngfnARc65ScArwAFmlhHa5VvAwx24vsh+UTIksn+mAvc75xoBnHMlwGhgs3NuXmhdRfP2dlgMnGRmd5jZ0c658l22TwHmOOcKQ+d8DDgmtK0eaB6TtIBgkiYiIr1PvJl9TjCp2AA8BOQAr5vZYuAnBJMfCLYcHRO63QeMN7NsoNQ5VxXa503nXLFzroZgt/CvdSCW40ItUosJflE3tsW2J/d2sHPOAf8ELjazNIJJ2qsduL7IflEyJLJ3y4BDWq4wsxRg8H6cs5Gdf//iAJxzK4GDCSZFvzWz/+vAORtCHyoAASBqP+ITEZHw1TxmaJJz7nrnXD1wN8FWmvHANYQ+Vwj2FDg6dJsDFALnEkySmjl25mjjc6olM4sD7gXODV33gV32q9r1mDb8A7gYuBD4Twe+QBTZb0qGRPbubSChRT9rP/An4BHgdeCaUFcFzKwvsALINLMpoXXJzdtbWEcw6cHMDgaGhh5nAdXOuX8Bf2jep4W5wLFm1i8Ux4XAu536bEVEpCdKBQpCjy9rXumc2wj0A0Y659YQ7E73Y4JJUrOTzKyvmcUDZxHsWrcV6G9m6WYWy87d35o1Jz5FZpZEMMlqj+3AjrG0zrlNwCbgZoKJkUi30TfHInvhnHNmdjZwr5ndQvBLhFeAnxNsgRkFLDKzBuAB59w9ocIHd4c+WGoIjhtq6b/ApWa2FPgUWBlaPx74g5k1AQ3Ad3aJZbOZ3QS8AxjwsnPu+c5/1iIi0sP8CviPmZUC/yP0JVvIp4A/9Ph94PcEk6Jmcwl+LuUA/3LOzQcws9+EthUAX+56QedcmZk9ACwBtgDz2hnrI8DfzawGOCLUPe8xIMM5t7yd5xDpFPZVrxoRERERiSRmdjkw2Tn3XY/juAf4zDn3kJdxSORRy5CIiIiIeMbMFhAcX/Qjr2ORyKOWIRERERERiUgqoCAiIiIiIhFJyZCIiIiIiEQkJUMiIiIiIhKRlAyJiIiIiEhEUjIkIiIiIiIRScmQiIiIiIhEpP8PIh6NDwLp9lMAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"**As you see, there isn't any significant relationship between target(Pawplularity) and data attributes! Almost all zeros and ones are in the same variation range!**\n\nSo, it can be assumed that the CSV data is not suitable for builing a model and it's better to use the images themselves.","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"train_df['Pawpularity'].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:50:56.559826Z","iopub.execute_input":"2022-08-28T07:50:56.560108Z","iopub.status.idle":"2022-08-28T07:50:57.147993Z","shell.execute_reply.started":"2022-08-28T07:50:56.560077Z","shell.execute_reply":"2022-08-28T07:50:57.147165Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"X = train_df[train_df.columns[1:-1]]\ny = train_df['Pawpularity']","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:50:58.677764Z","iopub.execute_input":"2022-08-28T07:50:58.678043Z","iopub.status.idle":"2022-08-28T07:50:58.683305Z","shell.execute_reply.started":"2022-08-28T07:50:58.678012Z","shell.execute_reply":"2022-08-28T07:50:58.682346Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:51:05.730973Z","iopub.execute_input":"2022-08-28T07:51:05.731248Z","iopub.status.idle":"2022-08-28T07:51:05.739267Z","shell.execute_reply.started":"2022-08-28T07:51:05.731217Z","shell.execute_reply":"2022-08-28T07:51:05.738347Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# ElasticNet Regression","metadata":{}},{"cell_type":"markdown","source":"Since there are many hyperparameters for each algorithm, we're going to use GridSearchCV tuner to find the best values for the hyperparameters. You can use RandomizedSearchCV too.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import r2_score\n\nElnetReg = ElasticNet(random_state=42)\nElnetReg_param = {'selection': ['cyclic', 'random'],\n                  'warm_start': [True, False],\n                  'alpha': list(np.random.random_sample((10,)))}\n\nElnetReg_GS = GridSearchCV(ElnetReg,\n                           ElnetReg_param,\n                           scoring = [\"r2\", \"neg_mean_absolute_error\"],\n                           refit = \"r2\",\n                           cv = 5,\n                           verbose=3)\n\nElnetReg_GS.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:51:10.225957Z","iopub.execute_input":"2022-08-28T07:51:10.226261Z","iopub.status.idle":"2022-08-28T07:51:11.595036Z","shell.execute_reply.started":"2022-08-28T07:51:10.226226Z","shell.execute_reply":"2022-08-28T07:51:11.591013Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 40 candidates, totalling 200 fits\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=True .....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.4595306316357075, selection=random, warm_start=False ....\n[CV]  alpha=0.4595306316357075, selection=random, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=True .....\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=True .....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=True .....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=True .....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=True .....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=True .....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.9429388606283784, selection=random, warm_start=False ....\n[CV]  alpha=0.9429388606283784, selection=random, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.158, r2=-0.001, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.180, r2=-0.001, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.884, r2=-0.003, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.158, r2=-0.001, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.180, r2=-0.001, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.884, r2=-0.003, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=True, neg_mean_absolute_error=-15.158, r2=-0.001, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=True, neg_mean_absolute_error=-15.180, r2=-0.001, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=True, neg_mean_absolute_error=-14.884, r2=-0.003, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=True ....\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=False, neg_mean_absolute_error=-15.158, r2=-0.001, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=False, neg_mean_absolute_error=-15.180, r2=-0.001, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=False, neg_mean_absolute_error=-14.884, r2=-0.003, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.33085288207909413, selection=random, warm_start=False ...\n[CV]  alpha=0.33085288207909413, selection=random, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=True .....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5763943948443414, selection=random, warm_start=False ....\n[CV]  alpha=0.5763943948443414, selection=random, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=True .....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5713218410019746, selection=random, warm_start=False ....\n[CV]  alpha=0.5713218410019746, selection=random, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.161, r2=-0.001, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.181, r2=-0.001, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.887, r2=-0.003, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.843, r2=-0.002, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.181, r2=-0.003, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.161, r2=-0.001, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.181, r2=-0.001, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.887, r2=-0.003, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.843, r2=-0.002, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=cyclic, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.181, r2=-0.003, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=True, neg_mean_absolute_error=-15.161, r2=-0.001, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=True, neg_mean_absolute_error=-15.181, r2=-0.001, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=True, neg_mean_absolute_error=-14.887, r2=-0.003, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=True, neg_mean_absolute_error=-15.843, r2=-0.002, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=True ....\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=True, neg_mean_absolute_error=-15.181, r2=-0.003, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=False, neg_mean_absolute_error=-15.161, r2=-0.001, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=False, neg_mean_absolute_error=-15.181, r2=-0.001, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=False, neg_mean_absolute_error=-14.887, r2=-0.003, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=False, neg_mean_absolute_error=-15.843, r2=-0.002, total=   0.0s\n[CV] alpha=0.16398561206197804, selection=random, warm_start=False ...\n[CV]  alpha=0.16398561206197804, selection=random, warm_start=False, neg_mean_absolute_error=-15.181, r2=-0.003, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=True .....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.4178953955746625, selection=random, warm_start=False ....\n[CV]  alpha=0.4178953955746625, selection=random, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=True .....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.5967483856864241, selection=random, warm_start=False ....\n[CV]  alpha=0.5967483856864241, selection=random, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=True, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=True, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=True, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=True, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=True .....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=False, neg_mean_absolute_error=-15.157, r2=-0.001, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=False, neg_mean_absolute_error=-15.179, r2=-0.001, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=False, neg_mean_absolute_error=-14.883, r2=-0.003, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=False, neg_mean_absolute_error=-15.845, r2=-0.002, total=   0.0s\n[CV] alpha=0.8505678372834498, selection=random, warm_start=False ....\n[CV]  alpha=0.8505678372834498, selection=random, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.160, r2=-0.001, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.181, r2=-0.001, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=True, neg_mean_absolute_error=-14.886, r2=-0.003, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.844, r2=-0.002, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.160, r2=-0.001, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.181, r2=-0.001, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=False, neg_mean_absolute_error=-14.886, r2=-0.003, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.844, r2=-0.002, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=cyclic, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=cyclic, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=True, neg_mean_absolute_error=-15.160, r2=-0.001, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=True, neg_mean_absolute_error=-15.181, r2=-0.001, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=True, neg_mean_absolute_error=-14.886, r2=-0.003, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=True, neg_mean_absolute_error=-15.844, r2=-0.002, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=True .....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=False, neg_mean_absolute_error=-15.160, r2=-0.001, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=False, neg_mean_absolute_error=-15.181, r2=-0.001, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=False, neg_mean_absolute_error=-14.886, r2=-0.003, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=False, neg_mean_absolute_error=-15.844, r2=-0.002, total=   0.0s\n[CV] alpha=0.1983081771286802, selection=random, warm_start=False ....\n[CV]  alpha=0.1983081771286802, selection=random, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.003, total=   0.0s\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    1.3s finished\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5, estimator=ElasticNet(random_state=42),\n             param_grid={'alpha': [0.4595306316357075, 0.9429388606283784,\n                                   0.33085288207909413, 0.5763943948443414,\n                                   0.5713218410019746, 0.16398561206197804,\n                                   0.4178953955746625, 0.5967483856864241,\n                                   0.8505678372834498, 0.1983081771286802],\n                         'selection': ['cyclic', 'random'],\n                         'warm_start': [True, False]},\n             refit='r2', scoring=['r2', 'neg_mean_absolute_error'], verbose=3)"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's see what are the best hyperparameters found by GridSearchCV","metadata":{}},{"cell_type":"code","source":"print(ElnetReg_GS.best_params_)\nprint(ElnetReg_GS.best_score_)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:51:15.670702Z","iopub.execute_input":"2022-08-28T07:51:15.670982Z","iopub.status.idle":"2022-08-28T07:51:15.676977Z","shell.execute_reply.started":"2022-08-28T07:51:15.670950Z","shell.execute_reply":"2022-08-28T07:51:15.676007Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'alpha': 0.4595306316357075, 'selection': 'cyclic', 'warm_start': True}\n-0.0016709497423792019\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Time to test the model! I use R2 score to evaluate the model","metadata":{}},{"cell_type":"code","source":"model_pred = ElnetReg_GS.predict(X_test)\nElnetReg_r2 = r2_score(y_test, model_pred)\nElnetReg_r2","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:51:30.531095Z","iopub.execute_input":"2022-08-28T07:51:30.531657Z","iopub.status.idle":"2022-08-28T07:51:30.541782Z","shell.execute_reply.started":"2022-08-28T07:51:30.531620Z","shell.execute_reply":"2022-08-28T07:51:30.540418Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"-0.0008285427279919322"},"metadata":{}}]},{"cell_type":"markdown","source":"Hmmm... a negative R2 score! that's terrible :)","metadata":{}},{"cell_type":"markdown","source":"# AdaBoost Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\n\nAdaBoostReg = AdaBoostRegressor(random_state=42)\nAdaBoostReg_params = {'loss': ['linear', 'square', 'exponential'],\n                      'learning_rate': list(np.random.random_sample((5,))),\n                      'n_estimators': [50, 100, 200, 400]}\n\nAdaBoostReg_GS = GridSearchCV(AdaBoostReg,\n                              AdaBoostReg_params,\n                              scoring = [\"r2\", \"neg_mean_absolute_error\"],\n                              refit = \"r2\",\n                              cv = 5,\n                              verbose=3)\n\nAdaBoostReg_GS.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:51:35.794073Z","iopub.execute_input":"2022-08-28T07:51:35.794362Z","iopub.status.idle":"2022-08-28T07:52:37.339274Z","shell.execute_reply.started":"2022-08-28T07:51:35.794331Z","shell.execute_reply":"2022-08-28T07:52:37.338593Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 60 candidates, totalling 300 fits\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=50, neg_mean_absolute_error=-15.881, r2=-0.035, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=50, neg_mean_absolute_error=-15.981, r2=-0.037, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=50, neg_mean_absolute_error=-15.563, r2=-0.031, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.597, r2=-0.008, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=50, neg_mean_absolute_error=-15.813, r2=-0.007, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=100 .\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n","output_type":"stream"},{"name":"stdout","text":"[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=100, neg_mean_absolute_error=-15.881, r2=-0.035, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=100 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=100, neg_mean_absolute_error=-15.981, r2=-0.037, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=100 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=100, neg_mean_absolute_error=-15.563, r2=-0.031, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=100 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.597, r2=-0.008, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=100 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=100, neg_mean_absolute_error=-15.813, r2=-0.007, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=200, neg_mean_absolute_error=-15.881, r2=-0.035, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=200, neg_mean_absolute_error=-15.981, r2=-0.037, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=200, neg_mean_absolute_error=-15.563, r2=-0.031, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.597, r2=-0.008, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=200, neg_mean_absolute_error=-15.813, r2=-0.007, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=400, neg_mean_absolute_error=-15.881, r2=-0.035, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=400, neg_mean_absolute_error=-15.981, r2=-0.037, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=400, neg_mean_absolute_error=-15.563, r2=-0.031, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.597, r2=-0.008, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=linear, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=linear, n_estimators=400, neg_mean_absolute_error=-15.813, r2=-0.007, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=50, neg_mean_absolute_error=-23.074, r2=-0.673, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=50, neg_mean_absolute_error=-21.715, r2=-0.565, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=50, neg_mean_absolute_error=-22.865, r2=-0.734, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=50, neg_mean_absolute_error=-21.883, r2=-0.359, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=50 ..\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=50, neg_mean_absolute_error=-21.789, r2=-0.488, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=100 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=100, neg_mean_absolute_error=-23.074, r2=-0.673, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=100 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=100, neg_mean_absolute_error=-21.696, r2=-0.562, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=100 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=100, neg_mean_absolute_error=-22.865, r2=-0.734, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=100 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=100, neg_mean_absolute_error=-21.883, r2=-0.359, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=100 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=100, neg_mean_absolute_error=-21.789, r2=-0.488, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=200, neg_mean_absolute_error=-23.074, r2=-0.673, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=200, neg_mean_absolute_error=-21.696, r2=-0.562, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=200, neg_mean_absolute_error=-22.865, r2=-0.734, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=200, neg_mean_absolute_error=-21.883, r2=-0.359, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=200 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=200, neg_mean_absolute_error=-21.789, r2=-0.488, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=400, neg_mean_absolute_error=-23.074, r2=-0.673, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=400, neg_mean_absolute_error=-21.696, r2=-0.562, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=400, neg_mean_absolute_error=-22.865, r2=-0.734, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=400, neg_mean_absolute_error=-21.883, r2=-0.359, total=   0.0s\n[CV] learning_rate=0.7878436092009511, loss=square, n_estimators=400 .\n[CV]  learning_rate=0.7878436092009511, loss=square, n_estimators=400, neg_mean_absolute_error=-21.789, r2=-0.488, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=50, neg_mean_absolute_error=-20.506, r2=-0.391, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=50, neg_mean_absolute_error=-19.893, r2=-0.362, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=50, neg_mean_absolute_error=-19.380, r2=-0.331, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=50, neg_mean_absolute_error=-21.128, r2=-0.291, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=50, neg_mean_absolute_error=-20.218, r2=-0.331, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=100, neg_mean_absolute_error=-21.060, r2=-0.448, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.893, r2=-0.362, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.380, r2=-0.331, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=100, neg_mean_absolute_error=-21.665, r2=-0.337, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=100, neg_mean_absolute_error=-21.105, r2=-0.419, total=   0.3s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=200, neg_mean_absolute_error=-21.060, r2=-0.448, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.893, r2=-0.362, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.380, r2=-0.331, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=200, neg_mean_absolute_error=-21.665, r2=-0.337, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=200, neg_mean_absolute_error=-21.105, r2=-0.419, total=   0.3s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=400, neg_mean_absolute_error=-21.060, r2=-0.448, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.893, r2=-0.362, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.380, r2=-0.331, total=   0.1s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=400, neg_mean_absolute_error=-21.665, r2=-0.337, total=   0.2s\n[CV] learning_rate=0.7878436092009511, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.7878436092009511, loss=exponential, n_estimators=400, neg_mean_absolute_error=-21.105, r2=-0.419, total=   0.3s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.433, r2=-0.052, total=   0.0s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.828, r2=-0.079, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.561, r2=-0.093, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.901, r2=-0.018, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.184, r2=-0.021, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.433, r2=-0.052, total=   0.0s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.828, r2=-0.079, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.561, r2=-0.093, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.901, r2=-0.018, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.184, r2=-0.021, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.433, r2=-0.052, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.828, r2=-0.079, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.561, r2=-0.093, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.901, r2=-0.018, total=   0.0s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.184, r2=-0.021, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.433, r2=-0.052, total=   0.0s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.828, r2=-0.079, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.561, r2=-0.093, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.901, r2=-0.018, total=   0.0s\n[CV] learning_rate=0.45544203516917636, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.184, r2=-0.021, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=50, neg_mean_absolute_error=-21.022, r2=-0.443, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=50, neg_mean_absolute_error=-22.241, r2=-0.637, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=50, neg_mean_absolute_error=-21.411, r2=-0.557, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=50, neg_mean_absolute_error=-23.199, r2=-0.481, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=50, neg_mean_absolute_error=-21.843, r2=-0.497, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=100, neg_mean_absolute_error=-21.022, r2=-0.443, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=100, neg_mean_absolute_error=-22.241, r2=-0.637, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=100, neg_mean_absolute_error=-21.411, r2=-0.557, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=100, neg_mean_absolute_error=-23.199, r2=-0.481, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=100, neg_mean_absolute_error=-21.843, r2=-0.497, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=200, neg_mean_absolute_error=-21.022, r2=-0.443, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=200, neg_mean_absolute_error=-22.241, r2=-0.637, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=200, neg_mean_absolute_error=-21.411, r2=-0.557, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=200, neg_mean_absolute_error=-23.199, r2=-0.481, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=200, neg_mean_absolute_error=-21.843, r2=-0.497, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=400, neg_mean_absolute_error=-21.022, r2=-0.443, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=400, neg_mean_absolute_error=-22.241, r2=-0.637, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=400, neg_mean_absolute_error=-21.411, r2=-0.557, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=400, neg_mean_absolute_error=-23.199, r2=-0.481, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=square, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=square, n_estimators=400, neg_mean_absolute_error=-21.843, r2=-0.497, total=   0.1s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=50, neg_mean_absolute_error=-18.934, r2=-0.242, total=   0.2s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=50, neg_mean_absolute_error=-19.086, r2=-0.279, total=   0.2s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=50, neg_mean_absolute_error=-19.352, r2=-0.327, total=   0.2s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=50, neg_mean_absolute_error=-19.364, r2=-0.152, total=   0.2s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=50, neg_mean_absolute_error=-18.414, r2=-0.165, total=   0.2s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=100, neg_mean_absolute_error=-20.158, r2=-0.357, total=   0.3s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.263, r2=-0.294, total=   0.2s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=100, neg_mean_absolute_error=-21.050, r2=-0.510, total=   0.4s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=100, neg_mean_absolute_error=-20.759, r2=-0.260, total=   0.3s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=100, neg_mean_absolute_error=-20.052, r2=-0.315, total=   0.3s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=200, neg_mean_absolute_error=-20.158, r2=-0.357, total=   0.3s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.263, r2=-0.294, total=   0.2s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=200, neg_mean_absolute_error=-21.921, r2=-0.613, total=   0.6s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=200, neg_mean_absolute_error=-20.759, r2=-0.260, total=   0.3s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=200, neg_mean_absolute_error=-20.052, r2=-0.315, total=   0.3s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=400, neg_mean_absolute_error=-20.158, r2=-0.357, total=   0.3s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.263, r2=-0.294, total=   0.2s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=400, neg_mean_absolute_error=-21.921, r2=-0.613, total=   0.6s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=400, neg_mean_absolute_error=-20.759, r2=-0.260, total=   0.3s\n[CV] learning_rate=0.45544203516917636, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.45544203516917636, loss=exponential, n_estimators=400, neg_mean_absolute_error=-20.052, r2=-0.315, total=   0.4s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.639, r2=-0.066, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.515, r2=-0.062, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.078, r2=-0.059, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=50, neg_mean_absolute_error=-17.047, r2=-0.022, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.218, r2=-0.021, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.639, r2=-0.066, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.515, r2=-0.062, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.078, r2=-0.059, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=100, neg_mean_absolute_error=-17.047, r2=-0.022, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.218, r2=-0.021, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.639, r2=-0.066, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.515, r2=-0.062, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.078, r2=-0.059, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=200, neg_mean_absolute_error=-17.047, r2=-0.022, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.218, r2=-0.021, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.639, r2=-0.066, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.515, r2=-0.062, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.078, r2=-0.059, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=400, neg_mean_absolute_error=-17.047, r2=-0.022, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.218, r2=-0.021, total=   0.1s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=50, neg_mean_absolute_error=-21.466, r2=-0.489, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=50, neg_mean_absolute_error=-20.610, r2=-0.445, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=50, neg_mean_absolute_error=-21.164, r2=-0.525, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=50, neg_mean_absolute_error=-22.168, r2=-0.382, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=50, neg_mean_absolute_error=-20.877, r2=-0.396, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=100, neg_mean_absolute_error=-21.466, r2=-0.489, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=100, neg_mean_absolute_error=-20.610, r2=-0.445, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=100, neg_mean_absolute_error=-21.606, r2=-0.576, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=100, neg_mean_absolute_error=-22.567, r2=-0.420, total=   0.3s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=100, neg_mean_absolute_error=-21.511, r2=-0.463, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=200, neg_mean_absolute_error=-21.466, r2=-0.489, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=200, neg_mean_absolute_error=-20.610, r2=-0.445, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=200, neg_mean_absolute_error=-21.606, r2=-0.576, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=200, neg_mean_absolute_error=-22.567, r2=-0.420, total=   0.3s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=200, neg_mean_absolute_error=-21.511, r2=-0.463, total=   0.3s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=400, neg_mean_absolute_error=-21.466, r2=-0.489, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=400, neg_mean_absolute_error=-20.610, r2=-0.445, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=400, neg_mean_absolute_error=-21.606, r2=-0.576, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=400, neg_mean_absolute_error=-22.567, r2=-0.420, total=   0.3s\n[CV] learning_rate=0.18853621987376834, loss=square, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=square, n_estimators=400, neg_mean_absolute_error=-21.511, r2=-0.463, total=   0.3s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=50, neg_mean_absolute_error=-16.968, r2=-0.087, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.181, r2=-0.107, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=50, neg_mean_absolute_error=-16.920, r2=-0.115, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.679, r2=-0.050, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=50, neg_mean_absolute_error=-16.891, r2=-0.056, total=   0.2s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=100, neg_mean_absolute_error=-18.468, r2=-0.199, total=   0.4s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=100, neg_mean_absolute_error=-18.551, r2=-0.224, total=   0.4s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=100, neg_mean_absolute_error=-18.365, r2=-0.233, total=   0.4s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.005, r2=-0.129, total=   0.4s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=100, neg_mean_absolute_error=-18.019, r2=-0.134, total=   0.4s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.177, r2=-0.262, total=   0.5s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.425, r2=-0.310, total=   0.6s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.651, r2=-0.358, total=   0.6s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=200, neg_mean_absolute_error=-20.560, r2=-0.243, total=   0.8s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=200, neg_mean_absolute_error=-18.697, r2=-0.191, total=   0.8s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.177, r2=-0.262, total=   0.5s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.425, r2=-0.310, total=   0.6s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.651, r2=-0.358, total=   0.6s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=400, neg_mean_absolute_error=-20.560, r2=-0.243, total=   0.8s\n[CV] learning_rate=0.18853621987376834, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.18853621987376834, loss=exponential, n_estimators=400, neg_mean_absolute_error=-18.697, r2=-0.191, total=   0.6s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.548, r2=-0.061, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.483, r2=-0.062, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.168, r2=-0.064, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.943, r2=-0.018, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.030, r2=-0.014, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.548, r2=-0.061, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.483, r2=-0.062, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.168, r2=-0.064, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.943, r2=-0.018, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.030, r2=-0.014, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.548, r2=-0.061, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.483, r2=-0.062, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.168, r2=-0.064, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.943, r2=-0.018, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.030, r2=-0.014, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.548, r2=-0.061, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.483, r2=-0.062, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.168, r2=-0.064, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.943, r2=-0.018, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.030, r2=-0.014, total=   0.1s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=50, neg_mean_absolute_error=-22.353, r2=-0.590, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=50, neg_mean_absolute_error=-22.051, r2=-0.613, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=50, neg_mean_absolute_error=-22.359, r2=-0.668, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=50, neg_mean_absolute_error=-22.900, r2=-0.452, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=50, neg_mean_absolute_error=-21.745, r2=-0.485, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=100, neg_mean_absolute_error=-22.646, r2=-0.624, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=100, neg_mean_absolute_error=-22.394, r2=-0.652, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=100, neg_mean_absolute_error=-22.421, r2=-0.675, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=100, neg_mean_absolute_error=-22.904, r2=-0.452, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=100, neg_mean_absolute_error=-21.966, r2=-0.507, total=   0.4s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=200, neg_mean_absolute_error=-22.646, r2=-0.624, total=   0.4s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=200, neg_mean_absolute_error=-22.394, r2=-0.652, total=   0.4s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=200, neg_mean_absolute_error=-22.421, r2=-0.675, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=200, neg_mean_absolute_error=-22.904, r2=-0.452, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=200, neg_mean_absolute_error=-21.966, r2=-0.507, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=400, neg_mean_absolute_error=-22.646, r2=-0.624, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=400, neg_mean_absolute_error=-22.394, r2=-0.652, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=400, neg_mean_absolute_error=-22.421, r2=-0.675, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=400, neg_mean_absolute_error=-22.904, r2=-0.452, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=square, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=square, n_estimators=400, neg_mean_absolute_error=-21.966, r2=-0.507, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.503, r2=-0.125, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.614, r2=-0.141, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.244, r2=-0.141, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=50, neg_mean_absolute_error=-18.118, r2=-0.074, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.178, r2=-0.075, total=   0.2s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=100, neg_mean_absolute_error=-18.707, r2=-0.221, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.298, r2=-0.297, total=   0.4s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.090, r2=-0.301, total=   0.4s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.694, r2=-0.176, total=   0.4s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=100, neg_mean_absolute_error=-18.637, r2=-0.185, total=   0.4s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=200, neg_mean_absolute_error=-18.707, r2=-0.221, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=200, neg_mean_absolute_error=-20.135, r2=-0.387, total=   0.5s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.404, r2=-0.333, total=   0.4s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=200, neg_mean_absolute_error=-20.616, r2=-0.247, total=   0.6s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.363, r2=-0.249, total=   0.5s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=400, neg_mean_absolute_error=-18.707, r2=-0.221, total=   0.3s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=400, neg_mean_absolute_error=-20.135, r2=-0.387, total=   0.5s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.404, r2=-0.333, total=   0.4s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=400, neg_mean_absolute_error=-20.616, r2=-0.247, total=   0.6s\n[CV] learning_rate=0.24916352789976326, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.24916352789976326, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.363, r2=-0.249, total=   0.5s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.458, r2=-0.058, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.375, r2=-0.050, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=50, neg_mean_absolute_error=-15.986, r2=-0.052, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=50, neg_mean_absolute_error=-17.033, r2=-0.024, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=50, neg_mean_absolute_error=-16.069, r2=-0.017, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.458, r2=-0.058, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.375, r2=-0.050, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=100, neg_mean_absolute_error=-15.986, r2=-0.052, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=100, neg_mean_absolute_error=-17.033, r2=-0.024, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=100, neg_mean_absolute_error=-16.069, r2=-0.017, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.458, r2=-0.058, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.375, r2=-0.050, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=200, neg_mean_absolute_error=-15.986, r2=-0.052, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=200, neg_mean_absolute_error=-17.033, r2=-0.024, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=200, neg_mean_absolute_error=-16.069, r2=-0.017, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.458, r2=-0.058, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.375, r2=-0.050, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=400, neg_mean_absolute_error=-15.986, r2=-0.052, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=400, neg_mean_absolute_error=-17.033, r2=-0.024, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=linear, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=linear, n_estimators=400, neg_mean_absolute_error=-16.069, r2=-0.017, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=50, neg_mean_absolute_error=-22.463, r2=-0.603, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=50, neg_mean_absolute_error=-21.690, r2=-0.566, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=50, neg_mean_absolute_error=-21.815, r2=-0.602, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=50, neg_mean_absolute_error=-22.706, r2=-0.433, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=50 .\n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=50, neg_mean_absolute_error=-20.731, r2=-0.381, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=100, neg_mean_absolute_error=-22.463, r2=-0.603, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=100, neg_mean_absolute_error=-21.690, r2=-0.566, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=100, neg_mean_absolute_error=-22.470, r2=-0.683, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=100, neg_mean_absolute_error=-22.706, r2=-0.433, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=100, neg_mean_absolute_error=-20.731, r2=-0.381, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=200, neg_mean_absolute_error=-22.463, r2=-0.603, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=200, neg_mean_absolute_error=-21.690, r2=-0.566, total=   0.3s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=200, neg_mean_absolute_error=-22.470, r2=-0.683, total=   0.3s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=200, neg_mean_absolute_error=-22.706, r2=-0.433, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=200, neg_mean_absolute_error=-20.731, r2=-0.381, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=400, neg_mean_absolute_error=-22.463, r2=-0.603, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=400, neg_mean_absolute_error=-21.690, r2=-0.566, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=400, neg_mean_absolute_error=-22.470, r2=-0.683, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=400, neg_mean_absolute_error=-22.706, r2=-0.433, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=square, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=square, n_estimators=400, neg_mean_absolute_error=-20.731, r2=-0.381, total=   0.1s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.515, r2=-0.125, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.497, r2=-0.131, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.430, r2=-0.155, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=50, neg_mean_absolute_error=-18.181, r2=-0.075, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=50 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=50, neg_mean_absolute_error=-17.347, r2=-0.087, total=   0.2s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.188, r2=-0.264, total=   0.4s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.095, r2=-0.277, total=   0.4s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.095, r2=-0.301, total=   0.4s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=100, neg_mean_absolute_error=-19.734, r2=-0.179, total=   0.4s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=100 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=100, neg_mean_absolute_error=-18.684, r2=-0.190, total=   0.4s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.188, r2=-0.264, total=   0.4s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.227, r2=-0.290, total=   0.4s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=200, neg_mean_absolute_error=-19.932, r2=-0.387, total=   0.5s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=200, neg_mean_absolute_error=-20.684, r2=-0.253, total=   0.6s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=200 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=200, neg_mean_absolute_error=-20.327, r2=-0.342, total=   0.8s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.188, r2=-0.264, total=   0.4s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.227, r2=-0.290, total=   0.4s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=400, neg_mean_absolute_error=-19.932, r2=-0.387, total=   0.5s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=400, neg_mean_absolute_error=-20.684, r2=-0.253, total=   0.6s\n[CV] learning_rate=0.23446570350767693, loss=exponential, n_estimators=400 \n[CV]  learning_rate=0.23446570350767693, loss=exponential, n_estimators=400, neg_mean_absolute_error=-20.375, r2=-0.346, total=   0.8s\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:  1.0min finished\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5, estimator=AdaBoostRegressor(random_state=42),\n             param_grid={'learning_rate': [0.7878436092009511,\n                                           0.45544203516917636,\n                                           0.18853621987376834,\n                                           0.24916352789976326,\n                                           0.23446570350767693],\n                         'loss': ['linear', 'square', 'exponential'],\n                         'n_estimators': [50, 100, 200, 400]},\n             refit='r2', scoring=['r2', 'neg_mean_absolute_error'], verbose=3)"},"metadata":{}}]},{"cell_type":"code","source":"print(AdaBoostReg_GS.best_params_)\nprint(AdaBoostReg_GS.best_score_)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:57:16.803954Z","iopub.execute_input":"2022-08-28T07:57:16.804244Z","iopub.status.idle":"2022-08-28T07:57:16.809868Z","shell.execute_reply.started":"2022-08-28T07:57:16.804196Z","shell.execute_reply":"2022-08-28T07:57:16.809119Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"{'learning_rate': 0.7878436092009511, 'loss': 'linear', 'n_estimators': 50}\n-0.023615265377149884\n","output_type":"stream"}]},{"cell_type":"code","source":"model_pred = AdaBoostReg_GS.predict(X_test)\nAdaBoostReg_r2 = r2_score(y_test, model_pred)\nAdaBoostReg_r2","metadata":{"execution":{"iopub.status.busy":"2022-08-28T07:57:18.856703Z","iopub.execute_input":"2022-08-28T07:57:18.857181Z","iopub.status.idle":"2022-08-28T07:57:18.869982Z","shell.execute_reply.started":"2022-08-28T07:57:18.857146Z","shell.execute_reply":"2022-08-28T07:57:18.869094Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"-0.05968743478816685"},"metadata":{}}]},{"cell_type":"markdown","source":"# Random Forest Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nRFreg = RandomForestRegressor(random_state=42)\nRFreg_params = {'max_features': ['sqrt', 'log2'],\n                'max_depth': [5, 6, 7],\n                'bootstrap': [True, False],\n                'warm_start': [True, False],\n                'oob_score': [True, False]}\n\nRFreg_GS = GridSearchCV(RFreg,\n                        RFreg_params,\n                        scoring = [\"r2\", \"neg_mean_absolute_error\"],\n                        refit = \"r2\",\n                        cv = 5,\n                        n_jobs = -1,\n                        verbose=3)\n\nRFreg_GS.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T08:06:32.012479Z","iopub.execute_input":"2022-08-28T08:06:32.012757Z","iopub.status.idle":"2022-08-28T08:07:02.987142Z","shell.execute_reply.started":"2022-08-28T08:06:32.012728Z","shell.execute_reply":"2022-08-28T08:07:02.986509Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 48 candidates, totalling 240 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","output_type":"stream"},{"name":"stdout","text":"\n[CV] bootstrap=False, criterion=absolute_error, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.156, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-14.871, r2=-0.003, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.155, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.163, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.822, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.156, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.871, r2=-0.003, total=   0.5s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.155, r2=-0.001, total=   0.4s","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    5.3s\n","output_type":"stream"},{"name":"stdout","text":"\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, criterion=absolute_error, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.1s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.163, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.822, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.156, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-14.871, r2=-0.003, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.155, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.163, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.822, r2=-0.001, total=   0.5s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.156, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.163, r2=-0.000, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.155, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.163, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.822, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.156, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-14.871, r2=-0.003, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.155, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.163, r2=-0.000, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.822, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.156, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.871, r2=-0.003, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.155, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.170, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.825, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.146, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-14.888, r2=-0.005, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.871, r2=-0.003, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.822, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.156, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-14.871, r2=-0.003, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.155, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.163, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.822, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.156, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.871, r2=-0.003, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.155, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.163, r2=-0.000, total=   0.3s\n[CV] bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.822, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.146, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-14.888, r2=-0.005, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.156, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.170, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.825, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.146, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.888, r2=-0.005, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.156, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.170, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.825, r2=-0.000, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.146, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-14.888, r2=-0.005, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.156, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.170, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.825, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.146, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.888, r2=-0.005, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.156, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.170, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.825, r2=-0.000, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.158, r2=-0.006, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-14.909, r2=-0.006, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.148, r2=-0.002, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False ","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   21.5s\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 392, in fit\n    for i, t in enumerate(trees))\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 1041, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 777, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 170, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1246, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 336, in fit\n    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\nKeyError: 'absolute_error'\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 392, in fit\n    for i, t in enumerate(trees))\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 1041, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 777, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 170, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1246, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 336, in fit\n    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\nKeyError: 'absolute_error'\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n","output_type":"stream"},{"name":"stdout","text":"\n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.156, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.170, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.825, r2=-0.000, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.146, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.888, r2=-0.005, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.156, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.170, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.825, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.146, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-14.888, r2=-0.005, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.156, r2=-0.001, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.170, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.825, r2=-0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.146, r2=-0.004, total=   0.6s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.888, r2=-0.005, total=   0.3s\n[CV] bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.156, r2=-0.001, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.200, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.813, r2=0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.158, r2=-0.006, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-14.909, r2=-0.006, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.148, r2=-0.002, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.200, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.813, r2=0.000, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.158, r2=-0.006, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.909, r2=-0.006, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.148, r2=-0.002, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.200, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.813, r2=0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.158, r2=-0.006, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-14.909, r2=-0.006, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.148, r2=-0.002, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.200, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.813, r2=0.000, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.158, r2=-0.006, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.909, r2=-0.006, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.148, r2=-0.002, total=   0.3s","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 392, in fit\n    for i, t in enumerate(trees))\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 1041, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 777, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 170, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1246, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 336, in fit\n    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\nKeyError: 'absolute_error'\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 392, in fit\n    for i, t in enumerate(trees))\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 1041, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 777, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 170, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1246, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 336, in fit\n    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\nKeyError: 'absolute_error'\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 392, in fit\n    for i, t in enumerate(trees))\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 1041, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 777, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n    self.results = batch()\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 170, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 1246, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 336, in fit\n    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\nKeyError: 'absolute_error'\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n","output_type":"stream"},{"name":"stdout","text":"\n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.200, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.813, r2=0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.158, r2=-0.006, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.909, r2=-0.006, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.148, r2=-0.002, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.200, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.813, r2=0.000, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.158, r2=-0.006, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-14.909, r2=-0.006, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=-15.148, r2=-0.002, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.200, r2=-0.004, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=-15.813, r2=0.000, total=   0.4s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.158, r2=-0.006, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.909, r2=-0.006, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.148, r2=-0.002, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.200, r2=-0.004, total=   0.3s\n[CV] bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=True, max_depth=7, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.813, r2=0.000, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.164, r2=-0.004, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.176, r2=-0.000, total=   0.2s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.148, r2=0.001, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.164, r2=-0.004, total=   0.2s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.842, r2=-0.002, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.148, r2=0.001, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.886, r2=-0.003, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.842, r2=-0.002, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.176, r2=-0.000, total=   0.3s","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n","output_type":"stream"},{"name":"stdout","text":"\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.886, r2=-0.003, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.842, r2=-0.002, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.176, r2=-0.000, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.886, r2=-0.003, total=   0.2s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.164, r2=-0.004, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.176, r2=-0.000, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.148, r2=0.001, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.164, r2=-0.004, total=   0.2s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.842, r2=-0.002, total=   0.3s\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.148, r2=0.001, total=   0.4s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.894, r2=-0.005, total=   0.4s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.840, r2=-0.001, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.191, r2=-0.002, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.894, r2=-0.005, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.166, r2=-0.005, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.191, r2=-0.002, total=   0.3s","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\", line 351, in fit\n    raise ValueError(\"Out of bag estimation only available\"\nValueError: Out of bag estimation only available if bootstrap=True\n\n  FitFailedWarning)\n","output_type":"stream"},{"name":"stdout","text":"\n[CV] bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=5, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.886, r2=-0.003, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.166, r2=-0.005, total=   0.5s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.191, r2=-0.002, total=   0.4s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.150, r2=-0.001, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.166, r2=-0.005, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.840, r2=-0.001, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.150, r2=-0.001, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-14.894, r2=-0.005, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.840, r2=-0.001, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.191, r2=-0.002, total=   0.3s\n[CV] bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=6, max_features=log2, oob_score=False, warm_start=False, neg_mean_absolute_error=-14.894, r2=-0.005, total=   0.3s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=True, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=True, warm_start=False, neg_mean_absolute_error=nan, r2=nan, total=   0.0s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.182, r2=-0.008, total=   0.3s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.236, r2=-0.007, total=   0.3s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=True, neg_mean_absolute_error=-15.151, r2=-0.003, total=   0.3s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.182, r2=-0.008, total=   0.3s\n[CV] bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False \n[CV]  bootstrap=False, max_depth=7, max_features=sqrt, oob_score=False, warm_start=False, neg_mean_absolute_error=-15.839, r2=-0.000, total=   0.3s","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 237 out of 240 | elapsed:   30.1s remaining:    0.4s\n[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   30.7s finished\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42), n_jobs=-1,\n             param_grid={'bootstrap': [True, False], 'max_depth': [5, 6, 7],\n                         'max_features': ['sqrt', 'log2'],\n                         'oob_score': [True, False],\n                         'warm_start': [True, False]},\n             refit='r2', scoring=['r2', 'neg_mean_absolute_error'], verbose=3)"},"metadata":{}}]},{"cell_type":"code","source":"print(RFreg_GS.best_params_)\nprint(RFreg_GS.best_score_)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T08:07:11.116724Z","iopub.execute_input":"2022-08-28T08:07:11.117131Z","iopub.status.idle":"2022-08-28T08:07:11.124964Z","shell.execute_reply.started":"2022-08-28T08:07:11.117094Z","shell.execute_reply":"2022-08-28T08:07:11.124033Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"{'bootstrap': False, 'max_depth': 5, 'max_features': 'sqrt', 'oob_score': False, 'warm_start': True}\n-0.0017657271100173454\n","output_type":"stream"}]},{"cell_type":"code","source":"model_pred = RFreg_GS.predict(X_test)\nRFreg_r2 = r2_score(y_test, model_pred)\nRFreg_r2","metadata":{"execution":{"iopub.status.busy":"2022-08-28T08:07:21.809109Z","iopub.execute_input":"2022-08-28T08:07:21.809382Z","iopub.status.idle":"2022-08-28T08:07:21.834053Z","shell.execute_reply.started":"2022-08-28T08:07:21.809351Z","shell.execute_reply":"2022-08-28T08:07:21.833061Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"-0.0017640342469860126"},"metadata":{}}]},{"cell_type":"markdown","source":"# SVM Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\n\nSVMreg = SVR()\nSVMreg_params = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n                 'degree': [2, 3, 4],\n                 'C': list(np.random.random_sample((5,))),\n                 'gamma': ['scale', 'auto'] + list(np.random.random_sample((3,)))}\n\nSVMreg_GS = GridSearchCV(SVMreg,\n                        SVMreg_params,\n                        scoring = [\"r2\", \"neg_mean_absolute_error\"],\n                        refit = \"r2\",\n                        cv = 5,\n                        n_jobs = -1,\n                        verbose=3)\n\nSVMreg_GS.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T08:07:45.111139Z","iopub.execute_input":"2022-08-28T08:07:45.111932Z","iopub.status.idle":"2022-08-28T08:42:59.637173Z","shell.execute_reply.started":"2022-08-28T08:07:45.111895Z","shell.execute_reply":"2022-08-28T08:42:59.636365Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   38.4s\n","output_type":"stream"},{"name":"stdout","text":"[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.8s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   2.2s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.454, r2=-0.042, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.271, r2=-0.063, total=   2.0s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.519, r2=-0.043, total=   3.0s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.227, r2=-0.039, total=   3.2s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.940, r2=-0.082, total=   3.0s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.479, r2=-0.050, total=   3.8s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-15.291, r2=-0.060, total=   4.1s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   2.4s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   2.0s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.471, r2=-0.044, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.299, r2=-0.063, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.524, r2=-0.044, total=   3.2s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.224, r2=-0.040, total=   3.0s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.938, r2=-0.079, total=   3.0s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.469, r2=-0.045, total=   3.5s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.294, r2=-0.063, total=   3.2s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.8s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.470, r2=-0.044, total=   2.3s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.298, r2=-0.063, total=   2.0s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.523, r2=-0.044, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.225, r2=-0.040, total=   3.0s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.938, r2=-0.079, total=   3.5s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.469, r2=-0.044, total=   3.5s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.294, r2=-0.063, total=   3.2s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.525, r2=-0.043, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.212, r2=-0.039, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.923, r2=-0.080, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   3.3s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.262, r2=-0.063, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.833, r2=-2.315, total=   4.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.170, r2=-2.258, total=   4.5s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid [CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.8s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.526, r2=-0.044, total=   2.5s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.215, r2=-0.039, total=   2.0s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.929, r2=-0.080, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.455, r2=-0.044, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.268, r2=-0.063, total=   3.3s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.519, r2=-0.047, total=   3.8s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.248, r2=-0.039, total=   3.8s\n[CV] C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.967, r2=-0.086, total=   4.2s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   2.5s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.532, r2=-0.044, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.231, r2=-0.038, total=   2.0s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.077, total=   2.3s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.467, r2=-0.043, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.287, r2=-0.063, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.2s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.228, r2=-0.040, total=   3.4s\n[CV] C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.935, r2=-0.077, total=   3.3s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.531, r2=-0.045, total=   2.4s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.230, r2=-0.038, total=   2.0s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.077, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.466, r2=-0.043, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.286, r2=-0.063, total=   3.2s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.520, r2=-0.045, total=   3.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.227, r2=-0.040, total=   3.2s\n[CV] C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.935, r2=-0.078, total=   3.5s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.474, r2=-0.044, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.257, r2=-0.062, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.519, r2=-0.044, total=   3.3s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.230, r2=-0.038, total=   3.0s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.944, r2=-0.083, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.771, r2=-2.344, total=   4.3s\n[CV] C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-24.016, r2=-1.492, total=   4.3s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.8s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear ","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  2.9min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV]  C=0.3066326133977365, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.897, r2=-2.173, total=   4.2s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.456, r2=-0.043, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.268, r2=-0.062, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.518, r2=-0.043, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.227, r2=-0.038, total=   3.2s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.943, r2=-0.082, total=   3.0s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.252, r2=-0.249, total=   3.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.916, r2=-0.200, total=   4.3s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.8s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   1.9s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.9s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.522, r2=-0.044, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.213, r2=-0.040, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.912, r2=-0.080, total=   2.5s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.455, r2=-0.044, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.268, r2=-0.063, total=   3.5s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.519, r2=-0.047, total=   4.1s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.248, r2=-0.039, total=   3.8s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.967, r2=-0.086, total=   3.8s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   2.0s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.475, r2=-0.045, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.302, r2=-0.064, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.524, r2=-0.044, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.224, r2=-0.040, total=   3.2s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.938, r2=-0.079, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.469, r2=-0.045, total=   3.2s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.294, r2=-0.063, total=   3.3s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   2.3s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.474, r2=-0.045, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.301, r2=-0.064, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.523, r2=-0.044, total=   3.3s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.225, r2=-0.040, total=   3.0s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.938, r2=-0.079, total=   3.0s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.469, r2=-0.044, total=   3.5s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.294, r2=-0.063, total=   3.2s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.8s\n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   1.8s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   2.6s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.530, r2=-0.043, total=   2.4s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.211, r2=-0.039, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.925, r2=-0.079, total=   2.1s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.454, r2=-0.044, total=   2.9s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.266, r2=-0.063, total=   3.2s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-17.199, r2=-0.357, total=   4.0s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.172, r2=-0.252, total=   4.0s\n[CV] C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.694, r2=-0.253, total=   4.2s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.8s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.451, r2=-0.043, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.262, r2=-0.063, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.519, r2=-0.043, total=   3.4s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.227, r2=-0.039, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.940, r2=-0.082, total=   3.6s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.479, r2=-0.050, total=   4.1s\n[CV] C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-15.291, r2=-0.060, total=   3.8s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.8s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   1.8s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   2.2s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.045, total=   2.0s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.233, r2=-0.039, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.945, r2=-0.077, total=   2.0s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.467, r2=-0.043, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.287, r2=-0.063, total=   3.3s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.2s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.228, r2=-0.040, total=   3.2s\n[CV] C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.935, r2=-0.077, total=   3.7s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   2.0s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   2.4s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.045, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.231, r2=-0.039, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.942, r2=-0.077, total=   2.3s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.466, r2=-0.043, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.286, r2=-0.063, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.520, r2=-0.045, total=   3.3s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.227, r2=-0.040, total=   3.5s\n[CV] C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.935, r2=-0.078, total=   3.3s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.497, r2=-0.048, total=   2.5s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.243, r2=-0.059, total=   2.2s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.519, r2=-0.044, total=   3.5s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.230, r2=-0.038, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.944, r2=-0.083, total=   3.2s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.771, r2=-2.344, total=   4.2s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-24.016, r2=-1.492, total=   4.3s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   1.8s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.8s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.517, r2=-0.044, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.216, r2=-0.039, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.915, r2=-0.080, total=   2.4s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.454, r2=-0.044, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.266, r2=-0.063, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-17.199, r2=-0.357, total=   4.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.172, r2=-0.252, total=   4.2s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.694, r2=-0.253, total=   4.0s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   2.2s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.9s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.517, r2=-0.045, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.224, r2=-0.040, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.919, r2=-0.082, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.455, r2=-0.044, total=   3.2s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.268, r2=-0.063, total=   2.9s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.519, r2=-0.047, total=   3.8s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.248, r2=-0.039, total=   4.1s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.967, r2=-0.086, total=   4.4s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.473, r2=-0.047, total=   2.2s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.305, r2=-0.065, total=   2.2s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.524, r2=-0.044, total=   3.0s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.224, r2=-0.040, total=   2.9s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.938, r2=-0.079, total=   3.2s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.469, r2=-0.045, total=   3.2s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.294, r2=-0.063, total=   3.2s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   2.0s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   1.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.547, r2=-0.048, total=   2.4s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.236, r2=-0.040, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.920, r2=-0.080, total=   2.8s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.262, r2=-0.063, total=   3.4s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.833, r2=-2.315, total=   4.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.170, r2=-2.258, total=   4.2s\n[CV] C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.897, r2=-2.173, total=   4.5s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.8s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.460, r2=-0.043, total=   2.1s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.252, r2=-0.062, total=   2.4s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.518, r2=-0.043, total=   3.0s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.227, r2=-0.038, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.943, r2=-0.082, total=   2.9s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.252, r2=-0.249, total=   5.3s\n[CV] C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.916, r2=-0.200, total=   4.0s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.461, r2=-0.043, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.265, r2=-0.061, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.519, r2=-0.043, total=   2.9s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.227, r2=-0.039, total=   3.3s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.940, r2=-0.082, total=   3.0s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-14.479, r2=-0.050, total=   3.8s\n[CV] C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.3066326133977365, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-15.291, r2=-0.060, total=   4.2s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   2.3s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.536, r2=-0.046, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.235, r2=-0.040, total=   2.5s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.950, r2=-0.078, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.467, r2=-0.043, total=   2.9s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.287, r2=-0.063, total=   2.9s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.6s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.228, r2=-0.040, total=   3.3s\n[CV] C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.3066326133977365, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.935, r2=-0.077, total=   3.3s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   2.0s","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  6.6min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   2.0s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.536, r2=-0.046, total=   2.8s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.234, r2=-0.039, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.949, r2=-0.078, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.466, r2=-0.043, total=   3.2s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.286, r2=-0.063, total=   3.0s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.520, r2=-0.045, total=   3.3s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.227, r2=-0.040, total=   3.3s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.935, r2=-0.078, total=   3.7s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.9s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.572, r2=-0.053, total=   2.3s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.288, r2=-0.060, total=   2.6s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.519, r2=-0.044, total=   3.6s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.230, r2=-0.038, total=   2.9s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.944, r2=-0.083, total=   2.9s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.771, r2=-2.344, total=   4.5s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-24.016, r2=-1.492, total=   4.2s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.9s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.541, r2=-0.048, total=   2.2s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.247, r2=-0.042, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.926, r2=-0.081, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.454, r2=-0.044, total=   3.5s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.266, r2=-0.063, total=   3.4s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-17.199, r2=-0.357, total=   4.2s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.172, r2=-0.252, total=   4.2s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.694, r2=-0.253, total=   4.0s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.456, r2=-0.043, total=   2.4s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.268, r2=-0.062, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.516, r2=-0.043, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.223, r2=-0.038, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.937, r2=-0.081, total=   4.0s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.099, r2=-0.229, total=   4.0s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.628, r2=-0.171, total=   4.1s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.474, r2=-0.046, total=   2.7s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.304, r2=-0.065, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.523, r2=-0.044, total=   3.0s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.225, r2=-0.040, total=   3.3s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.938, r2=-0.079, total=   3.0s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.469, r2=-0.044, total=   3.3s\n[CV] C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.294, r2=-0.063, total=   3.5s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.045, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.046, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.062, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.615, r2=-0.055, total=   2.4s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.310, r2=-0.044, total=   2.7s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.930, r2=-0.080, total=   2.8s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   2.9s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.262, r2=-0.063, total=   2.9s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.833, r2=-2.315, total=   4.5s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.170, r2=-2.258, total=   4.2s\n[CV] C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-25.897, r2=-2.173, total=   4.5s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.224, r2=-0.038, total=   1.8s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.924, r2=-0.079, total=   1.9s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.494, r2=-0.046, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.261, r2=-0.061, total=   2.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.518, r2=-0.043, total=   3.3s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.227, r2=-0.038, total=   3.7s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.943, r2=-0.082, total=   3.1s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.252, r2=-0.249, total=   4.3s\n[CV] C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.3066326133977365, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-16.916, r2=-0.200, total=   4.0s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.8s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.530, r2=-0.043, total=   2.4s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.212, r2=-0.039, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.925, r2=-0.079, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.455, r2=-0.045, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.260, r2=-0.063, total=   3.4s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.062, r2=-0.212, total=   4.7s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-15.897, r2=-0.205, total=   4.0s\n[CV] C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.533, r2=-0.247, total=   4.3s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.532, r2=-0.045, total=   2.0s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.228, r2=-0.038, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.077, total=   2.3s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   2.9s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.282, r2=-0.064, total=   2.9s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.3s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.040, total=   3.6s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.938, r2=-0.079, total=   3.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   2.6s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   2.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.533, r2=-0.045, total=   2.5s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.227, r2=-0.038, total=   2.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.937, r2=-0.078, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.281, r2=-0.064, total=   3.3s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.522, r2=-0.045, total=   3.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.039, total=   3.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.937, r2=-0.079, total=   3.7s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.490, r2=-0.045, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.252, r2=-0.060, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.515, r2=-0.043, total=   3.3s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.039, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.082, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-35.997, r2=-6.987, total=   5.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.509, r2=-6.079, total=   4.3s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.8s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.8s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.522, r2=-0.043, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.209, r2=-0.039, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.926, r2=-0.080, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   2.9s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.255, r2=-0.062, total=   3.3s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.667, r2=-1.258, total=   4.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.495, r2=-1.279, total=   4.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.662, r2=-1.115, total=   4.6s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=linear ......\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.469, r2=-0.043, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.297, r2=-0.063, total=   2.3s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   2.9s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   2.9s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.947, r2=-0.082, total=   2.9s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.471, r2=-0.044, total=   3.6s\n[CV] C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.290, r2=-0.064, total=   3.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   2.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   2.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.468, r2=-0.043, total=   2.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.296, r2=-0.063, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   3.3s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.950, r2=-0.083, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.472, r2=-0.044, total=   3.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.289, r2=-0.064, total=   3.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   2.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.218, r2=-0.039, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.921, r2=-0.080, total=   2.5s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.448, r2=-0.043, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.247, r2=-0.061, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.400, r2=-6.955, total=   5.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-34.993, r2=-6.772, total=   4.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-35.836, r2=-6.320, total=   4.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   2.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.466, r2=-0.044, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.265, r2=-0.063, total=   2.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.518, r2=-0.043, total=   2.9s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.227, r2=-0.038, total=   3.2s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.081, total=   3.0s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.295, r2=-1.190, total=   4.1s\n[CV] C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.272, r2=-0.897, total=   4.5s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.8s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.8s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.517, r2=-0.044, total=   2.2s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.216, r2=-0.039, total=   2.4s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.516, r2=-0.043, total=   3.6s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.223, r2=-0.038, total=   2.9s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.937, r2=-0.081, total=   3.2s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.099, r2=-0.229, total=   4.1s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.628, r2=-0.171, total=   3.9s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.045, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.230, r2=-0.039, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.941, r2=-0.077, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   3.7s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.282, r2=-0.064, total=   3.2s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.3s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.040, total=   3.6s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.938, r2=-0.079, total=   3.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.044, total=   2.0s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.230, r2=-0.039, total=   2.4s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.939, r2=-0.076, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   3.0s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.281, r2=-0.064, total=   2.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.522, r2=-0.045, total=   4.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.039, total=   3.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.937, r2=-0.079, total=   3.3s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.530, r2=-0.050, total=   2.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.246, r2=-0.057, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.515, r2=-0.043, total=   2.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.039, total=   3.3s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.082, total=   2.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-35.997, r2=-6.987, total=   4.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.509, r2=-6.079, total=   5.3s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.8s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.453, r2=-0.042, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.257, r2=-0.062, total=   2.3s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.908, r2=-0.079, total=   2.7s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.455, r2=-0.045, total=   2.9s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.260, r2=-0.063, total=   2.9s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.062, r2=-0.212, total=   4.2s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-15.897, r2=-0.205, total=   4.0s\n[CV] C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.533, r2=-0.247, total=   4.3s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.473, r2=-0.044, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.301, r2=-0.064, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.2s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   3.6s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.947, r2=-0.082, total=   2.9s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.471, r2=-0.044, total=   3.2s\n[CV] C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.290, r2=-0.064, total=   3.4s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.471, r2=-0.044, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.300, r2=-0.063, total=   2.3s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.0s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   3.0s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.950, r2=-0.083, total=   3.1s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.472, r2=-0.044, total=   3.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.289, r2=-0.064, total=   3.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.8s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   2.0s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   2.0s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.555, r2=-0.050, total=   2.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.241, r2=-0.040, total=   2.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.926, r2=-0.083, total=   2.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.448, r2=-0.043, total=   3.3s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.247, r2=-0.061, total=   2.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.400, r2=-6.955, total=   4.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-34.993, r2=-6.772, total=   4.5s\n[CV] C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-35.836, r2=-6.320, total=   4.6s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 11.8min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.475, r2=-0.045, total=   2.4s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.248, r2=-0.060, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.518, r2=-0.043, total=   3.0s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.227, r2=-0.038, total=   3.0s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.081, total=   3.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.295, r2=-1.190, total=   4.1s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.272, r2=-0.897, total=   4.3s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   2.2s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   2.4s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.8s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.531, r2=-0.046, total=   2.2s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.240, r2=-0.041, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.920, r2=-0.081, total=   2.5s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.455, r2=-0.045, total=   2.9s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.260, r2=-0.063, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.062, r2=-0.212, total=   4.2s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-15.897, r2=-0.205, total=   3.9s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.533, r2=-0.247, total=   4.0s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   2.2s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.474, r2=-0.046, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.304, r2=-0.064, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   2.9s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   4.0s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.947, r2=-0.082, total=   3.2s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.471, r2=-0.044, total=   3.2s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.290, r2=-0.064, total=   3.6s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.475, r2=-0.045, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.303, r2=-0.064, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.950, r2=-0.083, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.472, r2=-0.044, total=   3.5s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.289, r2=-0.064, total=   3.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.8s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.522, r2=-0.046, total=   2.3s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.218, r2=-0.039, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.920, r2=-0.080, total=   2.1s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   2.9s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.255, r2=-0.062, total=   3.0s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.667, r2=-1.258, total=   4.5s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.495, r2=-1.279, total=   4.2s\n[CV] C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.662, r2=-1.115, total=   4.7s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.2s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.474, r2=-0.044, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.263, r2=-0.062, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.516, r2=-0.043, total=   3.2s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.223, r2=-0.038, total=   2.9s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.937, r2=-0.081, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.099, r2=-0.229, total=   4.3s\n[CV] C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.4954943017379566, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.628, r2=-0.171, total=   3.9s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.8s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   2.2s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.046, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.233, r2=-0.039, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.948, r2=-0.078, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   2.9s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.282, r2=-0.064, total=   4.1s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.3s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.040, total=   3.2s\n[CV] C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.4954943017379566, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.938, r2=-0.079, total=   3.6s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.046, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.232, r2=-0.039, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.946, r2=-0.077, total=   2.5s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   2.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.281, r2=-0.064, total=   2.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.522, r2=-0.045, total=   3.3s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.039, total=   3.5s\n[CV] C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.937, r2=-0.079, total=   3.3s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.671, r2=-0.059, total=   3.4s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.323, r2=-0.046, total=   2.4s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.081, total=   2.5s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.448, r2=-0.043, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.247, r2=-0.061, total=   3.3s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.400, r2=-6.955, total=   4.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-34.993, r2=-6.772, total=   4.5s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-35.836, r2=-6.320, total=   4.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.516, r2=-0.048, total=   2.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.267, r2=-0.061, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.518, r2=-0.043, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.227, r2=-0.038, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.081, total=   3.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.295, r2=-1.190, total=   4.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.272, r2=-0.897, total=   4.3s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.2s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.466, r2=-0.044, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.265, r2=-0.063, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.511, r2=-0.043, total=   3.3s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.232, r2=-0.039, total=   3.0s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.933, r2=-0.081, total=   3.3s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-20.959, r2=-1.229, total=   4.7s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-21.021, r2=-0.910, total=   4.2s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.533, r2=-0.045, total=   2.3s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.226, r2=-0.041, total=   2.0s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.079, total=   2.0s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.470, r2=-0.045, total=   2.9s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.278, r2=-0.064, total=   3.2s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.2s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.226, r2=-0.039, total=   3.2s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.941, r2=-0.081, total=   3.5s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   2.0s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.921, r2=-0.079, total=   2.1s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.621, r2=-0.059, total=   3.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.303, r2=-0.061, total=   2.5s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.515, r2=-0.043, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.039, total=   3.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.082, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-35.997, r2=-6.987, total=   4.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.509, r2=-6.079, total=   4.5s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.528, r2=-0.044, total=   1.8s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.8s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.558, r2=-0.050, total=   2.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.266, r2=-0.042, total=   2.4s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.924, r2=-0.082, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   2.9s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.255, r2=-0.062, total=   3.0s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.667, r2=-1.258, total=   4.5s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.495, r2=-1.279, total=   4.2s\n[CV] C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.4954943017379566, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.662, r2=-1.115, total=   4.6s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.522, r2=-0.043, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.209, r2=-0.039, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.926, r2=-0.080, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.459, r2=-0.044, total=   3.3s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.248, r2=-0.060, total=   2.9s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-21.026, r2=-1.211, total=   4.7s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-20.572, r2=-1.152, total=   4.5s\n[CV] C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-21.184, r2=-1.125, total=   4.3s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   2.2s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.466, r2=-0.043, total=   2.0s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.291, r2=-0.063, total=   2.0s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.520, r2=-0.044, total=   2.9s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.039, total=   3.3s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.941, r2=-0.082, total=   2.9s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.475, r2=-0.044, total=   3.2s\n[CV] C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.2s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.464, r2=-0.042, total=   2.2s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.288, r2=-0.064, total=   2.0s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.519, r2=-0.044, total=   3.4s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.039, total=   3.2s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.940, r2=-0.082, total=   3.0s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.476, r2=-0.044, total=   3.7s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.6s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.505, r2=-0.047, total=   2.4s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.247, r2=-0.060, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.507, r2=-0.043, total=   2.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.222, r2=-0.038, total=   3.0s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.926, r2=-0.083, total=   3.2s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-54.689, r2=-21.736, total=   4.3s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-54.716, r2=-18.803, total=   4.3s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   2.4s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.530, r2=-0.044, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.214, r2=-0.039, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.922, r2=-0.080, total=   2.4s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   2.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.242, r2=-0.061, total=   2.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-31.105, r2=-4.502, total=   4.8s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.145, r2=-4.486, total=   4.3s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.939, r2=-4.186, total=   4.3s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   2.4s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.469, r2=-0.044, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.252, r2=-0.061, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.511, r2=-0.043, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.232, r2=-0.039, total=   3.2s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.933, r2=-0.081, total=   2.9s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-20.959, r2=-1.229, total=   5.1s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-21.021, r2=-0.910, total=   4.4s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.531, r2=-0.044, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.226, r2=-0.041, total=   2.2s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.942, r2=-0.080, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.471, r2=-0.046, total=   3.4s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.276, r2=-0.064, total=   3.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.522, r2=-0.045, total=   3.3s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.227, r2=-0.039, total=   4.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.943, r2=-0.082, total=   3.3s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.539, r2=-0.046, total=   2.4s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.226, r2=-0.039, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.922, r2=-0.080, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.448, r2=-0.043, total=   3.0s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.233, r2=-0.060, total=   3.3s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-56.022, r2=-21.890, total=   4.2s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-53.043, r2=-21.122, total=   4.3s\n[CV] C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-54.602, r2=-19.545, total=   5.2s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.479, r2=-0.045, total=   2.1s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.255, r2=-0.061, total=   2.4s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.508, r2=-0.043, total=   3.0s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.230, r2=-0.039, total=   3.0s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.930, r2=-0.082, total=   2.9s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.775, r2=-4.635, total=   4.5s\n[CV] C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.257, r2=-3.492, total=   4.4s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   2.2s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.516, r2=-0.045, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.216, r2=-0.039, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.914, r2=-0.079, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.459, r2=-0.044, total=   3.3s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.248, r2=-0.060, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-21.026, r2=-1.211, total=   4.8s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-20.572, r2=-1.152, total=   4.6s\n[CV] C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-21.184, r2=-1.125, total=   4.3s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 18.6min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.470, r2=-0.044, total=   2.4s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.300, r2=-0.063, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.520, r2=-0.044, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.039, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.941, r2=-0.082, total=   3.3s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.475, r2=-0.044, total=   3.2s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.7s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.468, r2=-0.044, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.299, r2=-0.063, total=   2.0s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.519, r2=-0.044, total=   3.3s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.039, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.940, r2=-0.082, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.476, r2=-0.044, total=   3.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.6s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.549, r2=-0.051, total=   2.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.253, r2=-0.057, total=   2.5s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.507, r2=-0.043, total=   3.7s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.222, r2=-0.038, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.926, r2=-0.083, total=   3.3s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-54.689, r2=-21.736, total=   4.3s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-54.716, r2=-18.803, total=   4.3s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.537, r2=-0.047, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.232, r2=-0.040, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.914, r2=-0.079, total=   2.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   3.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.242, r2=-0.061, total=   2.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-31.105, r2=-4.502, total=   4.5s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.145, r2=-4.486, total=   5.4s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.939, r2=-4.186, total=   4.3s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   2.2s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=linear ......\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.044, total=   2.3s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.229, r2=-0.038, total=   2.0s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.076, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.470, r2=-0.045, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.278, r2=-0.064, total=   2.9s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.4s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.226, r2=-0.039, total=   3.2s\n[CV] C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.941, r2=-0.081, total=   3.6s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   2.4s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.536, r2=-0.045, total=   2.0s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.229, r2=-0.038, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.936, r2=-0.076, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.471, r2=-0.046, total=   3.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.276, r2=-0.064, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.522, r2=-0.045, total=   3.3s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.227, r2=-0.039, total=   3.5s\n[CV] C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.943, r2=-0.082, total=   3.3s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.571, r2=-0.051, total=   2.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.251, r2=-0.039, total=   2.5s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.085, total=   2.5s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.448, r2=-0.043, total=   3.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.233, r2=-0.060, total=   3.0s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-56.022, r2=-21.890, total=   4.5s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-53.043, r2=-21.122, total=   4.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-54.602, r2=-19.545, total=   4.5s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.493, r2=-0.047, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.242, r2=-0.060, total=   2.1s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.508, r2=-0.043, total=   3.3s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.230, r2=-0.039, total=   2.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.930, r2=-0.082, total=   2.9s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.775, r2=-4.635, total=   5.2s\n[CV] C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.257, r2=-3.492, total=   4.5s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   2.1s\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   2.0s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.494, r2=-0.046, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.261, r2=-0.061, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.511, r2=-0.043, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.232, r2=-0.039, total=   3.3s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.933, r2=-0.081, total=   2.9s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-20.959, r2=-1.229, total=   4.2s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-21.021, r2=-0.910, total=   4.5s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   2.6s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.046, total=   2.2s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.231, r2=-0.039, total=   2.3s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.945, r2=-0.077, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.470, r2=-0.045, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.278, r2=-0.064, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.6s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.226, r2=-0.039, total=   3.2s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.941, r2=-0.081, total=   3.3s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   2.2s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.473, r2=-0.044, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.301, r2=-0.064, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.519, r2=-0.044, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.039, total=   3.3s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.940, r2=-0.082, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.476, r2=-0.044, total=   3.8s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.6s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.684, r2=-0.068, total=   2.5s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.341, r2=-0.066, total=   2.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.507, r2=-0.043, total=   2.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.222, r2=-0.038, total=   2.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.926, r2=-0.083, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-54.689, r2=-21.736, total=   4.6s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-54.716, r2=-18.803, total=   4.3s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   2.2s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.541, r2=-0.048, total=   2.2s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.247, r2=-0.042, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.925, r2=-0.081, total=   2.2s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.459, r2=-0.044, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.248, r2=-0.060, total=   3.2s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-21.026, r2=-1.211, total=   4.2s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-20.572, r2=-1.152, total=   4.5s\n[CV] C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.8272363989013611, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-21.184, r2=-1.125, total=   4.3s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   2.3s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.475, r2=-0.045, total=   2.4s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.302, r2=-0.064, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.520, r2=-0.044, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.039, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.941, r2=-0.082, total=   3.3s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.475, r2=-0.044, total=   3.2s\n[CV] C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.8272363989013611, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.2s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.045, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.229, r2=-0.039, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.942, r2=-0.077, total=   2.1s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.471, r2=-0.046, total=   3.3s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.276, r2=-0.064, total=   3.0s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.522, r2=-0.045, total=   3.8s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.227, r2=-0.039, total=   3.3s\n[CV] C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.943, r2=-0.082, total=   3.4s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.490, r2=-0.049, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.061, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.717, r2=-0.064, total=   2.5s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.356, r2=-0.048, total=   2.7s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.945, r2=-0.083, total=   2.5s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.448, r2=-0.043, total=   2.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.233, r2=-0.060, total=   2.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-56.022, r2=-21.890, total=   4.5s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-53.043, r2=-21.122, total=   4.3s\n[CV] C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-54.602, r2=-19.545, total=   4.6s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.231, r2=-0.038, total=   1.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.078, total=   2.4s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.578, r2=-0.052, total=   2.6s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.287, r2=-0.042, total=   2.2s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.932, r2=-0.085, total=   2.4s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   3.2s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.242, r2=-0.061, total=   2.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-31.105, r2=-4.502, total=   4.5s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.145, r2=-4.486, total=   4.5s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.939, r2=-4.186, total=   4.3s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   2.2s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.456, r2=-0.043, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.267, r2=-0.062, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.517, r2=-0.043, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.223, r2=-0.038, total=   4.1s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.937, r2=-0.081, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.189, r2=-0.244, total=   3.9s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.731, r2=-0.181, total=   4.3s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.533, r2=-0.045, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.228, r2=-0.038, total=   2.4s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.937, r2=-0.077, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   3.0s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.282, r2=-0.064, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.5s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.040, total=   3.2s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.937, r2=-0.079, total=   3.3s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.3s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   2.5s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.468, r2=-0.043, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.296, r2=-0.063, total=   2.0s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   3.3s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.950, r2=-0.083, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.472, r2=-0.044, total=   3.2s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.289, r2=-0.064, total=   3.2s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.528, r2=-0.048, total=   2.2s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.268, r2=-0.061, total=   2.2s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.508, r2=-0.043, total=   3.2s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.230, r2=-0.039, total=   2.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.930, r2=-0.082, total=   2.9s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.775, r2=-4.635, total=   4.6s\n[CV] C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.8272363989013611, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-30.257, r2=-3.492, total=   4.4s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   2.2s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.530, r2=-0.043, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.211, r2=-0.039, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.925, r2=-0.079, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.455, r2=-0.045, total=   3.0s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.259, r2=-0.062, total=   3.9s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.278, r2=-0.242, total=   4.0s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.083, r2=-0.235, total=   4.0s\n[CV] C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.723, r2=-0.272, total=   4.2s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.469, r2=-0.043, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.297, r2=-0.063, total=   2.3s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.0s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.949, r2=-0.083, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.472, r2=-0.044, total=   3.5s\n[CV] C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.290, r2=-0.064, total=   3.2s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   2.7s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.533, r2=-0.045, total=   2.0s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.227, r2=-0.038, total=   2.0s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.078, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.281, r2=-0.064, total=   3.2s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.2s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.039, total=   3.3s\n[CV] C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.937, r2=-0.079, total=   3.7s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.8s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.219, r2=-0.039, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.920, r2=-0.080, total=   3.3s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.448, r2=-0.043, total=   3.0s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.247, r2=-0.061, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-37.097, r2=-7.348, total=   4.4s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-35.649, r2=-7.159, total=   4.2s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.514, r2=-6.677, total=   4.2s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.466, r2=-0.044, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.265, r2=-0.063, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.518, r2=-0.043, total=   3.0s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.038, total=   3.3s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.081, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.661, r2=-1.270, total=   4.7s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.651, r2=-0.968, total=   4.6s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.454, r2=-0.042, total=   2.4s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.256, r2=-0.062, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.517, r2=-0.043, total=   2.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.223, r2=-0.038, total=   2.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.937, r2=-0.081, total=   3.3s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.189, r2=-0.244, total=   4.0s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.731, r2=-0.181, total=   3.9s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   2.7s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.045, total=   2.0s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.230, r2=-0.039, total=   2.0s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.941, r2=-0.077, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   3.2s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.282, r2=-0.064, total=   2.9s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.3s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.040, total=   3.5s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.937, r2=-0.079, total=   3.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.044, total=   2.0s\n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.490, r2=-0.046, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.252, r2=-0.060, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.515, r2=-0.043, total=   3.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.039, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.083, total=   2.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.643, r2=-7.359, total=   4.5s\n[CV] C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-37.178, r2=-6.425, total=   4.3s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.8s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   2.2s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.522, r2=-0.043, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.209, r2=-0.039, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.926, r2=-0.080, total=   2.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   3.0s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.254, r2=-0.062, total=   3.1s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-22.001, r2=-1.346, total=   4.3s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.774, r2=-1.354, total=   4.9s\n[CV] C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-22.607, r2=-1.319, total=   4.4s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.517, r2=-0.044, total=   2.4s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.216, r2=-0.039, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.908, r2=-0.079, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.455, r2=-0.045, total=   2.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.259, r2=-0.062, total=   2.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.278, r2=-0.242, total=   4.2s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.083, r2=-0.235, total=   3.9s\n[CV] C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.723, r2=-0.272, total=   5.0s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.473, r2=-0.044, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.301, r2=-0.064, total=   2.0s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.3s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   2.9s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.949, r2=-0.083, total=   3.0s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.472, r2=-0.044, total=   3.4s\n[CV] C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.290, r2=-0.064, total=   3.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.471, r2=-0.044, total=   2.4s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.229, r2=-0.039, total=   2.4s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.939, r2=-0.076, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   3.0s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.281, r2=-0.064, total=   3.0s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   4.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.039, total=   3.3s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.937, r2=-0.079, total=   3.3s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.531, r2=-0.050, total=   2.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.247, r2=-0.057, total=   2.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.515, r2=-0.043, total=   2.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.039, total=   3.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.083, total=   2.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.643, r2=-7.359, total=   4.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-37.178, r2=-6.425, total=   4.6s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.8s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.523, r2=-0.046, total=   2.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.219, r2=-0.039, total=   2.3s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.920, r2=-0.080, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   3.5s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.254, r2=-0.062, total=   3.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-22.001, r2=-1.346, total=   4.3s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.774, r2=-1.354, total=   4.1s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-22.607, r2=-1.319, total=   4.7s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.475, r2=-0.045, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.264, r2=-0.062, total=   2.2s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.517, r2=-0.043, total=   3.2s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.223, r2=-0.038, total=   3.0s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.937, r2=-0.081, total=   3.0s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.189, r2=-0.244, total=   4.3s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.731, r2=-0.181, total=   4.3s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   2.2s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.046, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.300, r2=-0.063, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.0s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   3.0s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.950, r2=-0.083, total=   3.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.472, r2=-0.044, total=   3.3s\n[CV] C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.289, r2=-0.064, total=   3.3s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   2.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.556, r2=-0.050, total=   2.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.241, r2=-0.040, total=   2.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.926, r2=-0.083, total=   2.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.448, r2=-0.043, total=   3.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.247, r2=-0.061, total=   2.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-37.097, r2=-7.348, total=   4.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-35.649, r2=-7.159, total=   4.5s\n[CV] C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.514, r2=-6.677, total=   4.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.476, r2=-0.046, total=   2.4s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.248, r2=-0.060, total=   2.1s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.518, r2=-0.043, total=   3.0s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.038, total=   3.5s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.081, total=   3.2s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.661, r2=-1.270, total=   4.1s\n[CV] C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.651, r2=-0.968, total=   4.3s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=linear ......\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.533, r2=-0.046, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.240, r2=-0.041, total=   2.2s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=poly ........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.920, r2=-0.081, total=   2.5s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.455, r2=-0.045, total=   3.0s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf .........\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.259, r2=-0.062, total=   2.9s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.278, r2=-0.242, total=   4.3s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.083, r2=-0.235, total=   4.0s\n[CV] C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid .....\n[CV]  C=0.5078843648821761, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-16.723, r2=-0.272, total=   4.6s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=linear .......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.474, r2=-0.046, total=   2.1s","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 26.9min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.304, r2=-0.064, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.0s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   3.3s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.949, r2=-0.083, total=   3.0s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.472, r2=-0.044, total=   3.2s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.290, r2=-0.064, total=   3.5s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.8s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.475, r2=-0.045, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.303, r2=-0.064, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.040, total=   3.6s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.950, r2=-0.083, total=   2.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.472, r2=-0.044, total=   3.5s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.289, r2=-0.064, total=   3.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.8s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.674, r2=-0.060, total=   2.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.324, r2=-0.046, total=   2.4s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.939, r2=-0.081, total=   2.4s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.448, r2=-0.043, total=   3.0s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.247, r2=-0.061, total=   3.3s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-37.097, r2=-7.348, total=   4.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-35.649, r2=-7.159, total=   5.1s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.514, r2=-6.677, total=   4.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.517, r2=-0.048, total=   2.3s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.267, r2=-0.061, total=   2.3s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.518, r2=-0.043, total=   2.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.038, total=   2.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.081, total=   3.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.661, r2=-1.270, total=   4.1s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.651, r2=-0.968, total=   4.2s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   2.2s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=poly .........\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.233, r2=-0.039, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=poly .........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.948, r2=-0.078, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   3.0s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf ..........\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.282, r2=-0.064, total=   3.3s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.2s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.040, total=   3.2s\n[CV] C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid ......\n[CV]  C=0.5078843648821761, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.937, r2=-0.079, total=   3.5s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.046, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.232, r2=-0.039, total=   2.1s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.946, r2=-0.077, total=   2.4s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.468, r2=-0.042, total=   3.4s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.281, r2=-0.064, total=   3.1s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.5s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.224, r2=-0.039, total=   3.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.937, r2=-0.079, total=   3.3s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.922, r2=-0.079, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.624, r2=-0.059, total=   2.6s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.304, r2=-0.062, total=   2.4s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.515, r2=-0.043, total=   2.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.228, r2=-0.039, total=   3.1s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.083, total=   3.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-36.643, r2=-7.359, total=   4.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-37.178, r2=-6.425, total=   5.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.529, r2=-0.044, total=   1.8s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.488, r2=-0.049, total=   1.8s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.281, r2=-0.063, total=   1.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.559, r2=-0.050, total=   2.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.267, r2=-0.042, total=   2.5s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.923, r2=-0.083, total=   2.2s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   2.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.254, r2=-0.062, total=   2.9s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-22.001, r2=-1.346, total=   4.5s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-21.774, r2=-1.354, total=   4.1s\n[CV] C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.5078843648821761, degree=4, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-22.607, r2=-1.319, total=   4.4s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.523, r2=-0.043, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.209, r2=-0.039, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.926, r2=-0.079, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.457, r2=-0.044, total=   3.9s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.252, r2=-0.061, total=   2.9s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.202, r2=-0.753, total=   4.1s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-18.837, r2=-0.733, total=   4.4s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.222, r2=-0.689, total=   4.2s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   2.2s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.467, r2=-0.043, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.294, r2=-0.063, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.0s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.230, r2=-0.040, total=   3.1s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.944, r2=-0.083, total=   3.2s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.474, r2=-0.044, total=   3.2s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.2s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   2.2s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   2.2s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.466, r2=-0.043, total=   2.4s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.290, r2=-0.063, total=   2.0s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.2s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.039, total=   2.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.943, r2=-0.083, total=   2.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.475, r2=-0.044, total=   3.3s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.6s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   1.8s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.498, r2=-0.046, total=   2.3s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.250, r2=-0.060, total=   2.2s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.508, r2=-0.043, total=   2.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.224, r2=-0.038, total=   2.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.929, r2=-0.083, total=   3.8s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-47.745, r2=-15.378, total=   4.4s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-47.890, r2=-13.218, total=   4.3s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   2.2s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   1.8s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.525, r2=-0.043, total=   2.1s\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.461, r2=-0.043, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.266, r2=-0.062, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.515, r2=-0.043, total=   3.8s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.231, r2=-0.039, total=   3.0s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.081, total=   3.0s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.223, r2=-0.810, total=   4.2s\n[CV] C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=2, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.312, r2=-0.562, total=   4.4s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   1.8s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.533, r2=-0.045, total=   2.4s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.226, r2=-0.040, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.078, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.470, r2=-0.044, total=   3.0s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.278, r2=-0.064, total=   3.3s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.3s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.227, r2=-0.039, total=   3.2s\n[CV] C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=2, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.939, r2=-0.080, total=   3.2s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   2.2s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.533, r2=-0.045, total=   2.7s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.226, r2=-0.041, total=   2.0s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.079, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.469, r2=-0.045, total=   3.3s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.278, r2=-0.064, total=   3.0s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.3s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.226, r2=-0.039, total=   3.5s\n[CV] C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.938, r2=-0.080, total=   3.3s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.534, r2=-0.045, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.224, r2=-0.039, total=   2.4s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.918, r2=-0.080, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.447, r2=-0.043, total=   2.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.238, r2=-0.061, total=   3.0s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-48.659, r2=-15.297, total=   5.1s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-46.290, r2=-14.768, total=   4.4s\n[CV] C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-47.649, r2=-13.758, total=   4.4s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   1.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.474, r2=-0.044, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.257, r2=-0.062, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.512, r2=-0.043, total=   3.3s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.039, total=   2.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.934, r2=-0.082, total=   2.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-27.322, r2=-3.108, total=   4.5s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-26.960, r2=-2.374, total=   4.4s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   2.0s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   2.2s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.516, r2=-0.044, total=   2.7s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.217, r2=-0.039, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.915, r2=-0.080, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.457, r2=-0.044, total=   3.3s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.252, r2=-0.061, total=   2.9s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.202, r2=-0.753, total=   4.1s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-18.837, r2=-0.733, total=   4.4s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.222, r2=-0.689, total=   4.2s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.471, r2=-0.044, total=   2.2s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.300, r2=-0.063, total=   2.2s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.1s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.230, r2=-0.040, total=   3.4s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.944, r2=-0.083, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.474, r2=-0.044, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.3s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.469, r2=-0.044, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.299, r2=-0.063, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.0s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.039, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.943, r2=-0.083, total=   3.0s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.475, r2=-0.044, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.6s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   1.8s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.566, r2=-0.050, total=   2.3s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.250, r2=-0.039, total=   2.3s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.212, r2=-0.039, total=   2.1s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.924, r2=-0.080, total=   2.4s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   3.0s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.245, r2=-0.061, total=   2.9s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-27.644, r2=-3.119, total=   4.4s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-26.760, r2=-3.043, total=   4.5s\n[CV] C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=2, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-27.547, r2=-2.840, total=   4.5s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.0s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   2.2s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.464, r2=-0.043, total=   2.7s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.251, r2=-0.062, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.515, r2=-0.043, total=   3.0s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.231, r2=-0.039, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.081, total=   2.9s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.223, r2=-0.810, total=   4.1s\n[CV] C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=3, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.312, r2=-0.562, total=   4.5s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   1.8s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.044, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.229, r2=-0.039, total=   2.4s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.076, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.470, r2=-0.044, total=   3.6s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.278, r2=-0.064, total=   3.0s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.6s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.227, r2=-0.039, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=3, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.939, r2=-0.080, total=   3.3s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   2.0s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.044, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.228, r2=-0.038, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.938, r2=-0.077, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.469, r2=-0.045, total=   3.3s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-15.278, r2=-0.064, total=   2.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.226, r2=-0.039, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.0917919231271992, kernel=sigmoid, neg_mean_absolute_error=-14.938, r2=-0.080, total=   3.6s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.544, r2=-0.051, total=   2.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-15.251, r2=-0.057, total=   2.4s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.508, r2=-0.043, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.224, r2=-0.038, total=   3.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.929, r2=-0.083, total=   2.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-47.745, r2=-15.378, total=   4.5s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-47.890, r2=-13.218, total=   4.3s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   1.8s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   2.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.532, r2=-0.046, total=   2.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.228, r2=-0.040, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.914, r2=-0.078, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.453, r2=-0.044, total=   3.3s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-15.245, r2=-0.061, total=   2.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-27.644, r2=-3.119, total=   4.4s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-26.760, r2=-3.043, total=   4.5s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-27.547, r2=-2.840, total=   4.2s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   2.5s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.491, r2=-0.046, total=   2.4s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.244, r2=-0.041, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.515, r2=-0.043, total=   2.9s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.231, r2=-0.039, total=   2.9s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.936, r2=-0.081, total=   3.2s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.223, r2=-0.810, total=   4.1s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.312, r2=-0.562, total=   4.1s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   1.8s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.046, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.232, r2=-0.039, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.946, r2=-0.077, total=   2.5s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.470, r2=-0.044, total=   2.9s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-15.278, r2=-0.064, total=   2.9s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.523, r2=-0.045, total=   3.5s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.227, r2=-0.039, total=   4.1s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.939, r2=-0.080, total=   3.3s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.491, r2=-0.049, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.535, r2=-0.045, total=   2.3s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.230, r2=-0.039, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.943, r2=-0.077, total=   2.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=poly, neg_mean_absolute_error=-14.934, r2=-0.085, total=   2.5s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-14.447, r2=-0.043, total=   3.7s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=rbf, neg_mean_absolute_error=-15.238, r2=-0.061, total=   2.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-48.659, r2=-15.297, total=   4.5s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-46.290, r2=-14.768, total=   4.2s\n[CV] C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.8180224642517979, kernel=sigmoid, neg_mean_absolute_error=-47.649, r2=-13.758, total=   4.3s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.0s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   1.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-14.489, r2=-0.047, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=poly, neg_mean_absolute_error=-15.242, r2=-0.060, total=   2.1s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.512, r2=-0.043, total=   3.3s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.229, r2=-0.039, total=   3.0s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=rbf, neg_mean_absolute_error=-14.934, r2=-0.082, total=   2.9s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-27.322, r2=-3.108, total=   4.3s\n[CV] C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid \n[CV]  C=0.704648438550303, degree=3, gamma=0.5369765560050247, kernel=sigmoid, neg_mean_absolute_error=-26.960, r2=-2.374, total=   4.6s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   2.5s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=linear .......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=linear, neg_mean_absolute_error=-15.280, r2=-0.062, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.537, r2=-0.047, total=   2.5s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-15.263, r2=-0.062, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=poly .........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=poly, neg_mean_absolute_error=-14.923, r2=-0.081, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-14.457, r2=-0.044, total=   2.9s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=rbf ..........\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=rbf, neg_mean_absolute_error=-15.252, r2=-0.061, total=   3.3s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.202, r2=-0.753, total=   4.1s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-18.837, r2=-0.733, total=   4.1s\n[CV] C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid ......\n[CV]  C=0.704648438550303, degree=4, gamma=scale, kernel=sigmoid, neg_mean_absolute_error=-19.222, r2=-0.689, total=   4.5s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=linear ........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-14.475, r2=-0.045, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=poly ..........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=poly, neg_mean_absolute_error=-15.303, r2=-0.064, total=   2.4s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   2.9s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.230, r2=-0.040, total=   3.0s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=rbf ...........\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=rbf, neg_mean_absolute_error=-14.944, r2=-0.083, total=   2.9s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-14.474, r2=-0.044, total=   4.2s\n[CV] C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid .......\n[CV]  C=0.704648438550303, degree=4, gamma=auto, kernel=sigmoid, neg_mean_absolute_error=-15.288, r2=-0.065, total=   3.2s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.530, r2=-0.044, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.226, r2=-0.037, total=   1.9s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=linear, neg_mean_absolute_error=-14.923, r2=-0.078, total=   2.2s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-14.474, r2=-0.045, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=poly, neg_mean_absolute_error=-15.302, r2=-0.064, total=   2.1s\n[CV] C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=rbf \n[CV]  C=0.704648438550303, degree=4, gamma=0.0917919231271992, kernel=rbf, neg_mean_absolute_error=-14.521, r2=-0.044, total=   3.0s","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 35.2min finished\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5, estimator=SVR(), n_jobs=-1,\n             param_grid={'C': [0.3066326133977365, 0.4954943017379566,\n                               0.8272363989013611, 0.5078843648821761,\n                               0.704648438550303],\n                         'degree': [2, 3, 4],\n                         'gamma': ['scale', 'auto', 0.0917919231271992,\n                                   0.8180224642517979, 0.5369765560050247],\n                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n             refit='r2', scoring=['r2', 'neg_mean_absolute_error'], verbose=3)"},"metadata":{}}]},{"cell_type":"code","source":"print(SVMreg_GS.best_params_)\nprint(SVMreg_GS.best_score_)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T08:43:03.624535Z","iopub.execute_input":"2022-08-28T08:43:03.624804Z","iopub.status.idle":"2022-08-28T08:43:03.629637Z","shell.execute_reply.started":"2022-08-28T08:43:03.624771Z","shell.execute_reply":"2022-08-28T08:43:03.628791Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"{'C': 0.4954943017379566, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n-0.05315210359211799\n","output_type":"stream"}]},{"cell_type":"code","source":"model_pred = SVMreg_GS.predict(X_test)\nSVMreg_r2 = r2_score(y_test, model_pred)\nSVMreg_r2","metadata":{"execution":{"iopub.status.busy":"2022-08-28T08:43:08.664424Z","iopub.execute_input":"2022-08-28T08:43:08.664986Z","iopub.status.idle":"2022-08-28T08:43:08.959869Z","shell.execute_reply.started":"2022-08-28T08:43:08.664942Z","shell.execute_reply":"2022-08-28T08:43:08.959016Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"-0.06095478416018474"},"metadata":{}}]},{"cell_type":"markdown","source":"# XGB Regression","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\n\nXGBreg = xgb.XGBRegressor(random_state=42)\nXGBreg_param = {'booster': ['gbtree', 'gblinear', 'dart'],\n                'learning_rate': list(np.random.random_sample((3,))),\n                'gamma': list(np.random.random_sample((3,))),\n                'max_depth': [5, 6, 7],\n                'n_estimators': [100, 200, 400]}\n\nXGBreg_GS = GridSearchCV(XGBreg,\n                         XGBreg_param,\n                         scoring = [\"r2\", \"neg_mean_absolute_error\"],\n                         refit = \"r2\",\n                         cv = 5,\n                         n_jobs = -1,\n                         verbose=3)\n\nXGBreg_GS.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T08:58:14.475926Z","iopub.execute_input":"2022-08-28T08:58:14.476212Z","iopub.status.idle":"2022-08-28T13:37:03.315537Z","shell.execute_reply.started":"2022-08-28T08:58:14.476182Z","shell.execute_reply":"2022-08-28T13:37:03.314928Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.0min\n","output_type":"stream"},{"name":"stdout","text":"[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.382, r2=-0.025, total=   3.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.871, r2=-0.006, total=   1.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.394, r2=-0.035, total=   2.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.088, r2=-0.025, total=   3.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.289, r2=-0.024, total=   4.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.530, r2=-0.050, total=   4.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.928, r2=-0.011, total=   5.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.367, r2=-0.032, total=   3.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.433, r2=-0.034, total=   1.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.089, r2=-0.026, total=   3.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.278, r2=-0.024, total=   1.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.523, r2=-0.048, total=   2.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.940, r2=-0.011, total=   7.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.447, r2=-0.043, total=   6.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.177, r2=-0.036, total=   9.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.344, r2=-0.034, total=  18.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.949, r2=-0.014, total=   1.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.430, r2=-0.041, total=   8.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.145, r2=-0.031, total=  13.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.324, r2=-0.031, total=   4.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.568, r2=-0.054, total=  37.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.945, r2=-0.013, total=  10.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.493, r2=-0.049, total=   0.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.638, r2=-0.072, total=   9.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.213, r2=-0.039, total=   2.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.380, r2=-0.041, total=   1.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.637, r2=-0.072, total=   1.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.945, r2=-0.015, total=   2.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.496, r2=-0.049, total=  10.2s[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.328, r2=-0.028, total=   4.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.040, r2=-0.018, total=   1.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.225, r2=-0.014, total=   1.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.450, r2=-0.035, total=   2.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.910, r2=-0.009, total=   5.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.465, r2=-0.043, total=   4.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.129, r2=-0.030, total=   5.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.346, r2=-0.034, total=   7.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.902, r2=-0.008, total=   2.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.426, r2=-0.039, total=   2.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.149, r2=-0.032, total=   2.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.328, r2=-0.031, total=   7.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.573, r2=-0.055, total=   6.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.953, r2=-0.012, total=  13.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.392, r2=-0.036, total=   9.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.521, r2=-0.048, total=   2.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.108, r2=-0.027, total=   1.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.299, r2=-0.028, total=   1.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.566, r2=-0.054, total=  13.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.945, r2=-0.013, total=   8.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.431, r2=-0.042, total=  19.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.146, r2=-0.031, total=  25.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.325, r2=-0.031, total=  16.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.948, r2=-0.016, total=   2.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.496, r2=-0.049, total=   2.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.214, r2=-0.039, total=   1.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.381, r2=-0.041, total=   2.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.637, r2=-0.072, total=  10.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.945, r2=-0.015, total=  13.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.039, total=   5.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.381, r2=-0.041, total=  23.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.947, r2=-0.013, total=   2.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.447, r2=-0.042, total=   2.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.194, r2=-0.037, total=   3.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.346, r2=-0.037, total=   5.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.613, r2=-0.061, total=  12.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.947, r2=-0.013, total=   5.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.432, r2=-0.042, total=   2.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.576, r2=-0.056, total=   6.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.163, r2=-0.032, total=   2.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.372, r2=-0.039, total=   1.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.576, r2=-0.056, total=   2.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.967, r2=-0.015, total=   6.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.432, r2=-0.042, total=  11.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.163, r2=-0.032, total=  22.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.372, r2=-0.039, total=   9.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.970, r2=-0.015, total=   6.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.630, r2=-0.068, total=   8.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.213, r2=-0.039, total=   9.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.368, r2=-0.038, total=   2.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.630, r2=-0.068, total=   5.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.970, r2=-0.015, total=   4.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.446, r2=-0.043, total=   7.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.636, r2=-0.066, total=   1.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.159, r2=-0.032, total=   1.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.413, r2=-0.053, total=   6.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.636, r2=-0.066, total=   3.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.957, r2=-0.015, total=   2.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.447, r2=-0.042, total=   8.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.613, r2=-0.061, total=   5.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.194, r2=-0.037, total=   1.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.346, r2=-0.037, total=   1.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.613, r2=-0.061, total=   2.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.947, r2=-0.013, total=   3.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.447, r2=-0.042, total=  14.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.194, r2=-0.037, total=   5.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.346, r2=-0.037, total=  12.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.967, r2=-0.015, total=   2.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.432, r2=-0.042, total=   3.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.163, r2=-0.032, total=   7.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.372, r2=-0.039, total=   3.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.576, r2=-0.056, total=  25.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.967, r2=-0.015, total=  10.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.462, r2=-0.043, total=   1.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.630, r2=-0.068, total=   1.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.212, r2=-0.039, total=   1.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.366, r2=-0.038, total=   6.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.463, r2=-0.043, total=   8.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.970, r2=-0.015, total=   9.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.463, r2=-0.043, total=   5.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.213, r2=-0.039, total=   5.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.368, r2=-0.038, total=  11.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.957, r2=-0.015, total=   1.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.446, r2=-0.043, total=   8.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.159, r2=-0.032, total=   2.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.413, r2=-0.053, total=   4.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.636, r2=-0.066, total=  12.0s","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  6.9min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.446, r2=-0.043, total=   8.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.159, r2=-0.032, total=  15.8s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.413, r2=-0.053, total=   6.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.999, r2=-0.022, total=   7.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.592, r2=-0.060, total=   2.3s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.999, r2=-0.022, total=   3.0s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.363, r2=-0.037, total=   5.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.592, r2=-0.060, total=  22.9s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.999, r2=-0.022, total=  14.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.328, r2=-0.028, total=   5.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.382, r2=-0.025, total=   1.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.040, r2=-0.018, total=   1.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.871, r2=-0.006, total=   7.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.394, r2=-0.035, total=   2.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.083, r2=-0.025, total=  10.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.287, r2=-0.025, total=   2.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.541, r2=-0.051, total=   3.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.945, r2=-0.014, total=  11.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.370, r2=-0.032, total=   1.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.438, r2=-0.035, total=   2.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.084, r2=-0.025, total=   1.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.278, r2=-0.024, total=   1.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.546, r2=-0.050, total=   6.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.935, r2=-0.010, total=  13.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.450, r2=-0.043, total=  13.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.174, r2=-0.035, total=   5.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.344, r2=-0.034, total=  20.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.943, r2=-0.013, total=   1.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.427, r2=-0.041, total=   6.4s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.957, r2=-0.015, total=   9.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.433, r2=-0.042, total=   2.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.592, r2=-0.060, total=   1.6s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.182, r2=-0.038, total=   1.7s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.363, r2=-0.037, total=   7.5s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.433, r2=-0.042, total=   2.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.182, r2=-0.038, total=   3.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.433, r2=-0.042, total=  20.2s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.182, r2=-0.038, total=  18.1s\n[CV] booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.363, r2=-0.037, total=  13.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.225, r2=-0.014, total=   7.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.464, r2=-0.037, total=   2.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.916, r2=-0.010, total=   9.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.458, r2=-0.043, total=   4.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.142, r2=-0.030, total=  12.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.350, r2=-0.035, total=   4.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.902, r2=-0.008, total=   1.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.434, r2=-0.041, total=   5.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.138, r2=-0.031, total=   5.5s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.330, r2=-0.032, total=  12.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.583, r2=-0.057, total=  11.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.945, r2=-0.012, total=  17.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.395, r2=-0.037, total=   3.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.519, r2=-0.047, total=   2.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.121, r2=-0.028, total=   1.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.299, r2=-0.027, total=   3.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.566, r2=-0.054, total=   4.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.162, r2=-0.032, total=   2.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.321, r2=-0.031, total=   3.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.940, r2=-0.012, total=   2.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.428, r2=-0.041, total=   9.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.163, r2=-0.033, total=   9.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.322, r2=-0.031, total=  12.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.934, r2=-0.013, total=   1.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.499, r2=-0.049, total=   3.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.211, r2=-0.039, total=   2.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.373, r2=-0.040, total=   6.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.643, r2=-0.073, total=  25.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.934, r2=-0.013, total=  11.5s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.442, r2=-0.042, total=   1.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.613, r2=-0.061, total=   1.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.951, r2=-0.014, total=   1.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.442, r2=-0.042, total=   2.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.187, r2=-0.035, total=   3.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.350, r2=-0.036, total=   3.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.613, r2=-0.061, total=   9.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.951, r2=-0.014, total=  20.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.432, r2=-0.042, total=   5.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.575, r2=-0.055, total=   5.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.165, r2=-0.033, total=   6.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.371, r2=-0.039, total=   3.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.575, r2=-0.055, total=  13.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.966, r2=-0.015, total=   8.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.432, r2=-0.042, total=   5.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.165, r2=-0.033, total=  18.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.371, r2=-0.039, total=  11.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.957, r2=-0.015, total=   9.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.464, r2=-0.043, total=   2.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.569, r2=-0.054, total=  12.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.940, r2=-0.012, total=  12.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.499, r2=-0.049, total=   1.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.643, r2=-0.073, total=   1.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.211, r2=-0.039, total=   2.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.372, r2=-0.039, total=   1.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.643, r2=-0.073, total=   2.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.934, r2=-0.013, total=   2.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.499, r2=-0.049, total=  22.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.211, r2=-0.039, total=   9.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.373, r2=-0.040, total=  12.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.187, r2=-0.035, total=   1.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.350, r2=-0.036, total=   1.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.613, r2=-0.061, total=   3.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.951, r2=-0.014, total=   3.5s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.442, r2=-0.042, total=   5.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.187, r2=-0.035, total=  23.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.350, r2=-0.036, total=  13.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.966, r2=-0.015, total=   9.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.432, r2=-0.042, total=   3.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.165, r2=-0.033, total=  17.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.371, r2=-0.039, total=   3.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.575, r2=-0.055, total=  10.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.966, r2=-0.015, total=  16.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.462, r2=-0.043, total=   5.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.628, r2=-0.068, total=   0.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.210, r2=-0.039, total=   9.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.369, r2=-0.038, total=   1.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.628, r2=-0.068, total=   2.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.210, r2=-0.039, total=  15.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.369, r2=-0.038, total=   5.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.628, r2=-0.068, total=  20.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.957, r2=-0.015, total=  22.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.449, r2=-0.043, total=  11.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.634, r2=-0.066, total=   1.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.163, r2=-0.032, total=   1.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.411, r2=-0.053, total=   4.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.634, r2=-0.066, total=   3.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.957, r2=-0.015, total=   7.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.449, r2=-0.043, total=  11.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.163, r2=-0.032, total=   5.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.411, r2=-0.053, total=  39.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-16.000, r2=-0.022, total=   4.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.435, r2=-0.042, total=   3.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.181, r2=-0.038, total=   4.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.363, r2=-0.037, total=  12.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.591, r2=-0.060, total=  17.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-16.000, r2=-0.022, total=  10.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.329, r2=-0.028, total=   7.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.367, r2=-0.023, total=   2.3s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.043, r2=-0.019, total=   1.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.866, r2=-0.004, total=   1.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.209, r2=-0.013, total=   0.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.411, r2=-0.037, total=   3.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.080, r2=-0.024, total=   2.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.287, r2=-0.026, total=   2.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.546, r2=-0.051, total=  16.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.933, r2=-0.011, total=   4.3s","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 17.4min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.957, r2=-0.015, total=  18.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.464, r2=-0.043, total=  19.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.210, r2=-0.039, total=  18.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.369, r2=-0.038, total=  18.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.957, r2=-0.015, total=   1.8s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.449, r2=-0.043, total=   6.5s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.163, r2=-0.032, total=   2.5s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.411, r2=-0.053, total=   8.3s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.634, r2=-0.066, total=  11.0s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.957, r2=-0.015, total=  12.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.435, r2=-0.042, total=  10.6s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.591, r2=-0.060, total=  11.9s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.181, r2=-0.038, total=  12.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.363, r2=-0.037, total=   1.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.591, r2=-0.060, total=   3.4s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-16.000, r2=-0.022, total=   7.2s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.435, r2=-0.042, total=  12.7s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.181, r2=-0.038, total=  22.1s\n[CV] booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.363, r2=-0.037, total=  15.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.461, r2=-0.036, total=   3.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.919, r2=-0.009, total=   2.3s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.458, r2=-0.043, total=   4.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.126, r2=-0.030, total=  16.7s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.354, r2=-0.036, total=   5.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.903, r2=-0.009, total=   4.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.413, r2=-0.038, total=   8.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.133, r2=-0.031, total=  12.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.416, r2=-0.039, total=  10.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.140, r2=-0.032, total=   5.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.363, r2=-0.031, total=   1.3s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.470, r2=-0.039, total=   2.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.078, r2=-0.025, total=   1.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.271, r2=-0.023, total=   3.3s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.527, r2=-0.048, total=  15.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.934, r2=-0.012, total=   4.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.319, r2=-0.030, total=   3.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.527, r2=-0.048, total=   8.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.934, r2=-0.012, total=  21.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.395, r2=-0.037, total=   3.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.523, r2=-0.047, total=   1.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.940, r2=-0.013, total=   1.7s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.423, r2=-0.041, total=   7.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.155, r2=-0.032, total=   6.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.310, r2=-0.029, total=  14.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.562, r2=-0.052, total=  25.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.946, r2=-0.014, total=   6.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.461, r2=-0.043, total=   1.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.621, r2=-0.068, total=   0.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.039, total=   1.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.940, r2=-0.014, total=   2.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.369, r2=-0.038, total=   4.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.621, r2=-0.068, total=   4.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.940, r2=-0.014, total=   8.7s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.461, r2=-0.043, total=   6.7s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.039, total=   5.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.369, r2=-0.038, total=   4.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.954, r2=-0.015, total=   2.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.326, r2=-0.034, total=   1.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.328, r2=-0.031, total=  23.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.132, r2=-0.029, total=   1.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.291, r2=-0.026, total=   7.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.562, r2=-0.052, total=   7.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.946, r2=-0.014, total=   3.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.423, r2=-0.041, total=  18.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.155, r2=-0.032, total=  25.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.310, r2=-0.029, total=   8.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.461, r2=-0.043, total=   7.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.039, total=   3.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.369, r2=-0.038, total=   7.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.621, r2=-0.068, total=   6.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.940, r2=-0.014, total=   5.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.426, r2=-0.040, total=   1.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.615, r2=-0.062, total=   1.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.177, r2=-0.035, total=   2.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.426, r2=-0.040, total=   2.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.177, r2=-0.035, total=  14.7s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.326, r2=-0.034, total=   8.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.615, r2=-0.062, total=   6.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.954, r2=-0.015, total=  16.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.430, r2=-0.043, total=  10.3s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.573, r2=-0.055, total=   3.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.156, r2=-0.032, total=  16.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.355, r2=-0.035, total=  18.3s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.573, r2=-0.055, total=   8.3s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.969, r2=-0.017, total=   3.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.355, r2=-0.035, total=  15.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.573, r2=-0.055, total=  17.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.615, r2=-0.062, total=   3.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.954, r2=-0.015, total=  19.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.426, r2=-0.040, total=   6.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.177, r2=-0.035, total=   8.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.326, r2=-0.034, total=  33.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.969, r2=-0.017, total=  16.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.430, r2=-0.043, total=  15.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.156, r2=-0.032, total=   4.7s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.430, r2=-0.043, total=  25.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.156, r2=-0.032, total=  16.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.355, r2=-0.035, total=  13.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.360, r2=-0.038, total=   1.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.650, r2=-0.070, total=   5.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.966, r2=-0.016, total=  10.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.436, r2=-0.040, total=  18.3s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.205, r2=-0.038, total=   5.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.360, r2=-0.038, total=   5.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.956, r2=-0.015, total=   5.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.443, r2=-0.041, total=   2.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.150, r2=-0.030, total=   2.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.416, r2=-0.050, total=   3.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.620, r2=-0.065, total=  16.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.956, r2=-0.015, total=   6.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.434, r2=-0.041, total=   3.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.598, r2=-0.061, total=   9.7s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.175, r2=-0.036, total=   1.7s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.358, r2=-0.036, total=   1.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.598, r2=-0.061, total=   2.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-16.007, r2=-0.021, total=   4.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.434, r2=-0.041, total=   6.3s\n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.969, r2=-0.017, total=  11.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.436, r2=-0.040, total=   8.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.650, r2=-0.070, total=   1.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.205, r2=-0.038, total=   1.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.966, r2=-0.016, total=   1.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.436, r2=-0.040, total=   5.5s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.205, r2=-0.038, total=   8.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.360, r2=-0.038, total=  16.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.650, r2=-0.070, total=   6.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.966, r2=-0.016, total=   4.6s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.443, r2=-0.041, total=   2.1s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.620, r2=-0.065, total=   1.7s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.150, r2=-0.030, total=   3.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.416, r2=-0.050, total=   2.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.620, r2=-0.065, total=   2.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.956, r2=-0.015, total=   3.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.443, r2=-0.041, total=   8.8s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.150, r2=-0.030, total=  12.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.416, r2=-0.050, total=  16.4s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-16.007, r2=-0.021, total=   1.9s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.434, r2=-0.041, total=   3.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.175, r2=-0.036, total=   4.3s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.358, r2=-0.036, total=   4.2s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.598, r2=-0.061, total=   9.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-16.007, r2=-0.021, total=  24.0s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:23:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.255, r2=-0.029, total=   5.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:23:42] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.389, r2=-0.046, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:23:43] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-14.967, r2=-0.025, total=   1.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:23:45] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-16.053, r2=-0.042, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:23:45] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.021, total=   3.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:23:49] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.140, r2=-0.012, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:23:49] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.261, r2=-0.023, total=   1.1s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:23:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-14.868, r2=-0.009, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:23:51] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.893, r2=-0.017, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:23:51] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.141, r2=-0.003, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:23:52] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.137, r2=-0.007, total=   0.9s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:23:53] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.011, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:23:53] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-14.847, r2=-0.003, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:23:54] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.121, r2=0.002, total=   1.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:23:56] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.175, r2=-0.036, total=  20.0s\n[CV] booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=gbtree, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.358, r2=-0.036, total=  26.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:23:54] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.838, r2=-0.004, total=   1.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:23:55] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.029, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:23:55] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.388, r2=-0.046, total=   0.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:23:56] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-16.053, r2=-0.042, total=   4.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:24:01] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.140, r2=-0.012, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:24:01] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-14.868, r2=-0.009, total=   1.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:24:02] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.141, r2=-0.003, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:24:03] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.011, total=   1.0s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:24:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.838, r2=-0.004, total=   0.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:24:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.255, r2=-0.029, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:24:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.388, r2=-0.046, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:24:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-14.968, r2=-0.025, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:23:57] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.021, total=   4.1s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:24:01] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.262, r2=-0.023, total=   1.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:24:02] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.893, r2=-0.017, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:24:02] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.137, r2=-0.007, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:24:03] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-14.847, r2=-0.003, total=   1.1s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:24:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.121, r2=0.002, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:24:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-14.967, r2=-0.025, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:24:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.021, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:24:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.261, r2=-0.023, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:24:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.893, r2=-0.017, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:24:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.137, r2=-0.007, total=   1.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:24:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-14.847, r2=-0.003, total=   1.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-16.053, r2=-0.042, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:24:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.140, r2=-0.012, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:24:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-14.868, r2=-0.009, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:24:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.141, r2=-0.003, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:24:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.011, total=   1.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:24:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.838, r2=-0.004, total=   1.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:24:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:24:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:24:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:24:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:24:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:24:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:24:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:24:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.121, r2=0.002, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:24:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.1s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:24:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:24:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:24:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:24:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:24:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.9s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:24:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:24:13] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:24:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:24:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   3.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:24:17] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:24:18] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[09:24:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:24:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   1.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:24:13] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:24:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:24:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   3.1s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:24:17] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:24:18] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:24:19] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   1.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:24:20] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:24:21] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:24:21] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:24:21] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:24:22] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   1.9s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:24:20] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:24:21] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:24:21] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:24:22] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:24:22] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:24:23] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:24:23] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:24:24] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   5.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:24:29] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   4.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:24:34] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   6.0s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:24:40] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:24:41] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:24:41] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 26.5min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:24:22] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:24:22] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:24:23] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:24:24] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   5.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:24:29] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=  11.0s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:24:40] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:24:41] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:24:41] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:24:41] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:24:42] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:24:42] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:24:43] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:24:44] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:24:41] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:24:42] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:24:43] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:24:43] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:24:43] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.1s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:24:44] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:24:44] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:24:44] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   3.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:24:48] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   2.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:24:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:24:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   8.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:24:59] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   4.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:25:03] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.1s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:24:44] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:24:44] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   5.7s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:24:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:24:51] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=  12.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:25:03] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   1.0s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:25:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:25:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:25:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:25:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:25:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.8s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:25:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:25:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.029, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:25:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:25:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.2s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:25:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:25:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:25:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.4s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:25:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:25:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.9s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:25:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.6s\n[CV] booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:25:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:25:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-16.053, r2=-0.042, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:25:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.140, r2=-0.012, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:25:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-14.868, r2=-0.009, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:25:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.141, r2=-0.003, total=   0.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.388, r2=-0.046, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:25:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-14.967, r2=-0.025, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:25:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.021, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:25:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.261, r2=-0.023, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:25:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.893, r2=-0.017, total=   0.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:25:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.137, r2=-0.007, total=   0.8s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:25:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-14.847, r2=-0.003, total=   1.0s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:25:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.121, r2=0.002, total=   1.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:25:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-16.053, r2=-0.042, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:25:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.140, r2=-0.012, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:25:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-14.868, r2=-0.009, total=   0.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:25:13] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.141, r2=-0.003, total=  10.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:25:24] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.011, total=   1.0s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 [09:25:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.011, total=   1.0s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:25:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.838, r2=-0.004, total=   0.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:25:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.029, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:25:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.388, r2=-0.046, total=   0.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:25:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-14.967, r2=-0.025, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:25:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.021, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:25:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.261, r2=-0.023, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:25:13] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.893, r2=-0.017, total=   1.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:25:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.137, r2=-0.007, total=  11.0s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:25:25] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-14.847, r2=-0.003, total=   0.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:25:25] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.121, r2=0.002, total=   0.9s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:25:26] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.257, r2=-0.021, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:25:26] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[09:25:25] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.838, r2=-0.004, total=   0.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:25:25] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.029, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:25:26] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.388, r2=-0.046, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:25:26] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-14.967, r2=-0.025, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:25:26] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-16.052, r2=-0.042, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:25:26] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.140, r2=-0.012, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:25:27] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.893, r2=-0.017, total=   0.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:25:27] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.137, r2=-0.007, total=   9.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:25:36] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-14.847, r2=-0.003, total=   0.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:25:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.121, r2=0.002, total=   0.8s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:25:38] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:25:38] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   2.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:25:40] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.261, r2=-0.023, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:25:27] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-14.868, r2=-0.009, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:25:27] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.141, r2=-0.003, total=   7.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:25:34] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.011, total=   2.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:25:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.838, r2=-0.004, total=   0.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:25:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:25:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:25:38] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:25:38] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:25:38] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   2.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:25:41] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   5.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:25:46] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   6.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:25:52] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   5.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:25:58] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.9s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:25:59] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:25:59] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:25:59] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:25:59] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:00] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:00] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:01] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:01] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   1.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:03] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:03] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   8.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:25:49] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   8.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:25:58] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.8s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:25:59] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:25:59] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:00] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:00] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:01] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.9s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:02] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   1.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:03] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.8s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.8s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   1.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   1.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:26:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:26:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:26:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:26:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:26:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:26:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   3.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:26:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:26:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   2.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:26:16] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   1.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:26:18] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   1.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:26:19] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.9s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   1.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   1.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   1.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:26:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:26:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   3.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:26:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:26:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   2.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:26:16] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   1.0s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:26:17] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   2.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:26:20] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:26:20] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:26:20] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:26:20] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:26:21] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:26:21] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.8s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:26:22] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.8s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:26:23] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   1.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:26:24] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:26:24] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:26:24] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:26:25] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:26:25] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.8s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:26:26] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:26:20] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:26:20] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.7s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:26:21] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:26:22] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.9s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:26:23] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.8s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:26:23] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.2s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:26:24] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.3s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:26:24] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.1s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:26:24] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:26:25] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.5s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:26:25] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:26:26] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.6s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:26:26] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:26:27] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.029, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:26:27] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.388, r2=-0.046, total=   0.1s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:26:28] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-14.967, r2=-0.025, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:26:28] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-16.053, r2=-0.042, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:26:28] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.261, r2=-0.023, total=   0.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:26:29] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.893, r2=-0.017, total=   1.9s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:26:31] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.141, r2=-0.003, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:26:31] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.011, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:26:32] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.838, r2=-0.004, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:26:33] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.029, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:26:33] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.388, r2=-0.046, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:26:33] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-16.053, r2=-0.042, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:26:33] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.9s\n[CV] booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:26:27] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[09:26:28] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.021, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:26:28] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.140, r2=-0.012, total=   0.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[09:26:29] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-14.868, r2=-0.009, total=   1.9s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:26:31] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.137, r2=-0.007, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:26:31] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-14.847, r2=-0.003, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[09:26:32] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.121, r2=0.002, total=   0.9s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:26:33] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-14.967, r2=-0.025, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[09:26:33] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.021, total=   0.1s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:26:34] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.261, r2=-0.023, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:26:34] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.893, r2=-0.017, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:26:34] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.137, r2=-0.007, total=   0.9s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:26:35] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.140, r2=-0.012, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:26:34] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-14.868, r2=-0.009, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[09:26:34] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.141, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:26:34] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.011, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:26:35] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.838, r2=-0.004, total=   0.9s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:26:36] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.029, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:26:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.388, r2=-0.046, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:26:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-14.967, r2=-0.025, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:26:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.256, r2=-0.021, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:26:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.261, r2=-0.023, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:26:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.893, r2=-0.017, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:26:38] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.137, r2=-0.007, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:26:39] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-14.847, r2=-0.003, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:26:40] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-14.847, r2=-0.003, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[09:26:36] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.121, r2=0.002, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[09:26:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-16.053, r2=-0.042, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:26:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.140, r2=-0.012, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:26:37] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-14.868, r2=-0.009, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[09:26:38] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.141, r2=-0.003, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:26:38] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.011, total=   0.9s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[09:26:39] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.838, r2=-0.004, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:26:40] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:26:40] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:26:41] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:26:42] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:26:42] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:26:43] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.121, r2=0.002, total=   1.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[09:26:41] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:26:42] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:26:43] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[09:26:43] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:26:44] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:26:45] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:26:45] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:26:45] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:26:46] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:26:46] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:46] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:47] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:47] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:26:44] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:26:44] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[09:26:45] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[09:26:46] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:46] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:47] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[09:26:47] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:48] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:48] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:49] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:49] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:49] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.9s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:48] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[09:26:49] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[09:26:49] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   2.1s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:53] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:53] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   6.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:26:59] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   3.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:27:03] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:27:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:27:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.1s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:27:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[09:26:50] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:51] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   2.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:53] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   6.1s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[09:26:59] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   4.9s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[09:27:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:27:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:27:04] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:27:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:27:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:27:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:27:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.1s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:27:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 29.0min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[09:27:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:27:05] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:27:06] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   1.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[09:27:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.6s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:27:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:27:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.1s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:27:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:27:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:27:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:27:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:27:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.8s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:27:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.1s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:27:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[09:27:07] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:27:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:27:08] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[09:27:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:27:09] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[09:27:10] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:27:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.170, r2=-0.006, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:27:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:27:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-14.873, r2=-0.003, total=   0.3s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[09:27:11] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:27:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.005, total=   0.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:27:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.839, r2=-0.001, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:27:13] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.171, r2=-0.006, total=   0.7s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:27:12] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-14.873, r2=-0.003, total=   1.0s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[09:27:13] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.4s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:27:14] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.005, total=   3.9s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:27:17] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-14.873, r2=-0.003, total=   3.5s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:27:21] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.154, r2=0.001, total=   0.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.382, r2=-0.025, total=   9.1s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.871, r2=-0.006, total=   8.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.394, r2=-0.035, total=  31.2s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.088, r2=-0.025, total=  31.0s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.289, r2=-0.024, total= 1.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.530, r2=-0.050, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.928, r2=-0.011, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.367, r2=-0.032, total=   8.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.433, r2=-0.034, total=  11.7s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.089, r2=-0.026, total=   9.3s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.902, r2=-0.008, total=   7.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.278, r2=-0.024, total=   7.7s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.426, r2=-0.039, total=  40.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.523, r2=-0.048, total=  41.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.940, r2=-0.011, total=  43.0s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.447, r2=-0.043, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.177, r2=-0.036, total= 3.2min\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.171, r2=-0.006, total=   4.2s\n[CV] booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[09:27:18] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n[CV]  booster=gblinear, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.839, r2=-0.001, total=   3.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.328, r2=-0.028, total=   8.7s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.040, r2=-0.018, total=   8.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.225, r2=-0.014, total=   9.3s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.450, r2=-0.035, total=  28.2s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.910, r2=-0.009, total=  32.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.465, r2=-0.043, total= 3.4min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.129, r2=-0.030, total= 3.4min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.346, r2=-0.034, total= 2.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.149, r2=-0.032, total=  53.3s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.328, r2=-0.031, total=  32.1s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.573, r2=-0.055, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.953, r2=-0.012, total= 3.4min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.392, r2=-0.036, total=   9.7s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.521, r2=-0.048, total=   9.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.108, r2=-0.027, total=  20.0s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.949, r2=-0.014, total=  16.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.299, r2=-0.028, total=  13.6s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.430, r2=-0.041, total=  50.1s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.566, r2=-0.054, total=  49.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.945, r2=-0.013, total=  59.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.431, r2=-0.042, total= 2.7min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.146, r2=-0.031, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.325, r2=-0.031, total= 2.7min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.214, r2=-0.039, total=  32.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.381, r2=-0.041, total=  32.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.637, r2=-0.072, total= 2.9min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.344, r2=-0.034, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.145, r2=-0.031, total=  56.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.324, r2=-0.031, total=  37.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.568, r2=-0.054, total= 3.2min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.945, r2=-0.013, total= 2.7min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.493, r2=-0.049, total=   7.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.638, r2=-0.072, total=   7.3s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.213, r2=-0.039, total=  11.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.948, r2=-0.016, total=  15.6s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.380, r2=-0.041, total=  11.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.496, r2=-0.049, total=  36.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.637, r2=-0.072, total=  38.0s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.945, r2=-0.015, total=  33.3s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.496, r2=-0.049, total= 2.9min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.214, r2=-0.039, total= 2.6min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.381, r2=-0.041, total= 2.5min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.194, r2=-0.037, total=  32.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.346, r2=-0.037, total=  48.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.613, r2=-0.061, total= 2.5min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.947, r2=-0.013, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.432, r2=-0.042, total=  21.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.576, r2=-0.056, total=   8.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.163, r2=-0.032, total=  19.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.967, r2=-0.015, total=   8.0s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.372, r2=-0.039, total=  21.7s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.432, r2=-0.042, total=  37.2s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.576, r2=-0.056, total=  45.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.967, r2=-0.015, total=  32.1s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.432, r2=-0.042, total= 2.3min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.945, r2=-0.015, total= 2.6min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.447, r2=-0.042, total=   8.1s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.613, r2=-0.061, total=  21.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.194, r2=-0.037, total=  18.7s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.947, r2=-0.013, total=   9.0s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.346, r2=-0.037, total=  13.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.447, r2=-0.042, total=  28.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.613, r2=-0.061, total=  40.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.947, r2=-0.013, total=  36.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.447, r2=-0.042, total= 2.7min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.194, r2=-0.037, total= 3.0min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.346, r2=-0.037, total= 2.8min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.163, r2=-0.032, total=  40.9s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.372, r2=-0.039, total=  46.0s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.576, r2=-0.056, total= 2.2min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.967, r2=-0.015, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.462, r2=-0.043, total=   7.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.630, r2=-0.068, total=   9.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.212, r2=-0.039, total=  11.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.970, r2=-0.015, total=  16.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.366, r2=-0.038, total=  25.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.463, r2=-0.043, total=  52.7s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.630, r2=-0.068, total=  52.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.970, r2=-0.015, total=  38.2s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.463, r2=-0.043, total= 2.4min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.213, r2=-0.039, total= 2.8min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.368, r2=-0.038, total= 2.8min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.159, r2=-0.032, total=  59.8s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.413, r2=-0.053, total=  37.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.636, r2=-0.066, total= 2.3min\n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.163, r2=-0.032, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.372, r2=-0.039, total= 3.1min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.213, r2=-0.039, total=  39.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.368, r2=-0.038, total=  44.6s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.630, r2=-0.068, total= 2.4min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.970, r2=-0.015, total= 2.6min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.446, r2=-0.043, total=  18.3s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.636, r2=-0.066, total=   7.3s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.159, r2=-0.032, total=  24.0s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.957, r2=-0.015, total=   7.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.413, r2=-0.053, total=   7.3s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.446, r2=-0.043, total=  38.6s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.636, r2=-0.066, total=  59.6s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.957, r2=-0.015, total= 1.0min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.446, r2=-0.043, total= 2.2min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.159, r2=-0.032, total= 2.2min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.413, r2=-0.053, total= 3.0min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.182, r2=-0.038, total=  46.2s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.363, r2=-0.037, total=  45.7s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.592, r2=-0.060, total= 2.2min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.999, r2=-0.022, total= 2.7min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.328, r2=-0.028, total=   8.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.382, r2=-0.025, total=   7.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.040, r2=-0.018, total=   7.2s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.871, r2=-0.006, total=   9.1s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.225, r2=-0.014, total=   8.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.394, r2=-0.035, total=  38.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.464, r2=-0.037, total=  56.9s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.916, r2=-0.010, total=  30.2s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.458, r2=-0.043, total= 2.2min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.957, r2=-0.015, total= 2.5min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.433, r2=-0.042, total=  12.7s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.592, r2=-0.060, total=  14.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.182, r2=-0.038, total=   8.6s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.999, r2=-0.022, total=  12.6s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.363, r2=-0.037, total=  24.6s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.433, r2=-0.042, total=  43.1s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.592, r2=-0.060, total=  39.5s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.999, r2=-0.022, total=  38.4s\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.433, r2=-0.042, total= 2.4min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.182, r2=-0.038, total= 2.8min\n[CV] booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.13813876934737612, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.363, r2=-0.037, total= 2.3min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.083, r2=-0.025, total=  31.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.287, r2=-0.025, total=  33.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.541, r2=-0.051, total= 2.2min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.945, r2=-0.014, total= 3.6min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.370, r2=-0.032, total=   8.3s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.438, r2=-0.035, total=   8.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.084, r2=-0.025, total=  16.2s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.902, r2=-0.008, total=  21.0s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.278, r2=-0.024, total=  16.1s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.434, r2=-0.041, total=  55.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.546, r2=-0.050, total=  47.6s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.935, r2=-0.010, total=  50.3s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.450, r2=-0.043, total= 3.2min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.174, r2=-0.035, total= 3.6min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.344, r2=-0.034, total= 2.8min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.162, r2=-0.032, total=  52.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.321, r2=-0.031, total= 1.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.142, r2=-0.030, total= 3.0min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.350, r2=-0.035, total= 3.4min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.138, r2=-0.031, total=  59.1s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.330, r2=-0.032, total=  44.2s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.583, r2=-0.057, total= 3.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.945, r2=-0.012, total= 3.6min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.395, r2=-0.037, total=  31.8s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.519, r2=-0.047, total=  16.8s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.121, r2=-0.028, total=   9.6s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.943, r2=-0.013, total=  18.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.299, r2=-0.027, total=  15.1s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.427, r2=-0.041, total=  35.0s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.566, r2=-0.054, total=  39.9s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.940, r2=-0.012, total=  50.9s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.428, r2=-0.041, total= 3.0min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.163, r2=-0.033, total= 3.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.322, r2=-0.031, total= 2.8min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.211, r2=-0.039, total= 1.0min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.373, r2=-0.040, total=  42.0s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.643, r2=-0.073, total= 2.6min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.934, r2=-0.013, total= 2.6min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.442, r2=-0.042, total=  15.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.613, r2=-0.061, total=  14.9s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.187, r2=-0.035, total=   8.3s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.951, r2=-0.014, total=   7.9s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.350, r2=-0.036, total=  29.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.442, r2=-0.042, total=  46.9s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.613, r2=-0.061, total=  54.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.951, r2=-0.014, total=  31.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.569, r2=-0.054, total= 2.9min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.940, r2=-0.012, total= 2.9min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.499, r2=-0.049, total=  17.0s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.643, r2=-0.073, total=  18.1s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.211, r2=-0.039, total=   8.0s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.934, r2=-0.013, total=   7.3s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.372, r2=-0.039, total=  12.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.499, r2=-0.049, total=  39.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.643, r2=-0.073, total=  40.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.934, r2=-0.013, total= 1.0min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.499, r2=-0.049, total= 2.5min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.211, r2=-0.039, total= 2.7min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.373, r2=-0.040, total= 2.9min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.187, r2=-0.035, total=  44.1s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.350, r2=-0.036, total=  31.6s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.613, r2=-0.061, total= 2.5min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.951, r2=-0.014, total= 3.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.432, r2=-0.042, total=  12.3s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.575, r2=-0.055, total=  20.6s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.165, r2=-0.033, total=  18.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.966, r2=-0.015, total=  11.2s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.371, r2=-0.039, total=   8.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.432, r2=-0.042, total=  33.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.575, r2=-0.055, total=  54.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.966, r2=-0.015, total= 1.0min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.432, r2=-0.042, total= 3.3min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.165, r2=-0.033, total= 2.4min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.371, r2=-0.039, total= 2.2min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.210, r2=-0.039, total=  34.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.369, r2=-0.038, total=  32.4s\n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.442, r2=-0.042, total= 2.2min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.187, r2=-0.035, total= 3.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.350, r2=-0.036, total= 2.9min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.165, r2=-0.033, total= 1.0min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.371, r2=-0.039, total= 1.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.575, r2=-0.055, total= 2.8min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.966, r2=-0.015, total= 2.4min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.462, r2=-0.043, total=  11.6s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.628, r2=-0.068, total=  14.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.210, r2=-0.039, total=   8.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.957, r2=-0.015, total=   8.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.369, r2=-0.038, total=  14.6s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.464, r2=-0.043, total=  36.9s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.628, r2=-0.068, total=  36.8s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.957, r2=-0.015, total=  29.0s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.464, r2=-0.043, total= 2.4min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.210, r2=-0.039, total= 2.8min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.369, r2=-0.038, total= 2.5min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.163, r2=-0.032, total= 1.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.411, r2=-0.053, total=  32.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.634, r2=-0.066, total= 2.2min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.957, r2=-0.015, total= 2.0min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.435, r2=-0.042, total=   8.0s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.591, r2=-0.060, total=  13.6s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.181, r2=-0.038, total=   7.8s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-16.000, r2=-0.022, total=  22.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.363, r2=-0.037, total=  14.3s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.435, r2=-0.042, total=  52.0s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.591, r2=-0.060, total=  31.0s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-16.000, r2=-0.022, total=  38.6s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.628, r2=-0.068, total= 2.4min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.957, r2=-0.015, total= 2.9min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.449, r2=-0.043, total=   8.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.634, r2=-0.066, total=   8.3s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.163, r2=-0.032, total=  14.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.957, r2=-0.015, total=   9.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.411, r2=-0.053, total=  24.7s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.449, r2=-0.043, total=  32.4s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.634, r2=-0.066, total=  44.5s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.957, r2=-0.015, total= 1.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.449, r2=-0.043, total= 2.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.163, r2=-0.032, total= 2.1min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.411, r2=-0.053, total= 2.6min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.181, r2=-0.038, total=  34.2s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.363, r2=-0.037, total=  31.8s\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.591, r2=-0.060, total= 2.7min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-16.000, r2=-0.022, total= 3.0min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.329, r2=-0.028, total=  22.1s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.367, r2=-0.023, total=   8.5s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.043, r2=-0.019, total=   7.5s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.866, r2=-0.004, total=   7.9s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.209, r2=-0.013, total=   8.0s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.411, r2=-0.037, total=  56.9s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.461, r2=-0.036, total= 1.3min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.919, r2=-0.009, total=  45.3s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.458, r2=-0.043, total= 3.4min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.126, r2=-0.030, total= 3.2min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.354, r2=-0.036, total= 2.8min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.133, r2=-0.031, total= 1.1min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.435, r2=-0.042, total= 2.6min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.181, r2=-0.038, total= 2.9min\n[CV] booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.15157563325294887, learning_rate=0.9712859280926744, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.363, r2=-0.037, total= 3.0min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.080, r2=-0.024, total= 1.0min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.287, r2=-0.026, total= 1.1min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.546, r2=-0.051, total= 2.9min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.933, r2=-0.011, total= 3.1min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.363, r2=-0.031, total=  19.4s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.470, r2=-0.039, total=  17.0s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.078, r2=-0.025, total=   9.0s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.903, r2=-0.009, total=  14.6s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.271, r2=-0.023, total=   8.8s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.413, r2=-0.038, total=  46.2s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.527, r2=-0.048, total=  59.6s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.934, r2=-0.012, total= 1.0min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.416, r2=-0.039, total= 3.2min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.140, r2=-0.032, total= 2.8min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.328, r2=-0.031, total= 3.4min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.155, r2=-0.032, total= 1.0min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.310, r2=-0.029, total=  50.6s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.562, r2=-0.052, total= 3.0min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.946, r2=-0.014, total= 2.4min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.461, r2=-0.043, total=   7.2s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.621, r2=-0.068, total=  15.4s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.202, r2=-0.039, total=   9.4s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.940, r2=-0.014, total=   7.1s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.369, r2=-0.038, total=   7.9s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.461, r2=-0.043, total=  50.3s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.621, r2=-0.068, total=  55.5s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 237.5min\n","output_type":"stream"},{"name":"stdout","text":"\n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.319, r2=-0.030, total= 1.0min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.527, r2=-0.048, total= 2.9min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.934, r2=-0.012, total= 2.8min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.395, r2=-0.037, total=  27.6s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.523, r2=-0.047, total=  14.4s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.132, r2=-0.029, total=  25.3s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.940, r2=-0.013, total=   9.1s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.291, r2=-0.026, total=  14.5s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.423, r2=-0.041, total=  58.4s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.562, r2=-0.052, total=  59.2s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.946, r2=-0.014, total= 1.1min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.423, r2=-0.041, total= 2.9min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.155, r2=-0.032, total= 2.4min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.11066010406675952, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.310, r2=-0.029, total= 3.2min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.940, r2=-0.014, total=  38.2s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.461, r2=-0.043, total= 2.4min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.202, r2=-0.039, total= 2.8min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.369, r2=-0.038, total= 2.4min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.177, r2=-0.035, total=  50.0s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.326, r2=-0.034, total=  28.0s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.615, r2=-0.062, total= 2.7min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.954, r2=-0.015, total= 2.0min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.430, r2=-0.043, total=   8.5s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.573, r2=-0.055, total=   9.1s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.156, r2=-0.032, total=   7.7s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.969, r2=-0.017, total=  10.8s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=100, neg_mean_absolute_error=-15.355, r2=-0.035, total=  10.8s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.430, r2=-0.043, total=  37.9s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.573, r2=-0.055, total=  40.3s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.969, r2=-0.017, total=  43.8s[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.202, r2=-0.039, total=  36.8s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.369, r2=-0.038, total=  40.9s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.621, r2=-0.068, total= 2.5min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.940, r2=-0.014, total= 2.6min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.426, r2=-0.040, total=   6.8s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.615, r2=-0.062, total=   9.8s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.177, r2=-0.035, total=  17.7s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.954, r2=-0.015, total=  15.4s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=100, neg_mean_absolute_error=-15.326, r2=-0.034, total=   9.1s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.426, r2=-0.040, total=  40.7s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.615, r2=-0.062, total=  40.4s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=200, neg_mean_absolute_error=-15.954, r2=-0.015, total=  42.3s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.426, r2=-0.040, total= 2.6min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.177, r2=-0.035, total= 2.1min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=6, n_estimators=400, neg_mean_absolute_error=-15.326, r2=-0.034, total= 2.1min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.156, r2=-0.032, total=  39.6s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=200, neg_mean_absolute_error=-15.355, r2=-0.035, total=  32.7s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.573, r2=-0.055, total= 2.4min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.8777637531712105, max_depth=7, n_estimators=400, neg_mean_absolute_error=-15.969, r2=-0.017, total= 2.5min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.436, r2=-0.040, total=  12.6s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.650, r2=-0.070, total=  10.8s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.205, r2=-0.038, total=   9.4s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.966, r2=-0.016, total=   6.9s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=100, neg_mean_absolute_error=-15.360, r2=-0.038, total=  11.5s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.436, r2=-0.040, total=  51.9s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.650, r2=-0.070, total=  55.7s\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=200, neg_mean_absolute_error=-15.966, r2=-0.016, total= 1.0min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.436, r2=-0.040, total= 2.4min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.205, r2=-0.038, total= 2.3min\n[CV] booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400 \n[CV]  booster=dart, gamma=0.911493697937794, learning_rate=0.9712859280926744, max_depth=5, n_estimators=400, neg_mean_absolute_error=-15.360, r2=-0.038, total= 2.7min","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Done 1215 out of 1215 | elapsed: 278.8min finished\n","output_type":"stream"},{"name":"stdout","text":"[13:37:03] WARNING: ../src/learner.cc:576: \nParameters: { \"gamma\", \"max_depth\" } might not be used.\n\n  This could be a false alarm, with some parameters getting used by language bindings but\n  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n  but getting flagged wrongly here. Please open an issue if you find any such cases.\n\n\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5,\n             estimator=XGBRegressor(base_score=None, booster=None,\n                                    colsample_bylevel=None,\n                                    colsample_bynode=None,\n                                    colsample_bytree=None,\n                                    enable_categorical=False, gamma=None,\n                                    gpu_id=None, importance_type=None,\n                                    interaction_constraints=None,\n                                    learning_rate=None, max_delta_step=None,\n                                    max_depth=None, min_child_weight=None,\n                                    missing=nan, monotone_constraints=None,\n                                    n...\n                                    validate_parameters=None, verbosity=None),\n             n_jobs=-1,\n             param_grid={'booster': ['gbtree', 'gblinear', 'dart'],\n                         'gamma': [0.13813876934737612, 0.15157563325294887,\n                                   0.911493697937794],\n                         'learning_rate': [0.11066010406675952,\n                                           0.8777637531712105,\n                                           0.9712859280926744],\n                         'max_depth': [5, 6, 7],\n                         'n_estimators': [100, 200, 400]},\n             refit='r2', scoring=['r2', 'neg_mean_absolute_error'], verbose=3)"},"metadata":{}}]},{"cell_type":"code","source":"print(XGBreg_GS.best_params_)\nprint(XGBreg_GS.best_score_)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:39:04.408442Z","iopub.execute_input":"2022-08-28T13:39:04.408744Z","iopub.status.idle":"2022-08-28T13:39:04.415678Z","shell.execute_reply.started":"2022-08-28T13:39:04.408710Z","shell.execute_reply":"2022-08-28T13:39:04.413664Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"{'booster': 'gblinear', 'gamma': 0.15157563325294887, 'learning_rate': 0.8777637531712105, 'max_depth': 6, 'n_estimators': 100}\n-0.002863236526097479\n","output_type":"stream"}]},{"cell_type":"code","source":"model_pred = XGBreg_GS.predict(X_test)\nXGBreg_r2 = r2_score(y_test, model_pred)\nXGBreg_r2","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:39:08.023383Z","iopub.execute_input":"2022-08-28T13:39:08.023964Z","iopub.status.idle":"2022-08-28T13:39:08.036175Z","shell.execute_reply.started":"2022-08-28T13:39:08.023927Z","shell.execute_reply":"2022-08-28T13:39:08.035351Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"-0.0014321364972478268"},"metadata":{}}]},{"cell_type":"markdown","source":"# Results of Regression algorithms\n\nAs we have guessed from the diagrams, the csv data is not suitable for training and we should use images themselves. Let's try it","metadata":{}},{"cell_type":"markdown","source":"# CNN with a regression head","metadata":{}},{"cell_type":"markdown","source":"Due to RAM limitation, I'm going to choose 7000 images randomly for training and resize them to 256 * 256 pixels","metadata":{}},{"cell_type":"code","source":"import cv2\nimport random\n\ntrain_imgs_path = '../input/petfinder-pawpularity-score/train'\ntrain_imgs_files = os.listdir(train_imgs_path)\ntrain_smpls_imgs = random.sample(train_imgs_files, 7000)\n\nX = []\nfor img_name in train_smpls_imgs:\n    image = cv2.imread(train_imgs_path + '/' + img_name, 1)\n    image = cv2.resize(image, dsize=(256,256), interpolation=cv2.INTER_CUBIC)\n    X.append(np.array(image))","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:42:25.301883Z","iopub.execute_input":"2022-08-28T13:42:25.302597Z","iopub.status.idle":"2022-08-28T13:43:55.540262Z","shell.execute_reply.started":"2022-08-28T13:42:25.302558Z","shell.execute_reply":"2022-08-28T13:43:55.539322Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Extracting the score(Pawpularity) of each image in the training set(X)","metadata":{}},{"cell_type":"code","source":"y = []\nfor i in range(len(train_smpls_imgs)):\n    y.append(int(train_df[train_df.Id == train_smpls_imgs[i].split('.')[0]]['Pawpularity'].values[0]))","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:44:06.080378Z","iopub.execute_input":"2022-08-28T13:44:06.081119Z","iopub.status.idle":"2022-08-28T13:44:13.439802Z","shell.execute_reply.started":"2022-08-28T13:44:06.081080Z","shell.execute_reply":"2022-08-28T13:44:13.439037Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:44:17.824220Z","iopub.execute_input":"2022-08-28T13:44:17.824519Z","iopub.status.idle":"2022-08-28T13:44:18.631148Z","shell.execute_reply.started":"2022-08-28T13:44:17.824484Z","shell.execute_reply":"2022-08-28T13:44:18.630228Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.losses import MeanAbsoluteError\nfrom tensorflow.keras.layers import InputLayer, Lambda, Conv2D, LeakyReLU, Dropout, MaxPooling2D, BatchNormalization, Flatten, Dense\n\ncnn_model = Sequential()\ncnn_model.add(InputLayer(input_shape=(256,256,3)))\ncnn_model.add(Lambda(lambda x: x/255.))   #Normalization\n\ncnn_model.add(Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(MaxPooling2D((2, 2)))\ncnn_model.add(BatchNormalization())\n\ncnn_model.add(Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(MaxPooling2D((2, 2)))\ncnn_model.add(BatchNormalization())\n\ncnn_model.add(Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(Dropout(0.2))\ncnn_model.add(Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(Dropout(0.2))\ncnn_model.add(Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(MaxPooling2D((2, 2)))\ncnn_model.add(BatchNormalization())\n\ncnn_model.add(Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(Dropout(0.2))\ncnn_model.add(Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(Dropout(0.2))\ncnn_model.add(Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(MaxPooling2D((2, 2)))\ncnn_model.add(BatchNormalization())\n\ncnn_model.add(Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(Dropout(0.3))\ncnn_model.add(Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(Dropout(0.3))\ncnn_model.add(Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same'))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(MaxPooling2D((2, 2)))\ncnn_model.add(BatchNormalization())\n\ncnn_model.add(Flatten())\ncnn_model.add(Dense(4096))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Dropout(0.2))\ncnn_model.add(Dense(2048))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Dropout(0.2))\ncnn_model.add(Dense(1024))\ncnn_model.add(LeakyReLU(alpha=0.2))\ncnn_model.add(Dense(1))\n\ncnn_model.compile(optimizer='adam', loss= 'MeanAbsoluteError', metrics=[keras.metrics.MeanAbsoluteError()])\ncnn_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:44:34.758378Z","iopub.execute_input":"2022-08-28T13:44:34.758826Z","iopub.status.idle":"2022-08-28T13:44:44.911097Z","shell.execute_reply.started":"2022-08-28T13:44:34.758785Z","shell.execute_reply":"2022-08-28T13:44:44.910153Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"2022-08-28 13:44:40.038488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-08-28 13:44:40.039801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-08-28 13:44:40.040611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-08-28 13:44:40.041595: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-08-28 13:44:40.042655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-08-28 13:44:40.043361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-08-28 13:44:40.044029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-08-28 13:44:44.196537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-08-28 13:44:44.197435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-08-28 13:44:44.198150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-08-28 13:44:44.198765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15195 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlambda (Lambda)              (None, 256, 256, 3)       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 256, 256, 64)      1792      \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 256, 256, 64)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 256, 256, 64)      36928     \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 256, 256, 64)      0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 128, 128, 64)      0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 128, 128, 64)      256       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 128, 128, 128)     73856     \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 128, 128, 128)     0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 128, 128, 128)     147584    \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 128, 128, 128)     0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 64, 64, 128)       0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 64, 64, 128)       512       \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 64, 64, 256)       295168    \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 64, 64, 256)       0         \n_________________________________________________________________\ndropout (Dropout)            (None, 64, 64, 256)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 64, 64, 256)       590080    \n_________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 256)       0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 64, 64, 256)       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 64, 64, 256)       590080    \n_________________________________________________________________\nleaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 256)       0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 32, 32, 256)       0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 32, 32, 256)       1024      \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 32, 32, 512)       1180160   \n_________________________________________________________________\nleaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 512)       0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 32, 32, 512)       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nleaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 512)       0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32, 32, 512)       0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 32, 32, 512)       2359808   \n_________________________________________________________________\nleaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 512)       0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 16, 16, 512)       0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 16, 16, 512)       2048      \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nleaky_re_lu_10 (LeakyReLU)   (None, 16, 16, 512)       0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 16, 16, 512)       0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nleaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 512)       0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 16, 16, 512)       0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nleaky_re_lu_12 (LeakyReLU)   (None, 16, 16, 512)       0         \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 8, 8, 512)         0         \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 8, 8, 512)         2048      \n_________________________________________________________________\nflatten (Flatten)            (None, 32768)             0         \n_________________________________________________________________\ndense (Dense)                (None, 4096)              134221824 \n_________________________________________________________________\nleaky_re_lu_13 (LeakyReLU)   (None, 4096)              0         \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 4096)              16384     \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 4096)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 2048)              8390656   \n_________________________________________________________________\nleaky_re_lu_14 (LeakyReLU)   (None, 2048)              0         \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 2048)              8192      \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1024)              2098176   \n_________________________________________________________________\nleaky_re_lu_15 (LeakyReLU)   (None, 1024)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 1025      \n=================================================================\nTotal params: 159,456,833\nTrainable params: 159,441,601\nNon-trainable params: 15,232\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n             tf.keras.callbacks.ModelCheckpoint(filepath='/kaggle/working/result', monitor='val_loss', mode='min')]\n\nhistory = cnn_model.fit(x = X_train,\n                        y = y_train,\n                        batch_size = 20,\n                        callbacks = callbacks,\n                        validation_split = 0.2,\n                        verbose = 1,\n                        epochs = 50)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:44:55.066261Z","iopub.execute_input":"2022-08-28T13:44:55.067155Z","iopub.status.idle":"2022-08-28T13:55:31.420486Z","shell.execute_reply.started":"2022-08-28T13:44:55.067109Z","shell.execute_reply":"2022-08-28T13:55:31.419496Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"2022-08-28 13:44:55.074484: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 880803840 exceeds 10% of free system memory.\n2022-08-28 13:44:56.067450: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 880803840 exceeds 10% of free system memory.\n2022-08-28 13:44:56.795684: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2022-08-28 13:44:59.145861: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"224/224 [==============================] - 64s 243ms/step - loss: 17.6830 - mean_absolute_error: 17.6830 - val_loss: 15.5210 - val_mean_absolute_error: 15.5210\n","output_type":"stream"},{"name":"stderr","text":"2022-08-28 13:46:02.794816: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n2022-08-28 13:46:08.555357: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 536870912 exceeds 10% of free system memory.\n2022-08-28 13:46:09.142007: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 536870912 exceeds 10% of free system memory.\n2022-08-28 13:46:09.716620: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 536870912 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/50\n224/224 [==============================] - 54s 241ms/step - loss: 15.7277 - mean_absolute_error: 15.7277 - val_loss: 16.3537 - val_mean_absolute_error: 16.3537\nEpoch 3/50\n224/224 [==============================] - 55s 246ms/step - loss: 15.7265 - mean_absolute_error: 15.7265 - val_loss: 15.1999 - val_mean_absolute_error: 15.1999\nEpoch 4/50\n224/224 [==============================] - 54s 241ms/step - loss: 15.4219 - mean_absolute_error: 15.4219 - val_loss: 14.6024 - val_mean_absolute_error: 14.6024\nEpoch 5/50\n224/224 [==============================] - 55s 247ms/step - loss: 15.3265 - mean_absolute_error: 15.3265 - val_loss: 15.0300 - val_mean_absolute_error: 15.0300\nEpoch 6/50\n224/224 [==============================] - 54s 242ms/step - loss: 15.2542 - mean_absolute_error: 15.2542 - val_loss: 14.7578 - val_mean_absolute_error: 14.7578\nEpoch 7/50\n224/224 [==============================] - 55s 244ms/step - loss: 15.2488 - mean_absolute_error: 15.2488 - val_loss: 14.7797 - val_mean_absolute_error: 14.7797\nEpoch 8/50\n224/224 [==============================] - 54s 243ms/step - loss: 15.1806 - mean_absolute_error: 15.1806 - val_loss: 15.2318 - val_mean_absolute_error: 15.2318\nEpoch 9/50\n224/224 [==============================] - 54s 242ms/step - loss: 15.3230 - mean_absolute_error: 15.3230 - val_loss: 15.1390 - val_mean_absolute_error: 15.1390\n","output_type":"stream"}]},{"cell_type":"code","source":"model_pred = cnn_model.predict(X_test)\nCNNreg_r2 = r2_score(y_test, model_pred)\nCNNreg_r2","metadata":{"execution":{"iopub.status.busy":"2022-08-28T13:57:29.198097Z","iopub.execute_input":"2022-08-28T13:57:29.198941Z","iopub.status.idle":"2022-08-28T13:57:34.558174Z","shell.execute_reply.started":"2022-08-28T13:57:29.198897Z","shell.execute_reply":"2022-08-28T13:57:34.557307Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"-0.0795106880751093"},"metadata":{}}]}]}